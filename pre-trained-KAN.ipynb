{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc69ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging  # [LOGGING] Importar la librería de logging\n",
    "import random  # [SEED] Importar la librería random de Python\n",
    "import numpy as np  # [SEED] Importar NumPy\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # Para barra de progreso\n",
    "\n",
    "# Importar tu modelo corregido (asegúrate de que el archivo .py esté en la carpeta)\n",
    "sys.path.append(\"KAN_models\")\n",
    "from SBTAYLOR_KAN import Net as KAN_Model\n",
    "\n",
    "# Configuración de Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "\n",
    "# Semilla\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ef72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_PATH = \"C:\\\\Users\\\\Admin-Cidis\\\\.cache\\\\kagglehub\\\\datasets\\\\akash2sharma\\\\tiny-imagenet\\\\versions\\\\1\\\\tiny-imagenet-200\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "RUN_SAVE_DIR = os.path.join(\"models/sbtaylor_kan_tiny_imagenet\", f\"run_{timestamp}\")\n",
    "os.makedirs(RUN_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"sbtaylor_kan.best_weights.pth\"\n",
    "MODEL_SAVE_PATH = os.path.join(RUN_SAVE_DIR, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfee12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE_PATH = os.path.join(RUN_SAVE_DIR, \"training_run.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8887fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 01:33:31,941 - INFO - Modelo SBTAYLOR_KAN.Net importado correctamente.\n",
      "2025-12-24 01:33:31,942 - INFO - Los pesos del modelo se guardarán en: 'models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\sbtaylor_kan.best_weights.pth'\n",
      "2025-12-24 01:33:31,944 - INFO - El registro de entrenamiento se guardará en: 'models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\training_run.log'\n"
     ]
    }
   ],
   "source": [
    "# --- [LOGGING] CONFIGURACIÓN DEL LOGGER ---\n",
    "# Configura el logger para que escriba en un archivo y en la consola.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Nivel mínimo de mensajes a registrar (INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # Formato del mensaje\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            LOG_FILE_PATH, mode=\"w\"\n",
    "        ),  # Escribe en el archivo .log (modo 'w' para sobreescribir en cada ejecución)\n",
    "        logging.StreamHandler(),  # Muestra los logs en la consola\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Ahora, en lugar de print(), usaremos logging.info()\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.info(\"Modelo SBTAYLOR_KAN.Net importado correctamente.\")\n",
    "logger.info(f\"Los pesos del modelo se guardarán en: '{MODEL_SAVE_PATH}'\")\n",
    "logger.info(f\"El registro de entrenamiento se guardará en: '{LOG_FILE_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19af029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 01:33:31,970 - INFO - Versión de PyTorch: 2.9.0+cu126\n",
      "2025-12-24 01:33:31,971 - INFO - ¿CUDA está disponible?: True\n",
      "2025-12-24 01:33:31,972 - INFO - Versión de CUDA con la que PyTorch fue compilado: 12.6\n",
      "2025-12-24 01:33:31,974 - INFO - Número de GPUs disponibles: 1\n",
      "2025-12-24 01:33:31,979 - INFO - Nombre de la GPU actual: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Versión de PyTorch: {torch.__version__}\")\n",
    "logger.info(f\"¿CUDA está disponible?: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(\n",
    "        f\"Versión de CUDA con la que PyTorch fue compilado: {torch.version.cuda}\"\n",
    "    )\n",
    "    logger.info(f\"Número de GPUs disponibles: {torch.cuda.device_count()}\")\n",
    "    logger.info(f\"Nombre de la GPU actual: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logger.info(\n",
    "        \"PyTorch no puede encontrar CUDA. Es probable que hayas instalado la versión de solo CPU.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8478fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 01:33:32,012 - INFO - --- Hyperparámetros de Entrenamiento ---\n",
      "2025-12-24 01:33:32,013 - INFO - Batch Size: 64\n",
      "2025-12-24 01:33:32,014 - INFO - Num Epochs: 250\n",
      "2025-12-24 01:33:32,015 - INFO - Num Workers: 4\n"
     ]
    }
   ],
   "source": [
    "# --- 2. PARÁMETROS DE ENTRENAMIENTO ---\n",
    "set_seed(74)  # [SEED] Establecer la semilla para reproducibilidad\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 250\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# print hyperparameters\n",
    "logging.info(f\"--- Hyperparámetros de Entrenamiento ---\")\n",
    "logging.info(f\"Batch Size: {BATCH_SIZE}\")\n",
    "logging.info(f\"Num Epochs: {NUM_EPOCHS}\")\n",
    "logging.info(f\"Num Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0521c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde: C:\\Users\\Admin-Cidis\\.cache\\kagglehub\\datasets\\akash2sharma\\tiny-imagenet\\versions\\1\\tiny-imagenet-200/train\n",
      "Usando 10 clases: ['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750']\n",
      "Dataset listo.\n",
      "Entrenamiento : 4000 imágenes\n",
      "Validación    : 500 imágenes\n",
      "Test          : 500 imágenes\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, random_split, DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "# --- 1. Clase Wrapper (Se mantiene igual) ---\n",
    "class ApplyTransform(Dataset):\n",
    "    \"\"\"\n",
    "    Envuelve un dataset (o subset) y aplica una transformación específica on-the-fly.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "# --- 2. Transformaciones ---\n",
    "\n",
    "# TRAIN: Augmentations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    #crop\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# VAL: Estándar\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# TEST: Igual a Val (Sin augmentations, solo evaluar)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# --- 3. Carga y Filtrado ---\n",
    "data_dir = IMAGENET_PATH + \"/train\" # Ajusta tu path si es necesario\n",
    "print(f\"Cargando datos desde: {data_dir}\")\n",
    "\n",
    "full_dataset_raw = torchvision.datasets.ImageFolder(data_dir)\n",
    "\n",
    "# Seleccionamos solo las primeras 10 clases\n",
    "selected_classes = full_dataset_raw.classes[:10]\n",
    "print(f\"Usando {len(selected_classes)} clases: {selected_classes}\")\n",
    "\n",
    "selected_indices = [i for i, (_, label) in enumerate(full_dataset_raw) if label < 10]\n",
    "subset_dataset = Subset(full_dataset_raw, selected_indices)\n",
    "\n",
    "\n",
    "# --- 4. Split 80/10/10 (Train/Val/Test) ---\n",
    "total_len = len(subset_dataset)\n",
    "train_len = int(0.8 * total_len)\n",
    "val_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - val_len  # El resto para test\n",
    "\n",
    "# Ahora random_split recibe 3 longitudes\n",
    "train_subset, val_subset, test_subset = random_split(\n",
    "    subset_dataset, [train_len, val_len, test_len]\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. Aplicar Wrapper ---\n",
    "# Asignamos transformaciones: Train con ruido, Val y Test limpias\n",
    "train_dataset = ApplyTransform(train_subset, transform=transform_train)\n",
    "val_dataset = ApplyTransform(val_subset, transform=transform_val)\n",
    "test_dataset = ApplyTransform(test_subset, transform=transform_test)\n",
    "\n",
    "\n",
    "# --- 6. DataLoaders ---\n",
    "trainloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "valloader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset listo.\")\n",
    "print(f\"Entrenamiento : {len(train_dataset)} imágenes\")\n",
    "print(f\"Validación    : {len(val_dataset)} imágenes\")\n",
    "print(f\"Test          : {len(test_dataset)} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe621b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 01:35:18,981 - INFO - \n",
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 4. INICIALIZACIÓN DEL MODELO, CRITERIO Y OPTIMIZADOR ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"\\nUsando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4daaea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x25d87fb79d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7777979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(learning_rate=0.001, dropout_1=0.4, dropout_2=0.5, weight_decay=1e-3):\n",
    "    # Instanciar el modelo (Asegúrate que SBTAYLOR_KAN.Net es tu clase corregida)\n",
    "    model_ft = KAN_Model(\n",
    "        num_classes=len(selected_classes),\n",
    "        input_size=(3, 224, 224),\n",
    "        dropout_1=dropout_1,\n",
    "        dropout_2=dropout_2,\n",
    "    ).to(device)\n",
    "\n",
    "    # En lugar de nn.CrossEntropyLoss() simple:\n",
    "    criterion = nn.CrossEntropyLoss() #(label_smoothing=0.1)\n",
    "    optimizer = optim.Adam(\n",
    "        model_ft.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    return model_ft, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc522b",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b21e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones calculadas automáticamente para FC1: 25088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 01:35:20,029 - INFO - Iniciando entrenamiento por 250 épocas...\n",
      "2025-12-24 01:35:20,030 - INFO - Paciencia configurada: 50 épocas.\n",
      "2025-12-24 01:35:20,031 - INFO - --- Época 1/250 ---\n",
      "2025-12-24 01:36:17,802 - INFO - Train Loss: 2.3432 Acc: 0.1323  \n",
      "2025-12-24 01:36:18,961 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:36:18,962 - INFO -   [Mejora Loss] inf -> 2.1668. Reseteando paciencia.\n",
      "2025-12-24 01:36:18,963 - INFO - Val Loss: 2.1668 Acc: 0.2340\n",
      "2025-12-24 01:36:19,508 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:36:19,509 - INFO - --- Época 2/250 ---\n",
      "2025-12-24 01:37:13,218 - INFO - Train Loss: 2.1811 Acc: 0.1938  \n",
      "2025-12-24 01:37:14,182 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:37:14,183 - INFO -   [Mejora Loss] 2.1668 -> 2.0213. Reseteando paciencia.\n",
      "2025-12-24 01:37:14,184 - INFO - Val Loss: 2.0213 Acc: 0.3000\n",
      "2025-12-24 01:37:14,660 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:37:14,662 - INFO - --- Época 3/250 ---\n",
      "2025-12-24 01:38:07,880 - INFO - Train Loss: 2.1195 Acc: 0.2230  \n",
      "2025-12-24 01:38:08,854 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:38:08,854 - INFO -   [Mejora Loss] 2.0213 -> 2.0112. Reseteando paciencia.\n",
      "2025-12-24 01:38:08,856 - INFO - Val Loss: 2.0112 Acc: 0.2600\n",
      "2025-12-24 01:38:08,857 - INFO - --- Época 4/250 ---\n",
      "2025-12-24 01:39:02,288 - INFO - Train Loss: 2.0672 Acc: 0.2445  \n",
      "2025-12-24 01:39:03,228 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:39:03,229 - INFO -   [Mejora Loss] 2.0112 -> 1.8780. Reseteando paciencia.\n",
      "2025-12-24 01:39:03,229 - INFO - Val Loss: 1.8780 Acc: 0.3440\n",
      "2025-12-24 01:39:03,693 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:39:03,694 - INFO - --- Época 5/250 ---\n",
      "2025-12-24 01:39:56,920 - INFO - Train Loss: 2.0295 Acc: 0.2565  \n",
      "2025-12-24 01:39:57,882 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:39:57,883 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:39:57,886 - INFO - Val Loss: 1.9590 Acc: 0.3120\n",
      "2025-12-24 01:39:57,887 - INFO - --- Época 6/250 ---\n",
      "2025-12-24 01:40:51,077 - INFO - Train Loss: 1.9998 Acc: 0.2797  \n",
      "2025-12-24 01:40:52,010 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:40:52,010 - INFO -   [Mejora Loss] 1.8780 -> 1.8592. Reseteando paciencia.\n",
      "2025-12-24 01:40:52,011 - INFO - Val Loss: 1.8592 Acc: 0.3260\n",
      "2025-12-24 01:40:52,013 - INFO - --- Época 7/250 ---\n",
      "2025-12-24 01:41:45,205 - INFO - Train Loss: 1.9801 Acc: 0.2800  \n",
      "2025-12-24 01:41:46,185 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:41:46,186 - INFO -   [Mejora Loss] 1.8592 -> 1.8026. Reseteando paciencia.\n",
      "2025-12-24 01:41:46,187 - INFO - Val Loss: 1.8026 Acc: 0.3480\n",
      "2025-12-24 01:41:46,627 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:41:46,628 - INFO - --- Época 8/250 ---\n",
      "2025-12-24 01:42:40,014 - INFO - Train Loss: 1.9619 Acc: 0.2878  \n",
      "2025-12-24 01:42:40,991 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:42:40,992 - INFO -   [Mejora Loss] 1.8026 -> 1.7950. Reseteando paciencia.\n",
      "2025-12-24 01:42:40,993 - INFO - Val Loss: 1.7950 Acc: 0.3960\n",
      "2025-12-24 01:42:41,415 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:42:41,417 - INFO - --- Época 9/250 ---\n",
      "2025-12-24 01:43:35,195 - INFO - Train Loss: 1.9492 Acc: 0.3008  \n",
      "2025-12-24 01:43:36,186 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:43:36,187 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:43:36,188 - INFO - Val Loss: 1.8365 Acc: 0.3860\n",
      "2025-12-24 01:43:36,189 - INFO - --- Época 10/250 ---\n",
      "2025-12-24 01:44:29,360 - INFO - Train Loss: 1.9552 Acc: 0.3003  \n",
      "2025-12-24 01:44:30,335 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:44:30,336 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 01:44:30,337 - INFO - Val Loss: 1.8063 Acc: 0.3620\n",
      "2025-12-24 01:44:30,338 - INFO - --- Época 11/250 ---\n",
      "2025-12-24 01:45:23,453 - INFO - Train Loss: 1.9373 Acc: 0.3165  \n",
      "2025-12-24 01:45:24,415 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:45:24,416 - INFO -   [Mejora Loss] 1.7950 -> 1.7649. Reseteando paciencia.\n",
      "2025-12-24 01:45:24,418 - INFO - Val Loss: 1.7649 Acc: 0.3960\n",
      "2025-12-24 01:45:24,419 - INFO - --- Época 12/250 ---\n",
      "2025-12-24 01:46:17,384 - INFO - Train Loss: 1.9342 Acc: 0.3118  \n",
      "2025-12-24 01:46:18,340 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:46:18,340 - INFO -   [Mejora Loss] 1.7649 -> 1.7612. Reseteando paciencia.\n",
      "2025-12-24 01:46:18,341 - INFO - Val Loss: 1.7612 Acc: 0.3900\n",
      "2025-12-24 01:46:18,342 - INFO - --- Época 13/250 ---\n",
      "2025-12-24 01:47:11,285 - INFO - Train Loss: 1.9059 Acc: 0.3225  \n",
      "2025-12-24 01:47:12,260 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:47:12,262 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:47:12,263 - INFO - Val Loss: 1.7685 Acc: 0.3860\n",
      "2025-12-24 01:47:12,264 - INFO - --- Época 14/250 ---\n",
      "2025-12-24 01:48:05,506 - INFO - Train Loss: 1.8812 Acc: 0.3280  \n",
      "2025-12-24 01:48:06,458 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:48:06,459 - INFO -   [Mejora Loss] 1.7612 -> 1.6901. Reseteando paciencia.\n",
      "2025-12-24 01:48:06,460 - INFO - Val Loss: 1.6901 Acc: 0.3860\n",
      "2025-12-24 01:48:06,461 - INFO - --- Época 15/250 ---\n",
      "2025-12-24 01:48:59,362 - INFO - Train Loss: 1.8544 Acc: 0.3347  \n",
      "2025-12-24 01:49:00,351 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:49:00,352 - INFO -   [Mejora Loss] 1.6901 -> 1.6338. Reseteando paciencia.\n",
      "2025-12-24 01:49:00,353 - INFO - Val Loss: 1.6338 Acc: 0.4380\n",
      "2025-12-24 01:49:00,800 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:49:00,802 - INFO - --- Época 16/250 ---\n",
      "2025-12-24 01:49:54,109 - INFO - Train Loss: 1.8251 Acc: 0.3528  \n",
      "2025-12-24 01:49:55,055 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:49:55,056 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:49:55,057 - INFO - Val Loss: 1.6621 Acc: 0.4220\n",
      "2025-12-24 01:49:55,058 - INFO - --- Época 17/250 ---\n",
      "2025-12-24 01:50:48,378 - INFO - Train Loss: 1.8113 Acc: 0.3595  \n",
      "2025-12-24 01:50:49,324 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:50:49,325 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 01:50:49,326 - INFO - Val Loss: 1.7102 Acc: 0.4060\n",
      "2025-12-24 01:50:49,328 - INFO - --- Época 18/250 ---\n",
      "2025-12-24 01:51:42,643 - INFO - Train Loss: 1.8058 Acc: 0.3678  \n",
      "2025-12-24 01:51:43,608 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:51:43,608 - INFO -   [Mejora Loss] 1.6338 -> 1.5785. Reseteando paciencia.\n",
      "2025-12-24 01:51:43,610 - INFO - Val Loss: 1.5785 Acc: 0.4440\n",
      "2025-12-24 01:51:44,038 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:51:44,039 - INFO - --- Época 19/250 ---\n",
      "2025-12-24 01:52:37,399 - INFO - Train Loss: 1.7542 Acc: 0.3745  \n",
      "2025-12-24 01:52:38,368 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:52:38,369 - INFO -   [Mejora Loss] 1.5785 -> 1.5385. Reseteando paciencia.\n",
      "2025-12-24 01:52:38,370 - INFO - Val Loss: 1.5385 Acc: 0.4660\n",
      "2025-12-24 01:52:38,806 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:52:38,808 - INFO - --- Época 20/250 ---\n",
      "2025-12-24 01:53:31,810 - INFO - Train Loss: 1.7749 Acc: 0.3643  \n",
      "2025-12-24 01:53:32,784 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:53:32,785 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:53:32,786 - INFO - Val Loss: 1.5904 Acc: 0.4500\n",
      "2025-12-24 01:53:32,787 - INFO - --- Época 21/250 ---\n",
      "2025-12-24 01:54:25,729 - INFO - Train Loss: 1.7481 Acc: 0.3840  \n",
      "2025-12-24 01:54:26,705 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:54:26,706 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 01:54:26,707 - INFO - Val Loss: 1.5725 Acc: 0.4380\n",
      "2025-12-24 01:54:26,707 - INFO - --- Época 22/250 ---\n",
      "2025-12-24 01:55:19,854 - INFO - Train Loss: 1.7064 Acc: 0.4155  \n",
      "2025-12-24 01:55:20,834 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:55:20,835 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 01:55:20,836 - INFO - Val Loss: 1.5625 Acc: 0.4680\n",
      "2025-12-24 01:55:21,315 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:55:21,317 - INFO - --- Época 23/250 ---\n",
      "2025-12-24 01:56:14,965 - INFO - Train Loss: 1.7254 Acc: 0.3912  \n",
      "2025-12-24 01:56:15,973 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:56:15,974 - INFO -   [Mejora Loss] 1.5385 -> 1.5220. Reseteando paciencia.\n",
      "2025-12-24 01:56:15,975 - INFO - Val Loss: 1.5220 Acc: 0.4820\n",
      "2025-12-24 01:56:16,398 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 01:56:16,400 - INFO - --- Época 24/250 ---\n",
      "2025-12-24 01:57:10,213 - INFO - Train Loss: 1.7042 Acc: 0.4040  \n",
      "2025-12-24 01:57:11,179 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:57:11,179 - INFO -   [Mejora Loss] 1.5220 -> 1.5128. Reseteando paciencia.\n",
      "2025-12-24 01:57:11,180 - INFO - Val Loss: 1.5128 Acc: 0.4500\n",
      "2025-12-24 01:57:11,181 - INFO - --- Época 25/250 ---\n",
      "2025-12-24 01:58:04,120 - INFO - Train Loss: 1.6692 Acc: 0.4103  \n",
      "2025-12-24 01:58:05,077 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:58:05,078 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:58:05,079 - INFO - Val Loss: 1.5332 Acc: 0.4660\n",
      "2025-12-24 01:58:05,080 - INFO - --- Época 26/250 ---\n",
      "2025-12-24 01:58:57,949 - INFO - Train Loss: 1.6622 Acc: 0.4198  \n",
      "2025-12-24 01:58:58,891 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:58:58,891 - INFO -   [Mejora Loss] 1.5128 -> 1.4828. Reseteando paciencia.\n",
      "2025-12-24 01:58:58,893 - INFO - Val Loss: 1.4828 Acc: 0.4820\n",
      "2025-12-24 01:58:58,893 - INFO - --- Época 27/250 ---\n",
      "2025-12-24 01:59:51,548 - INFO - Train Loss: 1.6742 Acc: 0.4260  \n",
      "2025-12-24 01:59:52,484 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 01:59:52,486 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 01:59:52,487 - INFO - Val Loss: 1.4870 Acc: 0.4780\n",
      "2025-12-24 01:59:52,488 - INFO - --- Época 28/250 ---\n",
      "2025-12-24 02:00:45,487 - INFO - Train Loss: 1.6412 Acc: 0.4245  \n",
      "2025-12-24 02:00:46,458 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:00:46,459 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:00:46,460 - INFO - Val Loss: 1.5262 Acc: 0.4800\n",
      "2025-12-24 02:00:46,461 - INFO - --- Época 29/250 ---\n",
      "2025-12-24 02:01:39,287 - INFO - Train Loss: 1.6405 Acc: 0.4290  \n",
      "2025-12-24 02:01:40,236 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:01:40,237 - INFO -   [Mejora Loss] 1.4828 -> 1.3928. Reseteando paciencia.\n",
      "2025-12-24 02:01:40,239 - INFO - Val Loss: 1.3928 Acc: 0.5180\n",
      "2025-12-24 02:01:40,680 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:01:40,681 - INFO - --- Época 30/250 ---\n",
      "2025-12-24 02:02:34,253 - INFO - Train Loss: 1.6129 Acc: 0.4430  \n",
      "2025-12-24 02:02:35,258 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:02:35,259 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:02:35,260 - INFO - Val Loss: 1.5839 Acc: 0.4440\n",
      "2025-12-24 02:02:35,261 - INFO - --- Época 31/250 ---\n",
      "2025-12-24 02:03:28,236 - INFO - Train Loss: 1.6214 Acc: 0.4353  \n",
      "2025-12-24 02:03:29,190 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:03:29,191 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:03:29,193 - INFO - Val Loss: 1.4058 Acc: 0.5180\n",
      "2025-12-24 02:03:29,195 - INFO - --- Época 32/250 ---\n",
      "2025-12-24 02:04:22,024 - INFO - Train Loss: 1.6030 Acc: 0.4485  \n",
      "2025-12-24 02:04:22,970 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:04:22,971 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 02:04:22,973 - INFO - Val Loss: 1.4034 Acc: 0.5060\n",
      "2025-12-24 02:04:22,974 - INFO - --- Época 33/250 ---\n",
      "2025-12-24 02:05:16,059 - INFO - Train Loss: 1.5882 Acc: 0.4525  \n",
      "2025-12-24 02:05:17,028 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:05:17,029 - INFO -   [Mejora Loss] 1.3928 -> 1.3617. Reseteando paciencia.\n",
      "2025-12-24 02:05:17,031 - INFO - Val Loss: 1.3617 Acc: 0.5300\n",
      "2025-12-24 02:05:17,458 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:05:17,460 - INFO - --- Época 34/250 ---\n",
      "2025-12-24 02:06:10,679 - INFO - Train Loss: 1.5841 Acc: 0.4582  \n",
      "2025-12-24 02:06:11,641 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:06:11,642 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:06:11,643 - INFO - Val Loss: 1.3711 Acc: 0.5320\n",
      "2025-12-24 02:06:12,070 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:06:12,072 - INFO - --- Época 35/250 ---\n",
      "2025-12-24 02:07:05,410 - INFO - Train Loss: 1.5880 Acc: 0.4487  \n",
      "2025-12-24 02:07:06,374 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:07:06,375 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:07:06,376 - INFO - Val Loss: 1.4475 Acc: 0.4880\n",
      "2025-12-24 02:07:06,377 - INFO - --- Época 36/250 ---\n",
      "2025-12-24 02:07:59,663 - INFO - Train Loss: 1.5864 Acc: 0.4562  \n",
      "2025-12-24 02:08:00,636 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:08:00,637 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 02:08:00,638 - INFO - Val Loss: 1.4379 Acc: 0.4820\n",
      "2025-12-24 02:08:00,639 - INFO - --- Época 37/250 ---\n",
      "2025-12-24 02:08:54,374 - INFO - Train Loss: 1.5514 Acc: 0.4630  \n",
      "2025-12-24 02:08:55,351 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:08:55,352 - INFO -   [Mejora Loss] 1.3617 -> 1.3514. Reseteando paciencia.\n",
      "2025-12-24 02:08:55,354 - INFO - Val Loss: 1.3514 Acc: 0.5260\n",
      "2025-12-24 02:08:55,356 - INFO - --- Época 38/250 ---\n",
      "2025-12-24 02:09:49,083 - INFO - Train Loss: 1.5528 Acc: 0.4703  \n",
      "2025-12-24 02:09:50,079 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:09:50,080 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:09:50,081 - INFO - Val Loss: 1.4205 Acc: 0.5060\n",
      "2025-12-24 02:09:50,082 - INFO - --- Época 39/250 ---\n",
      "2025-12-24 02:10:43,643 - INFO - Train Loss: 1.5424 Acc: 0.4695  \n",
      "2025-12-24 02:10:44,655 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:10:44,656 - INFO -   [Mejora Loss] 1.3514 -> 1.3426. Reseteando paciencia.\n",
      "2025-12-24 02:10:44,657 - INFO - Val Loss: 1.3426 Acc: 0.5540\n",
      "2025-12-24 02:10:45,133 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:10:45,136 - INFO - --- Época 40/250 ---\n",
      "2025-12-24 02:11:38,469 - INFO - Train Loss: 1.5371 Acc: 0.4730   \n",
      "2025-12-24 02:11:39,519 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:11:39,520 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:11:39,521 - INFO - Val Loss: 1.3504 Acc: 0.5280\n",
      "2025-12-24 02:11:39,522 - INFO - --- Época 41/250 ---\n",
      "2025-12-24 02:12:32,548 - INFO - Train Loss: 1.5419 Acc: 0.4600  \n",
      "2025-12-24 02:12:33,522 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:12:33,523 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:12:33,525 - INFO - Val Loss: 1.4031 Acc: 0.5140\n",
      "2025-12-24 02:12:33,526 - INFO - --- Época 42/250 ---\n",
      "2025-12-24 02:13:26,785 - INFO - Train Loss: 1.4895 Acc: 0.4868  \n",
      "2025-12-24 02:13:27,744 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:13:27,745 - INFO -   [Mejora Loss] 1.3426 -> 1.2607. Reseteando paciencia.\n",
      "2025-12-24 02:13:27,746 - INFO - Val Loss: 1.2607 Acc: 0.5920\n",
      "2025-12-24 02:13:28,160 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:13:28,161 - INFO - --- Época 43/250 ---\n",
      "2025-12-24 02:14:21,158 - INFO - Train Loss: 1.4947 Acc: 0.4875  \n",
      "2025-12-24 02:14:22,120 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:14:22,121 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:14:22,122 - INFO - Val Loss: 1.3071 Acc: 0.5740\n",
      "2025-12-24 02:14:22,124 - INFO - --- Época 44/250 ---\n",
      "2025-12-24 02:15:15,264 - INFO - Train Loss: 1.4954 Acc: 0.4943  \n",
      "2025-12-24 02:15:16,244 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:15:16,245 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:15:16,247 - INFO - Val Loss: 1.3108 Acc: 0.5480\n",
      "2025-12-24 02:15:16,248 - INFO - --- Época 45/250 ---\n",
      "2025-12-24 02:16:09,363 - INFO - Train Loss: 1.5213 Acc: 0.4825  \n",
      "2025-12-24 02:16:10,360 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:16:10,360 - INFO -   [Mejora Loss] 1.2607 -> 1.2462. Reseteando paciencia.\n",
      "2025-12-24 02:16:10,361 - INFO - Val Loss: 1.2462 Acc: 0.5760\n",
      "2025-12-24 02:16:10,362 - INFO - --- Época 46/250 ---\n",
      "2025-12-24 02:17:03,672 - INFO - Train Loss: 1.4588 Acc: 0.4948  \n",
      "2025-12-24 02:17:04,628 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:17:04,629 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:17:04,630 - INFO - Val Loss: 1.4792 Acc: 0.4580\n",
      "2025-12-24 02:17:04,631 - INFO - --- Época 47/250 ---\n",
      "2025-12-24 02:17:57,684 - INFO - Train Loss: 1.4753 Acc: 0.4990  \n",
      "2025-12-24 02:17:58,670 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:17:58,671 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:17:58,672 - INFO - Val Loss: 1.3677 Acc: 0.5280\n",
      "2025-12-24 02:17:58,674 - INFO - --- Época 48/250 ---\n",
      "2025-12-24 02:18:51,919 - INFO - Train Loss: 1.4569 Acc: 0.5045  \n",
      "2025-12-24 02:18:52,932 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:18:52,933 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 02:18:52,934 - INFO - Val Loss: 1.2482 Acc: 0.5720\n",
      "2025-12-24 02:18:52,935 - INFO - --- Época 49/250 ---\n",
      "2025-12-24 02:19:45,877 - INFO - Train Loss: 1.4744 Acc: 0.5070  \n",
      "2025-12-24 02:19:46,841 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:19:46,842 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 02:19:46,843 - INFO - Val Loss: 1.3120 Acc: 0.5480\n",
      "2025-12-24 02:19:46,845 - INFO - --- Época 50/250 ---\n",
      "2025-12-24 02:20:40,192 - INFO - Train Loss: 1.4848 Acc: 0.4930  \n",
      "2025-12-24 02:20:41,148 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:20:41,149 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 02:20:41,150 - INFO - Val Loss: 1.2837 Acc: 0.5480\n",
      "2025-12-24 02:20:41,151 - INFO - --- Época 51/250 ---\n",
      "2025-12-24 02:21:34,364 - INFO - Train Loss: 1.4402 Acc: 0.5100  \n",
      "2025-12-24 02:21:35,359 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:21:35,360 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 02:21:35,361 - INFO - Val Loss: 1.2769 Acc: 0.5720\n",
      "2025-12-24 02:21:35,362 - INFO - --- Época 52/250 ---\n",
      "2025-12-24 02:22:28,545 - INFO - Train Loss: 1.4439 Acc: 0.4983  \n",
      "2025-12-24 02:22:29,558 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:22:29,558 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 02:22:29,559 - INFO - Val Loss: 1.2875 Acc: 0.5840\n",
      "2025-12-24 02:22:29,560 - INFO - --- Época 53/250 ---\n",
      "2025-12-24 02:23:23,398 - INFO - Train Loss: 1.4472 Acc: 0.5055  \n",
      "2025-12-24 02:23:24,395 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:23:24,396 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 02:23:24,397 - INFO - Val Loss: 1.3079 Acc: 0.5380\n",
      "2025-12-24 02:23:24,398 - INFO - --- Época 54/250 ---\n",
      "2025-12-24 02:24:18,458 - INFO - Train Loss: 1.4216 Acc: 0.5148  \n",
      "2025-12-24 02:24:19,453 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:24:19,454 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 02:24:19,455 - INFO - Val Loss: 1.2743 Acc: 0.5340\n",
      "2025-12-24 02:24:19,456 - INFO - --- Época 55/250 ---\n",
      "2025-12-24 02:25:13,442 - INFO - Train Loss: 1.4326 Acc: 0.5145  \n",
      "2025-12-24 02:25:14,401 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:25:14,402 - INFO -   [Mejora Loss] 1.2462 -> 1.2302. Reseteando paciencia.\n",
      "2025-12-24 02:25:14,403 - INFO - Val Loss: 1.2302 Acc: 0.5760\n",
      "2025-12-24 02:25:14,405 - INFO - --- Época 56/250 ---\n",
      "2025-12-24 02:26:07,748 - INFO - Train Loss: 1.4064 Acc: 0.5142  \n",
      "2025-12-24 02:26:08,715 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:26:08,716 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:26:08,717 - INFO - Val Loss: 1.2367 Acc: 0.5740\n",
      "2025-12-24 02:26:08,718 - INFO - --- Época 57/250 ---\n",
      "2025-12-24 02:27:02,442 - INFO - Train Loss: 1.4276 Acc: 0.5170  \n",
      "2025-12-24 02:27:03,398 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:27:03,399 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:27:03,400 - INFO - Val Loss: 1.5179 Acc: 0.4860\n",
      "2025-12-24 02:27:03,401 - INFO - --- Época 58/250 ---\n",
      "2025-12-24 02:27:56,786 - INFO - Train Loss: 1.4249 Acc: 0.5140  \n",
      "2025-12-24 02:27:57,731 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:27:57,732 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 02:27:57,733 - INFO - Val Loss: 1.2627 Acc: 0.5760\n",
      "2025-12-24 02:27:57,734 - INFO - --- Época 59/250 ---\n",
      "2025-12-24 02:28:51,371 - INFO - Train Loss: 1.4301 Acc: 0.5212  \n",
      "2025-12-24 02:28:52,360 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:28:52,361 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 02:28:52,362 - INFO - Val Loss: 1.3329 Acc: 0.5400\n",
      "2025-12-24 02:28:52,363 - INFO - --- Época 60/250 ---\n",
      "2025-12-24 02:29:46,092 - INFO - Train Loss: 1.4200 Acc: 0.5162  \n",
      "2025-12-24 02:29:47,063 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:29:47,064 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 02:29:47,065 - INFO - Val Loss: 1.2698 Acc: 0.5880\n",
      "2025-12-24 02:29:47,066 - INFO - --- Época 61/250 ---\n",
      "2025-12-24 02:30:40,721 - INFO - Train Loss: 1.3900 Acc: 0.5248  \n",
      "2025-12-24 02:30:41,693 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:30:41,694 - INFO -   [Mejora Loss] 1.2302 -> 1.2262. Reseteando paciencia.\n",
      "2025-12-24 02:30:41,696 - INFO - Val Loss: 1.2262 Acc: 0.5860\n",
      "2025-12-24 02:30:41,698 - INFO - --- Época 62/250 ---\n",
      "2025-12-24 02:31:35,870 - INFO - Train Loss: 1.3701 Acc: 0.5278   \n",
      "2025-12-24 02:31:36,884 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:31:36,885 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:31:36,886 - INFO - Val Loss: 1.4049 Acc: 0.5400\n",
      "2025-12-24 02:31:36,888 - INFO - --- Época 63/250 ---\n",
      "2025-12-24 02:32:31,027 - INFO - Train Loss: 1.4009 Acc: 0.5290  \n",
      "2025-12-24 02:32:32,007 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:32:32,008 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:32:32,009 - INFO - Val Loss: 1.2771 Acc: 0.5400\n",
      "2025-12-24 02:32:32,011 - INFO - --- Época 64/250 ---\n",
      "2025-12-24 02:33:26,045 - INFO - Train Loss: 1.3865 Acc: 0.5295   \n",
      "2025-12-24 02:33:27,049 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:33:27,050 - INFO -   [Mejora Loss] 1.2262 -> 1.2145. Reseteando paciencia.\n",
      "2025-12-24 02:33:27,051 - INFO - Val Loss: 1.2145 Acc: 0.5840\n",
      "2025-12-24 02:33:27,052 - INFO - --- Época 65/250 ---\n",
      "2025-12-24 02:34:20,842 - INFO - Train Loss: 1.3656 Acc: 0.5345   \n",
      "2025-12-24 02:34:21,874 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:34:21,875 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:34:21,876 - INFO - Val Loss: 1.2538 Acc: 0.5700\n",
      "2025-12-24 02:34:21,877 - INFO - --- Época 66/250 ---\n",
      "2025-12-24 02:35:15,796 - INFO - Train Loss: 1.3865 Acc: 0.5242   \n",
      "2025-12-24 02:35:16,831 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:35:16,831 - INFO -   [Mejora Loss] 1.2145 -> 1.1752. Reseteando paciencia.\n",
      "2025-12-24 02:35:16,832 - INFO - Val Loss: 1.1752 Acc: 0.5860\n",
      "2025-12-24 02:35:16,833 - INFO - --- Época 67/250 ---\n",
      "2025-12-24 02:36:11,289 - INFO - Train Loss: 1.3540 Acc: 0.5435  \n",
      "2025-12-24 02:36:12,361 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:36:12,363 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:36:12,365 - INFO - Val Loss: 1.2508 Acc: 0.5720\n",
      "2025-12-24 02:36:12,366 - INFO - --- Época 68/250 ---\n",
      "2025-12-24 02:37:06,479 - INFO - Train Loss: 1.3969 Acc: 0.5255  \n",
      "2025-12-24 02:37:07,521 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:37:07,522 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:37:07,523 - INFO - Val Loss: 1.2766 Acc: 0.5760\n",
      "2025-12-24 02:37:07,524 - INFO - --- Época 69/250 ---\n",
      "2025-12-24 02:38:01,630 - INFO - Train Loss: 1.3522 Acc: 0.5425  \n",
      "2025-12-24 02:38:02,640 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:38:02,641 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 02:38:02,642 - INFO - Val Loss: 1.2451 Acc: 0.5660\n",
      "2025-12-24 02:38:02,643 - INFO - --- Época 70/250 ---\n",
      "2025-12-24 02:38:56,929 - INFO - Train Loss: 1.3571 Acc: 0.5383  \n",
      "2025-12-24 02:38:57,927 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:38:57,928 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 02:38:57,929 - INFO - Val Loss: 1.2136 Acc: 0.6020\n",
      "2025-12-24 02:38:58,394 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:38:58,396 - INFO - --- Época 71/250 ---\n",
      "2025-12-24 02:39:52,722 - INFO - Train Loss: 1.3577 Acc: 0.5423  \n",
      "2025-12-24 02:39:53,762 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:39:53,763 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 02:39:53,764 - INFO - Val Loss: 1.2276 Acc: 0.5820\n",
      "2025-12-24 02:39:53,765 - INFO - --- Época 72/250 ---\n",
      "2025-12-24 02:40:47,956 - INFO - Train Loss: 1.3355 Acc: 0.5405  \n",
      "2025-12-24 02:40:48,967 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:40:48,967 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 02:40:48,969 - INFO - Val Loss: 1.2272 Acc: 0.5800\n",
      "2025-12-24 02:40:48,969 - INFO - --- Época 73/250 ---\n",
      "2025-12-24 02:41:43,331 - INFO - Train Loss: 1.3421 Acc: 0.5487  \n",
      "2025-12-24 02:41:44,309 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:41:44,310 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 02:41:44,311 - INFO - Val Loss: 1.2772 Acc: 0.5860\n",
      "2025-12-24 02:41:44,312 - INFO - --- Época 74/250 ---\n",
      "2025-12-24 02:42:38,294 - INFO - Train Loss: 1.3298 Acc: 0.5375   \n",
      "2025-12-24 02:42:39,377 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:42:39,378 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 02:42:39,379 - INFO - Val Loss: 1.2973 Acc: 0.5320\n",
      "2025-12-24 02:42:39,380 - INFO - --- Época 75/250 ---\n",
      "2025-12-24 02:43:33,437 - INFO - Train Loss: 1.3286 Acc: 0.5547   \n",
      "2025-12-24 02:43:34,532 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:43:34,533 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 02:43:34,533 - INFO - Val Loss: 1.1900 Acc: 0.5740\n",
      "2025-12-24 02:43:34,535 - INFO - --- Época 76/250 ---\n",
      "2025-12-24 02:44:29,225 - INFO - Train Loss: 1.3227 Acc: 0.5510   \n",
      "2025-12-24 02:44:30,238 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2025-12-24 02:44:30,238 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 02:44:30,239 - INFO - Val Loss: 1.2405 Acc: 0.5840\n",
      "2025-12-24 02:44:30,241 - INFO - --- Época 77/250 ---\n",
      "2025-12-24 02:45:24,571 - INFO - Train Loss: 1.3224 Acc: 0.5467   \n",
      "2025-12-24 02:45:25,651 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:45:25,652 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2025-12-24 02:45:25,652 - INFO - Val Loss: 1.2737 Acc: 0.5740\n",
      "2025-12-24 02:45:25,653 - INFO - --- Época 78/250 ---\n",
      "2025-12-24 02:46:19,835 - INFO - Train Loss: 1.2755 Acc: 0.5675   \n",
      "2025-12-24 02:46:20,949 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:46:20,951 - INFO -   [Mejora Loss] 1.1752 -> 1.1200. Reseteando paciencia.\n",
      "2025-12-24 02:46:20,952 - INFO - Val Loss: 1.1200 Acc: 0.6100\n",
      "2025-12-24 02:46:21,366 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:46:21,369 - INFO - --- Época 79/250 ---\n",
      "2025-12-24 02:47:15,775 - INFO - Train Loss: 1.2585 Acc: 0.5865   \n",
      "2025-12-24 02:47:16,794 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:47:16,796 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:47:16,798 - INFO - Val Loss: 1.1440 Acc: 0.5920\n",
      "2025-12-24 02:47:16,799 - INFO - --- Época 80/250 ---\n",
      "2025-12-24 02:48:11,351 - INFO - Train Loss: 1.2536 Acc: 0.5830   \n",
      "2025-12-24 02:48:12,362 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:48:12,362 - INFO -   [Mejora Loss] 1.1200 -> 1.1062. Reseteando paciencia.\n",
      "2025-12-24 02:48:12,363 - INFO - Val Loss: 1.1062 Acc: 0.6160\n",
      "2025-12-24 02:48:12,763 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:48:12,764 - INFO - --- Época 81/250 ---\n",
      "2025-12-24 02:49:07,269 - INFO - Train Loss: 1.2377 Acc: 0.5827   \n",
      "2025-12-24 02:49:08,314 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:49:08,314 - INFO -   [Mejora Loss] 1.1062 -> 1.1029. Reseteando paciencia.\n",
      "2025-12-24 02:49:08,316 - INFO - Val Loss: 1.1029 Acc: 0.6400\n",
      "2025-12-24 02:49:08,748 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 02:49:08,750 - INFO - --- Época 82/250 ---\n",
      "2025-12-24 02:50:03,366 - INFO - Train Loss: 1.2209 Acc: 0.5857   \n",
      "2025-12-24 02:50:04,388 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:50:04,389 - INFO -   [Mejora Loss] 1.1029 -> 1.0968. Reseteando paciencia.\n",
      "2025-12-24 02:50:04,390 - INFO - Val Loss: 1.0968 Acc: 0.6260\n",
      "2025-12-24 02:50:04,391 - INFO - --- Época 83/250 ---\n",
      "2025-12-24 02:50:58,341 - INFO - Train Loss: 1.2217 Acc: 0.5923   \n",
      "2025-12-24 02:50:59,401 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:50:59,403 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:50:59,404 - INFO - Val Loss: 1.1331 Acc: 0.6280\n",
      "2025-12-24 02:50:59,405 - INFO - --- Época 84/250 ---\n",
      "2025-12-24 02:51:53,679 - INFO - Train Loss: 1.2159 Acc: 0.5897   \n",
      "2025-12-24 02:51:54,757 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:51:54,758 - INFO -   [Mejora Loss] 1.0968 -> 1.0930. Reseteando paciencia.\n",
      "2025-12-24 02:51:54,759 - INFO - Val Loss: 1.0930 Acc: 0.6240\n",
      "2025-12-24 02:51:54,760 - INFO - --- Época 85/250 ---\n",
      "2025-12-24 02:52:49,005 - INFO - Train Loss: 1.2305 Acc: 0.5745   \n",
      "2025-12-24 02:52:50,029 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:52:50,030 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:52:50,031 - INFO - Val Loss: 1.1843 Acc: 0.5940\n",
      "2025-12-24 02:52:50,032 - INFO - --- Época 86/250 ---\n",
      "2025-12-24 02:53:44,199 - INFO - Train Loss: 1.2229 Acc: 0.5883   \n",
      "2025-12-24 02:53:45,225 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:53:45,226 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:53:45,227 - INFO - Val Loss: 1.1148 Acc: 0.5720\n",
      "2025-12-24 02:53:45,228 - INFO - --- Época 87/250 ---\n",
      "2025-12-24 02:54:39,505 - INFO - Train Loss: 1.2120 Acc: 0.5945   \n",
      "2025-12-24 02:54:40,479 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:54:40,480 - INFO -   [Mejora Loss] 1.0930 -> 1.0886. Reseteando paciencia.\n",
      "2025-12-24 02:54:40,481 - INFO - Val Loss: 1.0886 Acc: 0.6280\n",
      "2025-12-24 02:54:40,482 - INFO - --- Época 88/250 ---\n",
      "2025-12-24 02:55:35,236 - INFO - Train Loss: 1.1907 Acc: 0.6018   \n",
      "2025-12-24 02:55:36,211 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:55:36,212 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 02:55:36,213 - INFO - Val Loss: 1.1402 Acc: 0.5940\n",
      "2025-12-24 02:55:36,214 - INFO - --- Época 89/250 ---\n",
      "2025-12-24 02:56:31,155 - INFO - Train Loss: 1.2091 Acc: 0.5920   \n",
      "2025-12-24 02:56:32,227 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:56:32,229 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 02:56:32,230 - INFO - Val Loss: 1.0930 Acc: 0.6200\n",
      "2025-12-24 02:56:32,231 - INFO - --- Época 90/250 ---\n",
      "2025-12-24 02:57:26,700 - INFO - Train Loss: 1.2009 Acc: 0.5893   \n",
      "2025-12-24 02:57:27,718 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:57:27,719 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 02:57:27,720 - INFO - Val Loss: 1.1070 Acc: 0.6340\n",
      "2025-12-24 02:57:27,721 - INFO - --- Época 91/250 ---\n",
      "2025-12-24 02:58:22,155 - INFO - Train Loss: 1.1803 Acc: 0.6088   \n",
      "2025-12-24 02:58:23,169 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:58:23,172 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 02:58:23,173 - INFO - Val Loss: 1.1592 Acc: 0.5900\n",
      "2025-12-24 02:58:23,176 - INFO - --- Época 92/250 ---\n",
      "2025-12-24 02:59:17,214 - INFO - Train Loss: 1.1905 Acc: 0.6008   \n",
      "2025-12-24 02:59:18,212 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 02:59:18,213 - INFO -   [Mejora Loss] 1.0886 -> 1.0758. Reseteando paciencia.\n",
      "2025-12-24 02:59:18,214 - INFO - Val Loss: 1.0758 Acc: 0.6260\n",
      "2025-12-24 02:59:18,214 - INFO - --- Época 93/250 ---\n",
      "2025-12-24 03:00:12,442 - INFO - Train Loss: 1.1653 Acc: 0.6165   \n",
      "2025-12-24 03:00:13,487 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:00:13,488 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:00:13,489 - INFO - Val Loss: 1.1111 Acc: 0.6200\n",
      "2025-12-24 03:00:13,490 - INFO - --- Época 94/250 ---\n",
      "2025-12-24 03:01:07,770 - INFO - Train Loss: 1.1858 Acc: 0.6000   \n",
      "2025-12-24 03:01:08,796 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:01:08,797 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 03:01:08,797 - INFO - Val Loss: 1.0813 Acc: 0.6400\n",
      "2025-12-24 03:01:08,798 - INFO - --- Época 95/250 ---\n",
      "2025-12-24 03:02:03,503 - INFO - Train Loss: 1.1901 Acc: 0.6020   \n",
      "2025-12-24 03:02:04,519 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:02:04,520 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 03:02:04,521 - INFO - Val Loss: 1.0978 Acc: 0.6240\n",
      "2025-12-24 03:02:04,522 - INFO - --- Época 96/250 ---\n",
      "2025-12-24 03:02:58,764 - INFO - Train Loss: 1.1644 Acc: 0.6078   \n",
      "2025-12-24 03:02:59,777 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:02:59,778 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 03:02:59,779 - INFO - Val Loss: 1.1770 Acc: 0.5880\n",
      "2025-12-24 03:02:59,781 - INFO - --- Época 97/250 ---\n",
      "2025-12-24 03:03:54,092 - INFO - Train Loss: 1.1855 Acc: 0.5980   \n",
      "2025-12-24 03:03:55,231 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:03:55,232 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 03:03:55,233 - INFO - Val Loss: 1.1019 Acc: 0.6340\n",
      "2025-12-24 03:03:55,234 - INFO - --- Época 98/250 ---\n",
      "2025-12-24 03:04:49,937 - INFO - Train Loss: 1.1676 Acc: 0.6030   \n",
      "2025-12-24 03:04:50,992 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:04:50,992 - INFO -   [Mejora Loss] 1.0758 -> 1.0577. Reseteando paciencia.\n",
      "2025-12-24 03:04:50,993 - INFO - Val Loss: 1.0577 Acc: 0.6520\n",
      "2025-12-24 03:04:51,416 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:04:51,417 - INFO - --- Época 99/250 ---\n",
      "2025-12-24 03:05:45,759 - INFO - Train Loss: 1.1748 Acc: 0.6033   \n",
      "2025-12-24 03:05:46,776 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:05:46,777 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:05:46,778 - INFO - Val Loss: 1.0753 Acc: 0.6340\n",
      "2025-12-24 03:05:46,779 - INFO - --- Época 100/250 ---\n",
      "2025-12-24 03:06:41,132 - INFO - Train Loss: 1.1457 Acc: 0.6148   \n",
      "2025-12-24 03:06:42,134 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:06:42,135 - INFO -   [Mejora Loss] 1.0577 -> 1.0434. Reseteando paciencia.\n",
      "2025-12-24 03:06:42,136 - INFO - Val Loss: 1.0434 Acc: 0.6400\n",
      "2025-12-24 03:06:42,137 - INFO - --- Época 101/250 ---\n",
      "2025-12-24 03:07:36,705 - INFO - Train Loss: 1.1365 Acc: 0.6188   \n",
      "2025-12-24 03:07:37,698 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:07:37,699 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:07:37,700 - INFO - Val Loss: 1.0610 Acc: 0.6300\n",
      "2025-12-24 03:07:37,701 - INFO - --- Época 102/250 ---\n",
      "2025-12-24 03:08:32,246 - INFO - Train Loss: 1.1436 Acc: 0.6178   \n",
      "2025-12-24 03:08:33,281 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:08:33,281 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 03:08:33,282 - INFO - Val Loss: 1.1549 Acc: 0.5760\n",
      "2025-12-24 03:08:33,283 - INFO - --- Época 103/250 ---\n",
      "2025-12-24 03:09:28,195 - INFO - Train Loss: 1.1473 Acc: 0.6160   \n",
      "2025-12-24 03:09:29,286 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:09:29,287 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 03:09:29,288 - INFO - Val Loss: 1.0571 Acc: 0.6180\n",
      "2025-12-24 03:09:29,289 - INFO - --- Época 104/250 ---\n",
      "2025-12-24 03:10:23,687 - INFO - Train Loss: 1.1600 Acc: 0.6078   \n",
      "2025-12-24 03:10:24,707 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:10:24,708 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 03:10:24,709 - INFO - Val Loss: 1.1045 Acc: 0.6140\n",
      "2025-12-24 03:10:24,710 - INFO - --- Época 105/250 ---\n",
      "2025-12-24 03:11:18,705 - INFO - Train Loss: 1.1520 Acc: 0.6158   \n",
      "2025-12-24 03:11:19,736 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:11:19,737 - INFO -   [Mejora Loss] 1.0434 -> 1.0181. Reseteando paciencia.\n",
      "2025-12-24 03:11:19,738 - INFO - Val Loss: 1.0181 Acc: 0.6540\n",
      "2025-12-24 03:11:20,160 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:11:20,161 - INFO - --- Época 106/250 ---\n",
      "2025-12-24 03:12:15,077 - INFO - Train Loss: 1.1263 Acc: 0.6210   \n",
      "2025-12-24 03:12:16,098 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:12:16,098 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:12:16,100 - INFO - Val Loss: 1.0743 Acc: 0.6260\n",
      "2025-12-24 03:12:16,101 - INFO - --- Época 107/250 ---\n",
      "2025-12-24 03:13:10,837 - INFO - Train Loss: 1.1355 Acc: 0.6215   \n",
      "2025-12-24 03:13:11,892 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:13:11,893 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 03:13:11,894 - INFO - Val Loss: 1.1069 Acc: 0.6220\n",
      "2025-12-24 03:13:11,894 - INFO - --- Época 108/250 ---\n",
      "2025-12-24 03:14:06,039 - INFO - Train Loss: 1.1210 Acc: 0.6192   \n",
      "2025-12-24 03:14:07,064 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:14:07,064 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 03:14:07,065 - INFO - Val Loss: 1.0457 Acc: 0.6500\n",
      "2025-12-24 03:14:07,066 - INFO - --- Época 109/250 ---\n",
      "2025-12-24 03:15:00,885 - INFO - Train Loss: 1.1421 Acc: 0.6220   \n",
      "2025-12-24 03:15:01,921 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:15:01,922 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 03:15:01,923 - INFO - Val Loss: 1.0265 Acc: 0.6420\n",
      "2025-12-24 03:15:01,924 - INFO - --- Época 110/250 ---\n",
      "2025-12-24 03:15:55,856 - INFO - Train Loss: 1.1141 Acc: 0.6300   \n",
      "2025-12-24 03:15:56,900 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:15:56,901 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 03:15:56,902 - INFO - Val Loss: 1.0580 Acc: 0.6360\n",
      "2025-12-24 03:15:56,903 - INFO - --- Época 111/250 ---\n",
      "2025-12-24 03:16:51,532 - INFO - Train Loss: 1.1195 Acc: 0.6152   \n",
      "2025-12-24 03:16:52,564 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:16:52,565 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 03:16:52,566 - INFO - Val Loss: 1.0432 Acc: 0.6340\n",
      "2025-12-24 03:16:52,567 - INFO - --- Época 112/250 ---\n",
      "2025-12-24 03:17:46,987 - INFO - Train Loss: 1.1104 Acc: 0.6265   \n",
      "2025-12-24 03:17:48,025 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:17:48,026 - INFO -   [Mejora Loss] 1.0181 -> 1.0036. Reseteando paciencia.\n",
      "2025-12-24 03:17:48,026 - INFO - Val Loss: 1.0036 Acc: 0.6420\n",
      "2025-12-24 03:17:48,027 - INFO - --- Época 113/250 ---\n",
      "2025-12-24 03:18:41,782 - INFO - Train Loss: 1.1104 Acc: 0.6318   \n",
      "2025-12-24 03:18:42,864 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:18:42,865 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:18:42,867 - INFO - Val Loss: 1.0416 Acc: 0.6580\n",
      "2025-12-24 03:18:43,294 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:18:43,296 - INFO - --- Época 114/250 ---\n",
      "2025-12-24 03:19:37,891 - INFO - Train Loss: 1.1031 Acc: 0.6330   \n",
      "2025-12-24 03:19:38,943 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:19:38,944 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 03:19:38,945 - INFO - Val Loss: 1.0715 Acc: 0.6460\n",
      "2025-12-24 03:19:38,946 - INFO - --- Época 115/250 ---\n",
      "2025-12-24 03:20:33,178 - INFO - Train Loss: 1.1232 Acc: 0.6310   \n",
      "2025-12-24 03:20:34,186 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:20:34,187 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 03:20:34,189 - INFO - Val Loss: 1.0889 Acc: 0.6060\n",
      "2025-12-24 03:20:34,191 - INFO - --- Época 116/250 ---\n",
      "2025-12-24 03:21:28,863 - INFO - Train Loss: 1.1116 Acc: 0.6290   \n",
      "2025-12-24 03:21:29,877 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:21:29,878 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 03:21:29,879 - INFO - Val Loss: 1.0696 Acc: 0.6300\n",
      "2025-12-24 03:21:29,879 - INFO - --- Época 117/250 ---\n",
      "2025-12-24 03:22:24,236 - INFO - Train Loss: 1.1077 Acc: 0.6322   \n",
      "2025-12-24 03:22:25,276 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:22:25,276 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 03:22:25,277 - INFO - Val Loss: 1.0428 Acc: 0.6340\n",
      "2025-12-24 03:22:25,278 - INFO - --- Época 118/250 ---\n",
      "2025-12-24 03:23:20,227 - INFO - Train Loss: 1.1179 Acc: 0.6252   \n",
      "2025-12-24 03:23:21,256 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:23:21,257 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 03:23:21,258 - INFO - Val Loss: 1.0519 Acc: 0.6520\n",
      "2025-12-24 03:23:21,259 - INFO - --- Época 119/250 ---\n",
      "2025-12-24 03:24:15,633 - INFO - Train Loss: 1.1041 Acc: 0.6280   \n",
      "2025-12-24 03:24:16,707 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:24:16,708 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 03:24:16,709 - INFO - Val Loss: 1.0310 Acc: 0.6340\n",
      "2025-12-24 03:24:16,710 - INFO - --- Época 120/250 ---\n",
      "2025-12-24 03:25:10,999 - INFO - Train Loss: 1.1121 Acc: 0.6360   \n",
      "2025-12-24 03:25:12,060 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:25:12,062 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 03:25:12,063 - INFO - Val Loss: 1.0551 Acc: 0.6320\n",
      "2025-12-24 03:25:12,066 - INFO - --- Época 121/250 ---\n",
      "2025-12-24 03:26:06,171 - INFO - Train Loss: 1.0852 Acc: 0.6342   \n",
      "2025-12-24 03:26:07,182 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:26:07,183 - INFO -   [Mejora Loss] 1.0036 -> 0.9742. Reseteando paciencia.\n",
      "2025-12-24 03:26:07,184 - INFO - Val Loss: 0.9742 Acc: 0.6620\n",
      "2025-12-24 03:26:07,649 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:26:07,651 - INFO - --- Época 122/250 ---\n",
      "2025-12-24 03:27:02,270 - INFO - Train Loss: 1.1024 Acc: 0.6310   \n",
      "2025-12-24 03:27:03,324 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:27:03,326 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:27:03,327 - INFO - Val Loss: 1.0953 Acc: 0.6160\n",
      "2025-12-24 03:27:03,328 - INFO - --- Época 123/250 ---\n",
      "2025-12-24 03:27:57,553 - INFO - Train Loss: 1.0923 Acc: 0.6350   \n",
      "2025-12-24 03:27:58,590 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:27:58,590 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 03:27:58,592 - INFO - Val Loss: 1.1174 Acc: 0.5960\n",
      "2025-12-24 03:27:58,593 - INFO - --- Época 124/250 ---\n",
      "2025-12-24 03:28:53,495 - INFO - Train Loss: 1.0699 Acc: 0.6332   \n",
      "2025-12-24 03:28:54,548 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:28:54,549 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 03:28:54,551 - INFO - Val Loss: 1.0538 Acc: 0.6440\n",
      "2025-12-24 03:28:54,552 - INFO - --- Época 125/250 ---\n",
      "2025-12-24 03:29:48,921 - INFO - Train Loss: 1.0653 Acc: 0.6485   \n",
      "2025-12-24 03:29:49,943 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:29:49,943 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 03:29:49,944 - INFO - Val Loss: 1.0636 Acc: 0.6540\n",
      "2025-12-24 03:29:49,945 - INFO - --- Época 126/250 ---\n",
      "2025-12-24 03:30:45,052 - INFO - Train Loss: 1.0720 Acc: 0.6412   \n",
      "2025-12-24 03:30:46,080 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:30:46,081 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 03:30:46,082 - INFO - Val Loss: 1.0234 Acc: 0.6300\n",
      "2025-12-24 03:30:46,083 - INFO - --- Época 127/250 ---\n",
      "2025-12-24 03:31:40,795 - INFO - Train Loss: 1.0581 Acc: 0.6455   \n",
      "2025-12-24 03:31:41,813 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:31:41,814 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 03:31:41,815 - INFO - Val Loss: 1.0048 Acc: 0.6560\n",
      "2025-12-24 03:31:41,817 - INFO - --- Época 128/250 ---\n",
      "2025-12-24 03:32:36,594 - INFO - Train Loss: 1.0791 Acc: 0.6388   \n",
      "2025-12-24 03:32:37,607 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:32:37,607 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 03:32:37,608 - INFO - Val Loss: 1.0337 Acc: 0.6340\n",
      "2025-12-24 03:32:37,609 - INFO - --- Época 129/250 ---\n",
      "2025-12-24 03:33:32,054 - INFO - Train Loss: 1.0579 Acc: 0.6515   \n",
      "2025-12-24 03:33:33,134 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:33:33,135 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 03:33:33,135 - INFO - Val Loss: 1.0432 Acc: 0.6260\n",
      "2025-12-24 03:33:33,136 - INFO - --- Época 130/250 ---\n",
      "2025-12-24 03:34:27,458 - INFO - Train Loss: 1.0550 Acc: 0.6478   \n",
      "2025-12-24 03:34:28,494 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:34:28,496 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 03:34:28,497 - INFO - Val Loss: 1.0561 Acc: 0.6440\n",
      "2025-12-24 03:34:28,498 - INFO - --- Época 131/250 ---\n",
      "2025-12-24 03:35:22,913 - INFO - Train Loss: 1.0803 Acc: 0.6368   \n",
      "2025-12-24 03:35:23,930 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2025-12-24 03:35:23,931 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 03:35:23,932 - INFO - Val Loss: 1.0377 Acc: 0.6440\n",
      "2025-12-24 03:35:23,933 - INFO - --- Época 132/250 ---\n",
      "2025-12-24 03:36:18,539 - INFO - Train Loss: 1.0322 Acc: 0.6573   \n",
      "2025-12-24 03:36:19,576 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:36:19,577 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2025-12-24 03:36:19,578 - INFO - Val Loss: 1.0806 Acc: 0.6360\n",
      "2025-12-24 03:36:19,579 - INFO - --- Época 133/250 ---\n",
      "2025-12-24 03:37:14,021 - INFO - Train Loss: 1.0103 Acc: 0.6655   \n",
      "2025-12-24 03:37:15,045 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:37:15,046 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2025-12-24 03:37:15,047 - INFO - Val Loss: 0.9902 Acc: 0.6580\n",
      "2025-12-24 03:37:15,048 - INFO - --- Época 134/250 ---\n",
      "2025-12-24 03:38:09,323 - INFO - Train Loss: 1.0208 Acc: 0.6580   \n",
      "2025-12-24 03:38:10,338 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:38:10,339 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2025-12-24 03:38:10,340 - INFO - Val Loss: 0.9869 Acc: 0.6480\n",
      "2025-12-24 03:38:10,341 - INFO - --- Época 135/250 ---\n",
      "2025-12-24 03:39:04,306 - INFO - Train Loss: 1.0142 Acc: 0.6638   \n",
      "2025-12-24 03:39:05,337 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:39:05,338 - INFO -   [Mejora Loss] 0.9742 -> 0.9741. Reseteando paciencia.\n",
      "2025-12-24 03:39:05,339 - INFO - Val Loss: 0.9741 Acc: 0.6640\n",
      "2025-12-24 03:39:05,759 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:39:05,761 - INFO - --- Época 136/250 ---\n",
      "2025-12-24 03:39:59,963 - INFO - Train Loss: 0.9855 Acc: 0.6695   \n",
      "2025-12-24 03:40:00,986 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:40:00,987 - INFO -   [Mejora Loss] 0.9741 -> 0.9249. Reseteando paciencia.\n",
      "2025-12-24 03:40:00,988 - INFO - Val Loss: 0.9249 Acc: 0.6720\n",
      "2025-12-24 03:40:01,381 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:40:01,383 - INFO - --- Época 137/250 ---\n",
      "2025-12-24 03:40:55,457 - INFO - Train Loss: 0.9806 Acc: 0.6608   \n",
      "2025-12-24 03:40:56,470 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:40:56,471 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:40:56,472 - INFO - Val Loss: 0.9526 Acc: 0.6620\n",
      "2025-12-24 03:40:56,474 - INFO - --- Época 138/250 ---\n",
      "2025-12-24 03:41:50,325 - INFO - Train Loss: 0.9714 Acc: 0.6773   \n",
      "2025-12-24 03:41:51,369 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:41:51,370 - INFO -   [Mejora Loss] 0.9249 -> 0.9193. Reseteando paciencia.\n",
      "2025-12-24 03:41:51,371 - INFO - Val Loss: 0.9193 Acc: 0.6800\n",
      "2025-12-24 03:41:51,797 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:41:51,799 - INFO - --- Época 139/250 ---\n",
      "2025-12-24 03:42:46,008 - INFO - Train Loss: 0.9657 Acc: 0.6807   \n",
      "2025-12-24 03:42:47,072 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:42:47,073 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:42:47,076 - INFO - Val Loss: 1.0007 Acc: 0.6300\n",
      "2025-12-24 03:42:47,077 - INFO - --- Época 140/250 ---\n",
      "2025-12-24 03:43:41,525 - INFO - Train Loss: 0.9604 Acc: 0.6757   \n",
      "2025-12-24 03:43:42,595 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:43:42,596 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 03:43:42,597 - INFO - Val Loss: 0.9590 Acc: 0.6520\n",
      "2025-12-24 03:43:42,598 - INFO - --- Época 141/250 ---\n",
      "2025-12-24 03:44:37,205 - INFO - Train Loss: 0.9613 Acc: 0.6783   \n",
      "2025-12-24 03:44:38,269 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:44:38,270 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 03:44:38,271 - INFO - Val Loss: 1.0082 Acc: 0.6520\n",
      "2025-12-24 03:44:38,272 - INFO - --- Época 142/250 ---\n",
      "2025-12-24 03:45:33,068 - INFO - Train Loss: 0.9632 Acc: 0.6795   \n",
      "2025-12-24 03:45:34,097 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:45:34,097 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 03:45:34,098 - INFO - Val Loss: 0.9564 Acc: 0.6640\n",
      "2025-12-24 03:45:34,099 - INFO - --- Época 143/250 ---\n",
      "2025-12-24 03:46:28,717 - INFO - Train Loss: 0.9614 Acc: 0.6760   \n",
      "2025-12-24 03:46:29,776 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:46:29,776 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 03:46:29,778 - INFO - Val Loss: 1.0070 Acc: 0.6480\n",
      "2025-12-24 03:46:29,779 - INFO - --- Época 144/250 ---\n",
      "2025-12-24 03:47:24,293 - INFO - Train Loss: 0.9671 Acc: 0.6723   \n",
      "2025-12-24 03:47:25,318 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:47:25,319 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 03:47:25,320 - INFO - Val Loss: 0.9683 Acc: 0.6720\n",
      "2025-12-24 03:47:25,321 - INFO - --- Época 145/250 ---\n",
      "2025-12-24 03:48:19,838 - INFO - Train Loss: 0.9665 Acc: 0.6735   \n",
      "2025-12-24 03:48:20,926 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:48:20,927 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 03:48:20,928 - INFO - Val Loss: 0.9725 Acc: 0.6600\n",
      "2025-12-24 03:48:20,929 - INFO - --- Época 146/250 ---\n",
      "2025-12-24 03:49:15,936 - INFO - Train Loss: 0.9479 Acc: 0.6787   \n",
      "2025-12-24 03:49:16,933 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:49:16,934 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 03:49:16,935 - INFO - Val Loss: 0.9526 Acc: 0.6760\n",
      "2025-12-24 03:49:16,936 - INFO - --- Época 147/250 ---\n",
      "2025-12-24 03:50:12,037 - INFO - Train Loss: 0.9503 Acc: 0.6770   \n",
      "2025-12-24 03:50:13,047 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:50:13,048 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 03:50:13,049 - INFO - Val Loss: 0.9790 Acc: 0.6660\n",
      "2025-12-24 03:50:13,049 - INFO - --- Época 148/250 ---\n",
      "2025-12-24 03:51:07,969 - INFO - Train Loss: 0.9499 Acc: 0.6813   \n",
      "2025-12-24 03:51:09,002 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2025-12-24 03:51:09,002 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 03:51:09,003 - INFO - Val Loss: 0.9888 Acc: 0.6640\n",
      "2025-12-24 03:51:09,004 - INFO - --- Época 149/250 ---\n",
      "2025-12-24 03:52:03,908 - INFO - Train Loss: 0.9646 Acc: 0.6763   \n",
      "2025-12-24 03:52:04,947 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:52:04,948 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2025-12-24 03:52:04,948 - INFO - Val Loss: 0.9664 Acc: 0.6700\n",
      "2025-12-24 03:52:04,949 - INFO - --- Época 150/250 ---\n",
      "2025-12-24 03:52:59,815 - INFO - Train Loss: 0.9412 Acc: 0.6827   \n",
      "2025-12-24 03:53:00,850 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:53:00,850 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2025-12-24 03:53:00,851 - INFO - Val Loss: 0.9431 Acc: 0.6720\n",
      "2025-12-24 03:53:00,852 - INFO - --- Época 151/250 ---\n",
      "2025-12-24 03:53:55,726 - INFO - Train Loss: 0.9321 Acc: 0.6847   \n",
      "2025-12-24 03:53:56,771 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:53:56,772 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2025-12-24 03:53:56,773 - INFO - Val Loss: 0.9346 Acc: 0.6860\n",
      "2025-12-24 03:53:57,247 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:53:57,249 - INFO - --- Época 152/250 ---\n",
      "2025-12-24 03:54:52,036 - INFO - Train Loss: 0.9103 Acc: 0.6937   \n",
      "2025-12-24 03:54:53,046 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:54:53,046 - INFO -   [Sin mejora Loss] Paciencia: 14/50\n",
      "2025-12-24 03:54:53,047 - INFO - Val Loss: 0.9370 Acc: 0.6840\n",
      "2025-12-24 03:54:53,048 - INFO - --- Época 153/250 ---\n",
      "2025-12-24 03:55:47,486 - INFO - Train Loss: 0.8928 Acc: 0.7027   \n",
      "2025-12-24 03:55:48,544 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:55:48,544 - INFO -   [Sin mejora Loss] Paciencia: 15/50\n",
      "2025-12-24 03:55:48,545 - INFO - Val Loss: 0.9200 Acc: 0.6880\n",
      "2025-12-24 03:55:48,995 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:55:48,997 - INFO - --- Época 154/250 ---\n",
      "2025-12-24 03:56:43,326 - INFO - Train Loss: 0.8949 Acc: 0.7005   \n",
      "2025-12-24 03:56:44,369 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:56:44,371 - INFO -   [Mejora Loss] 0.9193 -> 0.9140. Reseteando paciencia.\n",
      "2025-12-24 03:56:44,372 - INFO - Val Loss: 0.9140 Acc: 0.6920\n",
      "2025-12-24 03:56:44,791 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 03:56:44,792 - INFO - --- Época 155/250 ---\n",
      "2025-12-24 03:57:39,611 - INFO - Train Loss: 0.9135 Acc: 0.7037   \n",
      "2025-12-24 03:57:40,688 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:57:40,690 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 03:57:40,691 - INFO - Val Loss: 0.9275 Acc: 0.6860\n",
      "2025-12-24 03:57:40,692 - INFO - --- Época 156/250 ---\n",
      "2025-12-24 03:58:35,282 - INFO - Train Loss: 0.8977 Acc: 0.6975   \n",
      "2025-12-24 03:58:36,284 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:58:36,284 - INFO -   [Mejora Loss] 0.9140 -> 0.9117. Reseteando paciencia.\n",
      "2025-12-24 03:58:36,285 - INFO - Val Loss: 0.9117 Acc: 0.6920\n",
      "2025-12-24 03:58:36,286 - INFO - --- Época 157/250 ---\n",
      "2025-12-24 03:59:30,786 - INFO - Train Loss: 0.9188 Acc: 0.6993   \n",
      "2025-12-24 03:59:31,827 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 03:59:31,827 - INFO -   [Mejora Loss] 0.9117 -> 0.9115. Reseteando paciencia.\n",
      "2025-12-24 03:59:31,828 - INFO - Val Loss: 0.9115 Acc: 0.6880\n",
      "2025-12-24 03:59:31,830 - INFO - --- Época 158/250 ---\n",
      "2025-12-24 04:00:26,123 - INFO - Train Loss: 0.8998 Acc: 0.6970   \n",
      "2025-12-24 04:00:27,178 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:00:27,178 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:00:27,179 - INFO - Val Loss: 0.9158 Acc: 0.6920\n",
      "2025-12-24 04:00:27,180 - INFO - --- Época 159/250 ---\n",
      "2025-12-24 04:01:21,665 - INFO - Train Loss: 0.8828 Acc: 0.7033   \n",
      "2025-12-24 04:01:22,763 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:01:22,764 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:01:22,764 - INFO - Val Loss: 0.9171 Acc: 0.6820\n",
      "2025-12-24 04:01:22,767 - INFO - --- Época 160/250 ---\n",
      "2025-12-24 04:02:17,639 - INFO - Train Loss: 0.8867 Acc: 0.7055   \n",
      "2025-12-24 04:02:18,642 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:02:18,643 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 04:02:18,644 - INFO - Val Loss: 0.9432 Acc: 0.6780\n",
      "2025-12-24 04:02:18,646 - INFO - --- Época 161/250 ---\n",
      "2025-12-24 04:03:13,063 - INFO - Train Loss: 0.8888 Acc: 0.6975   \n",
      "2025-12-24 04:03:14,075 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:03:14,076 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 04:03:14,077 - INFO - Val Loss: 0.9204 Acc: 0.6920\n",
      "2025-12-24 04:03:14,078 - INFO - --- Época 162/250 ---\n",
      "2025-12-24 04:04:08,688 - INFO - Train Loss: 0.8763 Acc: 0.6997   \n",
      "2025-12-24 04:04:09,758 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:04:09,758 - INFO -   [Mejora Loss] 0.9115 -> 0.9093. Reseteando paciencia.\n",
      "2025-12-24 04:04:09,759 - INFO - Val Loss: 0.9093 Acc: 0.6920\n",
      "2025-12-24 04:04:09,760 - INFO - --- Época 163/250 ---\n",
      "2025-12-24 04:05:03,869 - INFO - Train Loss: 0.8780 Acc: 0.7027   \n",
      "2025-12-24 04:05:04,885 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:05:04,886 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:05:04,887 - INFO - Val Loss: 0.9411 Acc: 0.6880\n",
      "2025-12-24 04:05:04,888 - INFO - --- Época 164/250 ---\n",
      "2025-12-24 04:05:59,242 - INFO - Train Loss: 0.8763 Acc: 0.7065   \n",
      "2025-12-24 04:06:00,297 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:06:00,297 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:06:00,298 - INFO - Val Loss: 0.9220 Acc: 0.6840\n",
      "2025-12-24 04:06:00,299 - INFO - --- Época 165/250 ---\n",
      "2025-12-24 04:06:54,803 - INFO - Train Loss: 0.8696 Acc: 0.7033   \n",
      "2025-12-24 04:06:55,841 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:06:55,842 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 04:06:55,843 - INFO - Val Loss: 0.9273 Acc: 0.6880\n",
      "2025-12-24 04:06:55,845 - INFO - --- Época 166/250 ---\n",
      "2025-12-24 04:07:49,994 - INFO - Train Loss: 0.8756 Acc: 0.7087   \n",
      "2025-12-24 04:07:50,987 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:07:50,988 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 04:07:50,990 - INFO - Val Loss: 0.9265 Acc: 0.6760\n",
      "2025-12-24 04:07:50,991 - INFO - --- Época 167/250 ---\n",
      "2025-12-24 04:08:45,210 - INFO - Train Loss: 0.8674 Acc: 0.7133   \n",
      "2025-12-24 04:08:46,232 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:08:46,234 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 04:08:46,235 - INFO - Val Loss: 0.9233 Acc: 0.6940\n",
      "2025-12-24 04:08:46,682 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 04:08:46,684 - INFO - --- Época 168/250 ---\n",
      "2025-12-24 04:09:41,685 - INFO - Train Loss: 0.8820 Acc: 0.7055   \n",
      "2025-12-24 04:09:42,763 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:09:42,765 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 04:09:42,766 - INFO - Val Loss: 0.9096 Acc: 0.6960\n",
      "2025-12-24 04:09:43,214 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 04:09:43,216 - INFO - --- Época 169/250 ---\n",
      "2025-12-24 04:10:37,988 - INFO - Train Loss: 0.8729 Acc: 0.7053   \n",
      "2025-12-24 04:10:38,987 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:10:38,988 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 04:10:38,989 - INFO - Val Loss: 0.9269 Acc: 0.6780\n",
      "2025-12-24 04:10:38,990 - INFO - --- Época 170/250 ---\n",
      "2025-12-24 04:11:33,405 - INFO - Train Loss: 0.8503 Acc: 0.7103   \n",
      "2025-12-24 04:11:34,460 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:11:34,461 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 04:11:34,462 - INFO - Val Loss: 0.9156 Acc: 0.7000\n",
      "2025-12-24 04:11:34,887 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 04:11:34,889 - INFO - --- Época 171/250 ---\n",
      "2025-12-24 04:12:29,332 - INFO - Train Loss: 0.8658 Acc: 0.7100   \n",
      "2025-12-24 04:12:30,347 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:12:30,348 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 04:12:30,349 - INFO - Val Loss: 0.9219 Acc: 0.6800\n",
      "2025-12-24 04:12:30,350 - INFO - --- Época 172/250 ---\n",
      "2025-12-24 04:13:24,915 - INFO - Train Loss: 0.8712 Acc: 0.7027   \n",
      "2025-12-24 04:13:25,943 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2025-12-24 04:13:25,944 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 04:13:25,946 - INFO - Val Loss: 0.9197 Acc: 0.6920\n",
      "2025-12-24 04:13:25,947 - INFO - --- Época 173/250 ---\n",
      "2025-12-24 04:14:20,291 - INFO - Train Loss: 0.8706 Acc: 0.7065   \n",
      "2025-12-24 04:14:21,355 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:14:21,356 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2025-12-24 04:14:21,357 - INFO - Val Loss: 0.9608 Acc: 0.6820\n",
      "2025-12-24 04:14:21,358 - INFO - --- Época 174/250 ---\n",
      "2025-12-24 04:15:15,699 - INFO - Train Loss: 0.8284 Acc: 0.7205   \n",
      "2025-12-24 04:15:16,705 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:15:16,706 - INFO -   [Mejora Loss] 0.9093 -> 0.9047. Reseteando paciencia.\n",
      "2025-12-24 04:15:16,707 - INFO - Val Loss: 0.9047 Acc: 0.6980\n",
      "2025-12-24 04:15:16,708 - INFO - --- Época 175/250 ---\n",
      "2025-12-24 04:16:11,359 - INFO - Train Loss: 0.8453 Acc: 0.7163   \n",
      "2025-12-24 04:16:12,423 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:16:12,424 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:16:12,426 - INFO - Val Loss: 0.9055 Acc: 0.6900\n",
      "2025-12-24 04:16:12,427 - INFO - --- Época 176/250 ---\n",
      "2025-12-24 04:17:06,952 - INFO - Train Loss: 0.8305 Acc: 0.7150   \n",
      "2025-12-24 04:17:08,018 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:17:08,019 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:17:08,019 - INFO - Val Loss: 0.9100 Acc: 0.6900\n",
      "2025-12-24 04:17:08,020 - INFO - --- Época 177/250 ---\n",
      "2025-12-24 04:18:02,275 - INFO - Train Loss: 0.8346 Acc: 0.7250   \n",
      "2025-12-24 04:18:03,322 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:18:03,323 - INFO -   [Mejora Loss] 0.9047 -> 0.8979. Reseteando paciencia.\n",
      "2025-12-24 04:18:03,324 - INFO - Val Loss: 0.8979 Acc: 0.6980\n",
      "2025-12-24 04:18:03,325 - INFO - --- Época 178/250 ---\n",
      "2025-12-24 04:18:58,183 - INFO - Train Loss: 0.8534 Acc: 0.7153   \n",
      "2025-12-24 04:18:59,215 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:18:59,216 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:18:59,216 - INFO - Val Loss: 0.9042 Acc: 0.6960\n",
      "2025-12-24 04:18:59,217 - INFO - --- Época 179/250 ---\n",
      "2025-12-24 04:19:53,598 - INFO - Train Loss: 0.8281 Acc: 0.7195   \n",
      "2025-12-24 04:19:54,617 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:19:54,618 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:19:54,619 - INFO - Val Loss: 0.9020 Acc: 0.6980\n",
      "2025-12-24 04:19:54,620 - INFO - --- Época 180/250 ---\n",
      "2025-12-24 04:20:49,431 - INFO - Train Loss: 0.8205 Acc: 0.7240   \n",
      "2025-12-24 04:20:50,483 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:20:50,484 - INFO -   [Mejora Loss] 0.8979 -> 0.8948. Reseteando paciencia.\n",
      "2025-12-24 04:20:50,485 - INFO - Val Loss: 0.8948 Acc: 0.6940\n",
      "2025-12-24 04:20:50,486 - INFO - --- Época 181/250 ---\n",
      "2025-12-24 04:21:44,955 - INFO - Train Loss: 0.8356 Acc: 0.7175   \n",
      "2025-12-24 04:21:46,021 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:21:46,022 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:21:46,023 - INFO - Val Loss: 0.9115 Acc: 0.6940\n",
      "2025-12-24 04:21:46,024 - INFO - --- Época 182/250 ---\n",
      "2025-12-24 04:22:40,606 - INFO - Train Loss: 0.8262 Acc: 0.7210   \n",
      "2025-12-24 04:22:41,699 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:22:41,700 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:22:41,701 - INFO - Val Loss: 0.9036 Acc: 0.6940\n",
      "2025-12-24 04:22:41,702 - INFO - --- Época 183/250 ---\n",
      "2025-12-24 04:23:36,091 - INFO - Train Loss: 0.8106 Acc: 0.7278   \n",
      "2025-12-24 04:23:37,101 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:23:37,101 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 04:23:37,102 - INFO - Val Loss: 0.8963 Acc: 0.6980\n",
      "2025-12-24 04:23:37,103 - INFO - --- Época 184/250 ---\n",
      "2025-12-24 04:24:31,586 - INFO - Train Loss: 0.8401 Acc: 0.7153   \n",
      "2025-12-24 04:24:32,590 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:24:32,591 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 04:24:32,592 - INFO - Val Loss: 0.9019 Acc: 0.7000\n",
      "2025-12-24 04:24:32,592 - INFO - --- Época 185/250 ---\n",
      "2025-12-24 04:25:27,343 - INFO - Train Loss: 0.8368 Acc: 0.7228   \n",
      "2025-12-24 04:25:28,400 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:25:28,400 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 04:25:28,401 - INFO - Val Loss: 0.9041 Acc: 0.6740\n",
      "2025-12-24 04:25:28,402 - INFO - --- Época 186/250 ---\n",
      "2025-12-24 04:26:22,953 - INFO - Train Loss: 0.8283 Acc: 0.7258   \n",
      "2025-12-24 04:26:23,958 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:26:23,959 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 04:26:23,960 - INFO - Val Loss: 0.9015 Acc: 0.7000\n",
      "2025-12-24 04:26:23,961 - INFO - --- Época 187/250 ---\n",
      "2025-12-24 04:27:18,600 - INFO - Train Loss: 0.8155 Acc: 0.7238   \n",
      "2025-12-24 04:27:19,620 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:27:19,621 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 04:27:19,622 - INFO - Val Loss: 0.8978 Acc: 0.6960\n",
      "2025-12-24 04:27:19,623 - INFO - --- Época 188/250 ---\n",
      "2025-12-24 04:28:14,389 - INFO - Train Loss: 0.8198 Acc: 0.7225   \n",
      "2025-12-24 04:28:15,425 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:28:15,427 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 04:28:15,428 - INFO - Val Loss: 0.8952 Acc: 0.7040\n",
      "2025-12-24 04:28:15,835 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 04:28:15,837 - INFO - --- Época 189/250 ---\n",
      "2025-12-24 04:29:10,587 - INFO - Train Loss: 0.8318 Acc: 0.7260   \n",
      "2025-12-24 04:29:11,619 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:29:11,619 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 04:29:11,620 - INFO - Val Loss: 0.9049 Acc: 0.7120\n",
      "2025-12-24 04:29:12,079 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\best_model.pth\n",
      "2025-12-24 04:29:12,081 - INFO - --- Época 190/250 ---\n",
      "2025-12-24 04:30:06,895 - INFO - Train Loss: 0.8380 Acc: 0.7145   \n",
      "2025-12-24 04:30:07,924 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2025-12-24 04:30:07,925 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 04:30:07,927 - INFO - Val Loss: 0.9037 Acc: 0.6920\n",
      "2025-12-24 04:30:07,927 - INFO - --- Época 191/250 ---\n",
      "2025-12-24 04:31:02,609 - INFO - Train Loss: 0.8220 Acc: 0.7163   \n",
      "2025-12-24 04:31:03,665 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:31:03,666 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2025-12-24 04:31:03,667 - INFO - Val Loss: 0.9049 Acc: 0.6960\n",
      "2025-12-24 04:31:03,668 - INFO - --- Época 192/250 ---\n",
      "2025-12-24 04:31:58,299 - INFO - Train Loss: 0.8131 Acc: 0.7193   \n",
      "2025-12-24 04:31:59,299 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:31:59,300 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2025-12-24 04:31:59,301 - INFO - Val Loss: 0.9010 Acc: 0.6800\n",
      "2025-12-24 04:31:59,302 - INFO - --- Época 193/250 ---\n",
      "2025-12-24 04:32:53,680 - INFO - Train Loss: 0.8133 Acc: 0.7283   \n",
      "2025-12-24 04:32:54,708 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:32:54,709 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2025-12-24 04:32:54,710 - INFO - Val Loss: 0.9027 Acc: 0.6860\n",
      "2025-12-24 04:32:54,711 - INFO - --- Época 194/250 ---\n",
      "2025-12-24 04:33:48,998 - INFO - Train Loss: 0.8125 Acc: 0.7235   \n",
      "2025-12-24 04:33:49,994 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:33:49,995 - INFO -   [Sin mejora Loss] Paciencia: 14/50\n",
      "2025-12-24 04:33:49,997 - INFO - Val Loss: 0.9004 Acc: 0.6880\n",
      "2025-12-24 04:33:49,998 - INFO - --- Época 195/250 ---\n",
      "2025-12-24 04:34:44,566 - INFO - Train Loss: 0.8037 Acc: 0.7303   \n",
      "2025-12-24 04:34:45,575 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:34:45,576 - INFO -   [Sin mejora Loss] Paciencia: 15/50\n",
      "2025-12-24 04:34:45,578 - INFO - Val Loss: 0.9105 Acc: 0.6800\n",
      "2025-12-24 04:34:45,580 - INFO - --- Época 196/250 ---\n",
      "2025-12-24 04:35:40,391 - INFO - Train Loss: 0.8094 Acc: 0.7255   \n",
      "2025-12-24 04:35:41,444 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:35:41,445 - INFO -   [Sin mejora Loss] Paciencia: 16/50\n",
      "2025-12-24 04:35:41,446 - INFO - Val Loss: 0.9009 Acc: 0.6840\n",
      "2025-12-24 04:35:41,447 - INFO - --- Época 197/250 ---\n",
      "2025-12-24 04:36:35,923 - INFO - Train Loss: 0.8029 Acc: 0.7230   \n",
      "2025-12-24 04:36:36,925 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:36:36,926 - INFO -   [Sin mejora Loss] Paciencia: 17/50\n",
      "2025-12-24 04:36:36,927 - INFO - Val Loss: 0.8973 Acc: 0.6960\n",
      "2025-12-24 04:36:36,928 - INFO - --- Época 198/250 ---\n",
      "2025-12-24 04:37:31,757 - INFO - Train Loss: 0.8047 Acc: 0.7215   \n",
      "2025-12-24 04:37:32,803 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:37:32,804 - INFO -   [Mejora Loss] 0.8948 -> 0.8944. Reseteando paciencia.\n",
      "2025-12-24 04:37:32,806 - INFO - Val Loss: 0.8944 Acc: 0.6900\n",
      "2025-12-24 04:37:32,807 - INFO - --- Época 199/250 ---\n",
      "2025-12-24 04:38:27,461 - INFO - Train Loss: 0.8057 Acc: 0.7265   \n",
      "2025-12-24 04:38:28,505 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:38:28,505 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:38:28,506 - INFO - Val Loss: 0.8959 Acc: 0.6900\n",
      "2025-12-24 04:38:28,508 - INFO - --- Época 200/250 ---\n",
      "2025-12-24 04:39:23,047 - INFO - Train Loss: 0.7969 Acc: 0.7375   \n",
      "2025-12-24 04:39:24,041 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:39:24,041 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:39:24,043 - INFO - Val Loss: 0.8986 Acc: 0.6880\n",
      "2025-12-24 04:39:24,044 - INFO - --- Época 201/250 ---\n",
      "2025-12-24 04:40:18,857 - INFO - Train Loss: 0.7972 Acc: 0.7318   \n",
      "2025-12-24 04:40:19,906 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:40:19,907 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 04:40:19,909 - INFO - Val Loss: 0.8988 Acc: 0.6940\n",
      "2025-12-24 04:40:19,910 - INFO - --- Época 202/250 ---\n",
      "2025-12-24 04:41:14,321 - INFO - Train Loss: 0.7980 Acc: 0.7313   \n",
      "2025-12-24 04:41:15,352 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:41:15,353 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 04:41:15,354 - INFO - Val Loss: 0.8984 Acc: 0.6940\n",
      "2025-12-24 04:41:15,355 - INFO - --- Época 203/250 ---\n",
      "2025-12-24 04:42:09,777 - INFO - Train Loss: 0.8082 Acc: 0.7335   \n",
      "2025-12-24 04:42:10,781 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:42:10,782 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 04:42:10,783 - INFO - Val Loss: 0.8970 Acc: 0.6840\n",
      "2025-12-24 04:42:10,785 - INFO - --- Época 204/250 ---\n",
      "2025-12-24 04:43:05,028 - INFO - Train Loss: 0.7976 Acc: 0.7273   \n",
      "2025-12-24 04:43:06,064 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:43:06,064 - INFO -   [Mejora Loss] 0.8944 -> 0.8943. Reseteando paciencia.\n",
      "2025-12-24 04:43:06,066 - INFO - Val Loss: 0.8943 Acc: 0.6940\n",
      "2025-12-24 04:43:06,067 - INFO - --- Época 205/250 ---\n",
      "2025-12-24 04:44:00,712 - INFO - Train Loss: 0.8012 Acc: 0.7165   \n",
      "2025-12-24 04:44:01,809 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:44:01,809 - INFO -   [Mejora Loss] 0.8943 -> 0.8878. Reseteando paciencia.\n",
      "2025-12-24 04:44:01,810 - INFO - Val Loss: 0.8878 Acc: 0.6960\n",
      "2025-12-24 04:44:01,811 - INFO - --- Época 206/250 ---\n",
      "2025-12-24 04:44:56,728 - INFO - Train Loss: 0.7995 Acc: 0.7313   \n",
      "2025-12-24 04:44:57,776 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:44:57,776 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:44:57,777 - INFO - Val Loss: 0.8958 Acc: 0.6960\n",
      "2025-12-24 04:44:57,778 - INFO - --- Época 207/250 ---\n",
      "2025-12-24 04:45:52,190 - INFO - Train Loss: 0.7788 Acc: 0.7358   \n",
      "2025-12-24 04:45:53,238 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:45:53,239 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:45:53,240 - INFO - Val Loss: 0.8892 Acc: 0.7000\n",
      "2025-12-24 04:45:53,240 - INFO - --- Época 208/250 ---\n",
      "2025-12-24 04:46:47,865 - INFO - Train Loss: 0.7953 Acc: 0.7278   \n",
      "2025-12-24 04:46:48,902 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:46:48,903 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 04:46:48,904 - INFO - Val Loss: 0.8971 Acc: 0.6940\n",
      "2025-12-24 04:46:48,906 - INFO - --- Época 209/250 ---\n",
      "2025-12-24 04:47:43,402 - INFO - Train Loss: 0.7911 Acc: 0.7325   \n",
      "2025-12-24 04:47:44,436 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:47:44,437 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 04:47:44,438 - INFO - Val Loss: 0.8943 Acc: 0.6960\n",
      "2025-12-24 04:47:44,439 - INFO - --- Época 210/250 ---\n",
      "2025-12-24 04:48:39,140 - INFO - Train Loss: 0.8051 Acc: 0.7313   \n",
      "2025-12-24 04:48:40,221 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:48:40,221 - INFO -   [Mejora Loss] 0.8878 -> 0.8870. Reseteando paciencia.\n",
      "2025-12-24 04:48:40,222 - INFO - Val Loss: 0.8870 Acc: 0.6960\n",
      "2025-12-24 04:48:40,223 - INFO - --- Época 211/250 ---\n",
      "2025-12-24 04:49:34,770 - INFO - Train Loss: 0.8100 Acc: 0.7263   \n",
      "2025-12-24 04:49:35,821 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:49:35,822 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 04:49:35,824 - INFO - Val Loss: 0.8974 Acc: 0.6960\n",
      "2025-12-24 04:49:35,825 - INFO - --- Época 212/250 ---\n",
      "2025-12-24 04:50:29,973 - INFO - Train Loss: 0.8071 Acc: 0.7293   \n",
      "2025-12-24 04:50:31,013 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:50:31,014 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 04:50:31,014 - INFO - Val Loss: 0.8902 Acc: 0.6920\n",
      "2025-12-24 04:50:31,016 - INFO - --- Época 213/250 ---\n",
      "2025-12-24 04:51:25,890 - INFO - Train Loss: 0.7919 Acc: 0.7325   \n",
      "2025-12-24 04:51:26,925 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:51:26,925 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 04:51:26,926 - INFO - Val Loss: 0.8947 Acc: 0.7020\n",
      "2025-12-24 04:51:26,927 - INFO - --- Época 214/250 ---\n",
      "2025-12-24 04:52:21,615 - INFO - Train Loss: 0.8022 Acc: 0.7270   \n",
      "2025-12-24 04:52:22,664 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:52:22,665 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 04:52:22,666 - INFO - Val Loss: 0.8893 Acc: 0.6960\n",
      "2025-12-24 04:52:22,667 - INFO - --- Época 215/250 ---\n",
      "2025-12-24 04:53:17,411 - INFO - Train Loss: 0.8012 Acc: 0.7303   \n",
      "2025-12-24 04:53:18,429 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:53:18,429 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 04:53:18,430 - INFO - Val Loss: 0.8904 Acc: 0.7020\n",
      "2025-12-24 04:53:18,431 - INFO - --- Época 216/250 ---\n",
      "2025-12-24 04:54:12,894 - INFO - Train Loss: 0.7844 Acc: 0.7290   \n",
      "2025-12-24 04:54:13,906 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:54:13,907 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 04:54:13,908 - INFO - Val Loss: 0.8880 Acc: 0.6940\n",
      "2025-12-24 04:54:13,910 - INFO - --- Época 217/250 ---\n",
      "2025-12-24 04:55:08,223 - INFO - Train Loss: 0.8018 Acc: 0.7228   \n",
      "2025-12-24 04:55:09,229 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:55:09,230 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 04:55:09,230 - INFO - Val Loss: 0.8913 Acc: 0.6940\n",
      "2025-12-24 04:55:09,231 - INFO - --- Época 218/250 ---\n",
      "2025-12-24 04:56:03,880 - INFO - Train Loss: 0.8014 Acc: 0.7320   \n",
      "2025-12-24 04:56:04,928 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:56:04,929 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 04:56:04,930 - INFO - Val Loss: 0.8872 Acc: 0.7060\n",
      "2025-12-24 04:56:04,931 - INFO - --- Época 219/250 ---\n",
      "2025-12-24 04:56:59,671 - INFO - Train Loss: 0.7979 Acc: 0.7285   \n",
      "2025-12-24 04:57:00,721 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:57:00,723 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 04:57:00,724 - INFO - Val Loss: 0.8914 Acc: 0.6900\n",
      "2025-12-24 04:57:00,725 - INFO - --- Época 220/250 ---\n",
      "2025-12-24 04:57:54,864 - INFO - Train Loss: 0.7961 Acc: 0.7298   \n",
      "2025-12-24 04:57:55,879 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2025-12-24 04:57:55,880 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 04:57:55,881 - INFO - Val Loss: 0.8932 Acc: 0.7000\n",
      "2025-12-24 04:57:55,882 - INFO - --- Época 221/250 ---\n",
      "2025-12-24 04:58:50,306 - INFO - Train Loss: 0.7913 Acc: 0.7213   \n",
      "2025-12-24 04:58:51,325 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 04:58:51,325 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2025-12-24 04:58:51,326 - INFO - Val Loss: 0.8990 Acc: 0.6820\n",
      "2025-12-24 04:58:51,327 - INFO - --- Época 222/250 ---\n",
      "2025-12-24 04:59:45,973 - INFO - Train Loss: 0.7816 Acc: 0.7355   \n",
      "2025-12-24 04:59:47,011 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 04:59:47,012 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2025-12-24 04:59:47,013 - INFO - Val Loss: 0.8938 Acc: 0.6880\n",
      "2025-12-24 04:59:47,014 - INFO - --- Época 223/250 ---\n",
      "2025-12-24 05:00:41,247 - INFO - Train Loss: 0.7909 Acc: 0.7345   \n",
      "2025-12-24 05:00:42,245 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:00:42,246 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2025-12-24 05:00:42,247 - INFO - Val Loss: 0.8876 Acc: 0.6920\n",
      "2025-12-24 05:00:42,248 - INFO - --- Época 224/250 ---\n",
      "2025-12-24 05:01:36,490 - INFO - Train Loss: 0.7826 Acc: 0.7318   \n",
      "2025-12-24 05:01:37,541 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:01:37,543 - INFO -   [Sin mejora Loss] Paciencia: 14/50\n",
      "2025-12-24 05:01:37,544 - INFO - Val Loss: 0.8927 Acc: 0.6920\n",
      "2025-12-24 05:01:37,547 - INFO - --- Época 225/250 ---\n",
      "2025-12-24 05:02:31,760 - INFO - Train Loss: 0.8062 Acc: 0.7268   \n",
      "2025-12-24 05:02:32,800 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:02:32,801 - INFO -   [Sin mejora Loss] Paciencia: 15/50\n",
      "2025-12-24 05:02:32,802 - INFO - Val Loss: 0.8901 Acc: 0.6920\n",
      "2025-12-24 05:02:32,803 - INFO - --- Época 226/250 ---\n",
      "2025-12-24 05:03:27,417 - INFO - Train Loss: 0.7817 Acc: 0.7340   \n",
      "2025-12-24 05:03:28,437 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:03:28,438 - INFO -   [Sin mejora Loss] Paciencia: 16/50\n",
      "2025-12-24 05:03:28,438 - INFO - Val Loss: 0.8876 Acc: 0.6960\n",
      "2025-12-24 05:03:28,439 - INFO - --- Época 227/250 ---\n",
      "2025-12-24 05:04:22,978 - INFO - Train Loss: 0.7756 Acc: 0.7353   \n",
      "2025-12-24 05:04:24,019 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:04:24,020 - INFO -   [Mejora Loss] 0.8870 -> 0.8861. Reseteando paciencia.\n",
      "2025-12-24 05:04:24,021 - INFO - Val Loss: 0.8861 Acc: 0.6920\n",
      "2025-12-24 05:04:24,023 - INFO - --- Época 228/250 ---\n",
      "2025-12-24 05:05:18,634 - INFO - Train Loss: 0.7770 Acc: 0.7360   \n",
      "2025-12-24 05:05:19,608 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:05:19,609 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 05:05:19,610 - INFO - Val Loss: 0.8871 Acc: 0.6940\n",
      "2025-12-24 05:05:19,611 - INFO - --- Época 229/250 ---\n",
      "2025-12-24 05:06:13,769 - INFO - Train Loss: 0.7848 Acc: 0.7360   \n",
      "2025-12-24 05:06:14,770 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:06:14,771 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 05:06:14,771 - INFO - Val Loss: 0.8937 Acc: 0.6900\n",
      "2025-12-24 05:06:14,773 - INFO - --- Época 230/250 ---\n",
      "2025-12-24 05:07:09,260 - INFO - Train Loss: 0.7849 Acc: 0.7392   \n",
      "2025-12-24 05:07:10,265 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:07:10,266 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 05:07:10,267 - INFO - Val Loss: 0.8901 Acc: 0.6860\n",
      "2025-12-24 05:07:10,269 - INFO - --- Época 231/250 ---\n",
      "2025-12-24 05:08:04,402 - INFO - Train Loss: 0.7882 Acc: 0.7390   \n",
      "2025-12-24 05:08:05,486 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:08:05,487 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 05:08:05,488 - INFO - Val Loss: 0.8880 Acc: 0.6880\n",
      "2025-12-24 05:08:05,489 - INFO - --- Época 232/250 ---\n",
      "2025-12-24 05:09:00,256 - INFO - Train Loss: 0.7757 Acc: 0.7365   \n",
      "2025-12-24 05:09:01,259 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:09:01,260 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 05:09:01,261 - INFO - Val Loss: 0.8915 Acc: 0.6880\n",
      "2025-12-24 05:09:01,263 - INFO - --- Época 233/250 ---\n",
      "2025-12-24 05:09:55,830 - INFO - Train Loss: 0.7675 Acc: 0.7348   \n",
      "2025-12-24 05:09:56,885 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:09:56,886 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 05:09:56,887 - INFO - Val Loss: 0.8926 Acc: 0.6880\n",
      "2025-12-24 05:09:56,888 - INFO - --- Época 234/250 ---\n",
      "2025-12-24 05:10:51,900 - INFO - Train Loss: 0.7964 Acc: 0.7260   \n",
      "2025-12-24 05:10:52,937 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:10:52,938 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 05:10:52,939 - INFO - Val Loss: 0.8907 Acc: 0.6860\n",
      "2025-12-24 05:10:52,940 - INFO - --- Época 235/250 ---\n",
      "2025-12-24 05:11:47,189 - INFO - Train Loss: 0.7738 Acc: 0.7375   \n",
      "2025-12-24 05:11:48,215 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:11:48,216 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 05:11:48,219 - INFO - Val Loss: 0.8865 Acc: 0.6920\n",
      "2025-12-24 05:11:48,220 - INFO - --- Época 236/250 ---\n",
      "2025-12-24 05:12:42,726 - INFO - Train Loss: 0.7689 Acc: 0.7390   \n",
      "2025-12-24 05:12:43,712 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:12:43,713 - INFO -   [Mejora Loss] 0.8861 -> 0.8856. Reseteando paciencia.\n",
      "2025-12-24 05:12:43,714 - INFO - Val Loss: 0.8856 Acc: 0.6920\n",
      "2025-12-24 05:12:43,715 - INFO - --- Época 237/250 ---\n",
      "2025-12-24 05:13:37,756 - INFO - Train Loss: 0.7768 Acc: 0.7315   \n",
      "2025-12-24 05:13:38,773 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:13:38,773 - INFO -   [Mejora Loss] 0.8856 -> 0.8825. Reseteando paciencia.\n",
      "2025-12-24 05:13:38,775 - INFO - Val Loss: 0.8825 Acc: 0.6920\n",
      "2025-12-24 05:13:38,776 - INFO - --- Época 238/250 ---\n",
      "2025-12-24 05:14:32,705 - INFO - Train Loss: 0.7815 Acc: 0.7238   \n",
      "2025-12-24 05:14:33,736 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:14:33,737 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 05:14:33,738 - INFO - Val Loss: 0.8870 Acc: 0.6880\n",
      "2025-12-24 05:14:33,739 - INFO - --- Época 239/250 ---\n",
      "2025-12-24 05:15:28,171 - INFO - Train Loss: 0.7861 Acc: 0.7285   \n",
      "2025-12-24 05:15:29,213 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:15:29,214 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 05:15:29,215 - INFO - Val Loss: 0.8910 Acc: 0.6960\n",
      "2025-12-24 05:15:29,216 - INFO - --- Época 240/250 ---\n",
      "2025-12-24 05:16:23,957 - INFO - Train Loss: 0.7903 Acc: 0.7338   \n",
      "2025-12-24 05:16:24,976 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:16:24,977 - INFO -   [Mejora Loss] 0.8825 -> 0.8815. Reseteando paciencia.\n",
      "2025-12-24 05:16:24,978 - INFO - Val Loss: 0.8815 Acc: 0.7000\n",
      "2025-12-24 05:16:24,979 - INFO - --- Época 241/250 ---\n",
      "2025-12-24 05:17:19,607 - INFO - Train Loss: 0.7877 Acc: 0.7348   \n",
      "2025-12-24 05:17:20,638 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:17:20,639 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2025-12-24 05:17:20,641 - INFO - Val Loss: 0.8898 Acc: 0.6960\n",
      "2025-12-24 05:17:20,642 - INFO - --- Época 242/250 ---\n",
      "2025-12-24 05:18:15,260 - INFO - Train Loss: 0.7995 Acc: 0.7288   \n",
      "2025-12-24 05:18:16,297 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:18:16,297 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2025-12-24 05:18:16,298 - INFO - Val Loss: 0.8888 Acc: 0.6960\n",
      "2025-12-24 05:18:16,299 - INFO - --- Época 243/250 ---\n",
      "2025-12-24 05:19:10,785 - INFO - Train Loss: 0.7721 Acc: 0.7400   \n",
      "2025-12-24 05:19:11,858 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:19:11,859 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2025-12-24 05:19:11,860 - INFO - Val Loss: 0.8895 Acc: 0.6940\n",
      "2025-12-24 05:19:11,861 - INFO - --- Época 244/250 ---\n",
      "2025-12-24 05:20:06,294 - INFO - Train Loss: 0.7820 Acc: 0.7372   \n",
      "2025-12-24 05:20:07,328 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:20:07,329 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2025-12-24 05:20:07,330 - INFO - Val Loss: 0.8825 Acc: 0.6940\n",
      "2025-12-24 05:20:07,331 - INFO - --- Época 245/250 ---\n",
      "2025-12-24 05:21:01,944 - INFO - Train Loss: 0.7913 Acc: 0.7338   \n",
      "2025-12-24 05:21:02,989 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:21:02,990 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2025-12-24 05:21:02,991 - INFO - Val Loss: 0.8855 Acc: 0.6840\n",
      "2025-12-24 05:21:02,992 - INFO - --- Época 246/250 ---\n",
      "2025-12-24 05:21:57,363 - INFO - Train Loss: 0.7742 Acc: 0.7345   \n",
      "2025-12-24 05:21:58,389 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:21:58,390 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2025-12-24 05:21:58,391 - INFO - Val Loss: 0.8868 Acc: 0.6920\n",
      "2025-12-24 05:21:58,391 - INFO - --- Época 247/250 ---\n",
      "2025-12-24 05:22:53,068 - INFO - Train Loss: 0.7768 Acc: 0.7440   \n",
      "2025-12-24 05:22:54,112 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:22:54,112 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2025-12-24 05:22:54,113 - INFO - Val Loss: 0.8841 Acc: 0.7020\n",
      "2025-12-24 05:22:54,114 - INFO - --- Época 248/250 ---\n",
      "2025-12-24 05:23:47,982 - INFO - Train Loss: 0.7876 Acc: 0.7390   \n",
      "2025-12-24 05:23:49,017 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:23:49,018 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2025-12-24 05:23:49,019 - INFO - Val Loss: 0.8883 Acc: 0.7000\n",
      "2025-12-24 05:23:49,020 - INFO - --- Época 249/250 ---\n",
      "2025-12-24 05:24:42,749 - INFO - Train Loss: 0.7687 Acc: 0.7400   \n",
      "2025-12-24 05:24:43,800 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:24:43,801 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2025-12-24 05:24:43,802 - INFO - Val Loss: 0.8827 Acc: 0.6920\n",
      "2025-12-24 05:24:43,803 - INFO - --- Época 250/250 ---\n",
      "2025-12-24 05:25:37,967 - INFO - Train Loss: 0.7812 Acc: 0.7328   \n",
      "2025-12-24 05:25:39,003 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2025-12-24 05:25:39,004 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2025-12-24 05:25:39,005 - INFO - Val Loss: 0.8918 Acc: 0.6960\n",
      "2025-12-24 05:25:39,006 - INFO - Entrenamiento finalizado en 230m 19s\n",
      "2025-12-24 05:25:39,007 - INFO - Mejor Val Acc lograda: 0.7120\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    output_dir,\n",
    "    logger,\n",
    "    scheduler=None,\n",
    "):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # --- CONFIGURACIÓN DE EARLY STOPPING ---\n",
    "    patience = 50\n",
    "    patience_counter = 0\n",
    "    min_val_loss = np.inf\n",
    "    early_stop = False\n",
    "    # ---------------------------------------\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    logger.info(f\"Iniciando entrenamiento por {num_epochs} épocas...\")\n",
    "    logger.info(f\"Paciencia configurada: {patience} épocas.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            break\n",
    "\n",
    "        logger.info(f\"--- Época {epoch+1}/{num_epochs} ---\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            loop = tqdm(dataloader, desc=f\"{phase.capitalize()}\", leave=False)\n",
    "\n",
    "            for inputs, labels in loop:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "                history[\"train_acc\"].append(epoch_acc.item())\n",
    "            else:\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "                history[\"val_acc\"].append(epoch_acc.item())\n",
    "\n",
    "                # ==========================================\n",
    "                #      AQUÍ ESTÁ LA LÓGICA DEL SCHEDULER\n",
    "                # ==========================================\n",
    "                if scheduler is not None:\n",
    "                    # ReduceLROnPlateau necesita el valor de la pérdida (loss)\n",
    "                    scheduler.step(epoch_loss)\n",
    "\n",
    "                    # Log para ver si el LR cambia\n",
    "                    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "                    logger.info(f\"  [LR] Tasa de aprendizaje actual: {current_lr:.6f}\")\n",
    "                # ==========================================\n",
    "\n",
    "                # --- LÓGICA DE EARLY STOPPING ---\n",
    "                if epoch_loss < min_val_loss:\n",
    "                    logger.info(\n",
    "                        f\"  [Mejora Loss] {min_val_loss:.4f} -> {epoch_loss:.4f}. Reseteando paciencia.\"\n",
    "                    )\n",
    "                    min_val_loss = epoch_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    logger.info(\n",
    "                        f\"  [Sin mejora Loss] Paciencia: {patience_counter}/{patience}\"\n",
    "                    )\n",
    "                    if patience_counter >= patience:\n",
    "                        logger.info(\"¡EARLY STOPPING ACTIVADO!\")\n",
    "                        early_stop = True\n",
    "\n",
    "            logger.info(\n",
    "                f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Guardar el mejor modelo\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                save_path = os.path.join(output_dir, \"best_model.pth\")\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                logger.info(f\"  [Nuevo Récord Acc] Guardado en: {save_path}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    logger.info(\n",
    "        f\"Entrenamiento finalizado en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\"\n",
    "    )\n",
    "    logger.info(f\"Mejor Val Acc lograda: {best_acc:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    last_path = os.path.join(output_dir, \"last_model.pth\")\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# --- EJECUCIÓN ---\n",
    "\n",
    "# Instanciar el modelo (Asegúrate que SBTAYLOR_KAN.Net es tu clase corregida)\n",
    "# Nota: 'input_size' debe coincidir con el tamaño de tus imágenes en el dataloader\n",
    "model_ft, criterion, optimizer = model_init()\n",
    "#     best_params[\"lr\"],\n",
    "#     best_params[\"dropout_1\"],\n",
    "#     best_params[\"dropout_2\"],\n",
    "#     best_params[\"weight_decay\"],\n",
    "# )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=10,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150\n",
    "\n",
    "# Llamar a entrenar pasando el scheduler\n",
    "model_ft, history = train_model(\n",
    "    model=model_ft,\n",
    "    train_loader=trainloader,\n",
    "    val_loader=valloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    output_dir=RUN_SAVE_DIR,\n",
    "    logger=logger,\n",
    "    scheduler=scheduler,  # <--- Se pasa aquí\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0992da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
      "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
      "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
      "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
      "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
      "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
      "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
      "├─KANLinear: 1-3                         [-1, 256]                 --\n",
      "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
      "├─Dropout: 1-4                           [-1, 256]                 --\n",
      "├─KANLinear: 1-5                         [-1, 128]                 --\n",
      "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
      "├─Dropout: 1-6                           [-1, 128]                 --\n",
      "├─KANLinear: 1-7                         [-1, 10]                  --\n",
      "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
      "==========================================================================================\n",
      "Total params: 241,536\n",
      "Trainable params: 241,536\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 679.73\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 44.41\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 45.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
       "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
       "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
       "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
       "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
       "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
       "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
       "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
       "├─KANLinear: 1-3                         [-1, 256]                 --\n",
       "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
       "├─Dropout: 1-4                           [-1, 256]                 --\n",
       "├─KANLinear: 1-5                         [-1, 128]                 --\n",
       "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
       "├─Dropout: 1-6                           [-1, 128]                 --\n",
       "├─KANLinear: 1-7                         [-1, 10]                  --\n",
       "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
       "==========================================================================================\n",
       "Total params: 241,536\n",
       "Trainable params: 241,536\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 679.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 44.41\n",
       "Params size (MB): 0.92\n",
       "Estimated Total Size (MB): 45.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_ft, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80c1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfica guardada en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\training_history.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history[\"train_acc\"]\n",
    "    val_acc = history[\"val_acc\"]\n",
    "    loss = history[\"train_loss\"]\n",
    "    val_loss = history[\"val_loss\"]\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Gráfica de Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.grid(True)\n",
    "    # --- CORRECCIÓN AQUÍ ---\n",
    "    # 1. Guardar PRIMERO\n",
    "    save_path = os.path.join(RUN_SAVE_DIR, \"training_history.png\")\n",
    "    plt.savefig(\n",
    "        save_path, dpi=300, bbox_inches=\"tight\"\n",
    "    )  # dpi=300 para alta calidad, bbox_inches corta bordes blancos extra\n",
    "    print(f\"Gráfica guardada en: {save_path}\")\n",
    "\n",
    "    # 2. Mostrar DESPUÉS\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf7a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging  # Necesario para el type hinting o manejo interno\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names, output_dir, logger):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo entrenado y genera reporte.\n",
    "    Ahora recibe 'logger' como argumento para asegurar que escriba en tu archivo .log.\n",
    "    \"\"\"\n",
    "    logger.info(\"\\n\" + \"=\" * 40)\n",
    "    logger.info(\"--- INICIANDO EVALUACIÓN EN TEST SET ---\")\n",
    "    logger.info(\"=\" * 40)\n",
    "\n",
    "    # 1. Poner el modelo en modo de evaluación (Apaga Dropout/BatchNorm)\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    total_inference_time = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # 2. Iterar sobre el conjunto de prueba\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # --- BLOQUE DE MEDICIÓN DE TIEMPO PRECISA ---\n",
    "            # Si usas GPU, es obligatorio sincronizar antes y después del forward\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            end_time = time.time()\n",
    "            # ---------------------------------------------\n",
    "\n",
    "            # Acumular tiempo real de procesamiento\n",
    "            total_inference_time += end_time - start_time\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Convertir a numpy\n",
    "    true_labels = np.array(all_labels)\n",
    "    predicted_labels = np.array(all_preds)\n",
    "\n",
    "    # 3. Calcular Métricas\n",
    "    logger.info(\"Calculando métricas estadísticas...\")\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # zero_division=0 evita errores si una clase no tiene predicciones\n",
    "    precision_per_class = precision_score(\n",
    "        true_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "    recall_per_class = recall_score(\n",
    "        true_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "    f1_per_class = f1_score(\n",
    "        true_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Promedios Macro (trata todas las clases igual, útil si hay desbalance)\n",
    "    avg_precision = np.mean(precision_per_class)\n",
    "    avg_recall = np.mean(recall_per_class)\n",
    "    avg_f1 = np.mean(f1_per_class)\n",
    "\n",
    "    # Tiempo promedio por imagen (Métrica Clave para KAN vs VGG)\n",
    "    avg_inference_time_ms = (total_inference_time / total_samples) * 1000\n",
    "\n",
    "    # 4. Matriz de Confusión Visual\n",
    "    logger.info(\"Generando matriz de confusión...\")\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",  # 'd' es para enteros (decimal), mejor que 'g' para conteos\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicción del Modelo\", fontsize=12)\n",
    "    plt.ylabel(\"Realidad (Ground Truth)\", fontsize=12)\n",
    "    plt.title(f\"Matriz de Confusión - Accuracy: {accuracy:.2%}\", fontsize=14)\n",
    "\n",
    "    cm_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()  # Cierra la figura para liberar memoria\n",
    "    logger.info(f\"Gráfico guardado en: {cm_path}\")\n",
    "\n",
    "    # 5. Reporte de Texto\n",
    "    logger.info(\"Escribiendo reporte final...\")\n",
    "\n",
    "    metrics_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Clase\": class_names,\n",
    "            \"Precision\": np.round(precision_per_class, 4),\n",
    "            \"Recall\": np.round(recall_per_class, 4),\n",
    "            \"F1-Score\": np.round(f1_per_class, 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    report_path = os.path.join(output_dir, \"test_metrics_report.txt\")\n",
    "\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\" REPORTE DE EVALUACIÓN: {time.strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"Métricas Globales:\\n\")\n",
    "        f.write(f\"- Accuracy:          {accuracy:.4f} ({accuracy:.2%})\\n\")\n",
    "        f.write(f\"- Macro Precision:   {avg_precision:.4f}\\n\")\n",
    "        f.write(f\"- Macro Recall:      {avg_recall:.4f}\\n\")\n",
    "        f.write(f\"- Macro F1-Score:    {avg_f1:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"EFICIENCIA (Velocidad)\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"- Muestras totales:  {total_samples}\\n\")\n",
    "        f.write(f\"- Tiempo total:      {total_inference_time:.4f} seg\\n\")\n",
    "        f.write(f\"- Tiempo por imagen: {avg_inference_time_ms:.4f} ms\\n\\n\")\n",
    "\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"DETALLE POR CLASE\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        # Usamos to_markdown si pandas es reciente, sino to_string\n",
    "        try:\n",
    "            f.write(metrics_df.to_markdown(index=False))\n",
    "        except:\n",
    "            f.write(metrics_df.to_string(index=False))\n",
    "\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"Matriz de Confusión (Texto):\\n\")\n",
    "        f.write(np.array2string(cm, separator=\", \"))\n",
    "\n",
    "    logger.info(f\"Reporte de texto guardado en: {report_path}\")\n",
    "    logger.info(\"--- EVALUACIÓN FINALIZADA ---\")\n",
    "\n",
    "    return (\n",
    "        accuracy,\n",
    "        avg_f1,\n",
    "    )  # Retorna valores por si los necesitas en el script principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c1eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 05:25:44,640 - INFO - Cargando el mejor modelo para la evaluación...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones calculadas automáticamente para FC1: 25088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['n01443537',\n",
       " 'n01629819',\n",
       " 'n01641577',\n",
       " 'n01644900',\n",
       " 'n01698640',\n",
       " 'n01742172',\n",
       " 'n01768244',\n",
       " 'n01770393',\n",
       " 'n01774384',\n",
       " 'n01774750']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(RUN_SAVE_DIR, \"best_model.pth\")\n",
    "# 2. Crear una nueva instancia del modelo y cargar los mejores pesos\n",
    "logger.info(\"Cargando el mejor modelo para la evaluación...\")\n",
    "eval_model = KAN_Model(num_classes=len(selected_classes), input_size=(3, 224, 224)).to(\n",
    "    device\n",
    ")\n",
    "eval_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "class_names = (\n",
    "    selected_classes  # Obtener los nombres de las clases desde el dataset de prueba\n",
    ")\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c9eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 05:25:45,825 - INFO - \n",
      "========================================\n",
      "2025-12-24 05:25:45,827 - INFO - --- INICIANDO EVALUACIÓN EN TEST SET ---\n",
      "2025-12-24 05:25:45,829 - INFO - ========================================\n",
      "2025-12-24 05:25:46,845 - INFO - Calculando métricas estadísticas...\n",
      "2025-12-24 05:25:46,853 - INFO - Generando matriz de confusión...\n",
      "2025-12-24 05:25:47,257 - INFO - Gráfico guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\confusion_matrix.png\n",
      "2025-12-24 05:25:47,259 - INFO - Escribiendo reporte final...\n",
      "2025-12-24 05:25:47,275 - INFO - Reporte de texto guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20251224_013331\\test_metrics_report.txt\n",
      "2025-12-24 05:25:47,276 - INFO - --- EVALUACIÓN FINALIZADA ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.684, np.float64(0.6816993407942898))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Llamar a la función de evaluación\n",
    "# Suponiendo que tienes un 'test_loader' y un 'RUN_DIR' definidos\n",
    "evaluate_model(\n",
    "    model=eval_model,\n",
    "    test_loader=testloader,  # Usando val_loader como ejemplo; reemplaza con test_loader si tienes uno\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    output_dir=RUN_SAVE_DIR,  # El directorio de la ejecución actual para guardar los resultados\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daad25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
