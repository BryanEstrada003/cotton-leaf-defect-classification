{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc69ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging  # [LOGGING] Importar la librería de logging\n",
    "import random  # [SEED] Importar la librería random de Python\n",
    "import numpy as np  # [SEED] Importar NumPy\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # Para barra de progreso\n",
    "\n",
    "# Importar tu modelo corregido (asegúrate de que el archivo .py esté en la carpeta)\n",
    "sys.path.append(\"KAN_models\")\n",
    "from SBTAYLOR_KAN import Net as KAN_Model\n",
    "\n",
    "# Configuración de Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "\n",
    "# Semilla\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ef72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_PATH = \"C:\\\\Users\\\\Admin-Cidis\\\\.cache\\\\kagglehub\\\\datasets\\\\akash2sharma\\\\tiny-imagenet\\\\versions\\\\1\\\\tiny-imagenet-200\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "RUN_SAVE_DIR = os.path.join(\"models/sbtaylor_kan_tiny_imagenet\", f\"run_{timestamp}\")\n",
    "os.makedirs(RUN_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"sbtaylor_kan.best_weights.pth\"\n",
    "MODEL_SAVE_PATH = os.path.join(RUN_SAVE_DIR, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfee12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE_PATH = os.path.join(RUN_SAVE_DIR, \"training_run.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8887fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 16:05:30,517 - INFO - Modelo SBTAYLOR_KAN.Net importado correctamente.\n",
      "2026-01-04 16:05:30,520 - INFO - Los pesos del modelo se guardarán en: 'models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\sbtaylor_kan.best_weights.pth'\n",
      "2026-01-04 16:05:30,523 - INFO - El registro de entrenamiento se guardará en: 'models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\training_run.log'\n"
     ]
    }
   ],
   "source": [
    "# --- [LOGGING] CONFIGURACIÓN DEL LOGGER ---\n",
    "# Configura el logger para que escriba en un archivo y en la consola.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Nivel mínimo de mensajes a registrar (INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # Formato del mensaje\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            LOG_FILE_PATH, mode=\"w\"\n",
    "        ),  # Escribe en el archivo .log (modo 'w' para sobreescribir en cada ejecución)\n",
    "        logging.StreamHandler(),  # Muestra los logs en la consola\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Ahora, en lugar de print(), usaremos logging.info()\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.info(\"Modelo SBTAYLOR_KAN.Net importado correctamente.\")\n",
    "logger.info(f\"Los pesos del modelo se guardarán en: '{MODEL_SAVE_PATH}'\")\n",
    "logger.info(f\"El registro de entrenamiento se guardará en: '{LOG_FILE_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19af029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 16:05:30,644 - INFO - Versión de PyTorch: 2.9.0+cu126\n",
      "2026-01-04 16:05:30,648 - INFO - ¿CUDA está disponible?: True\n",
      "2026-01-04 16:05:30,655 - INFO - Versión de CUDA con la que PyTorch fue compilado: 12.6\n",
      "2026-01-04 16:05:30,659 - INFO - Número de GPUs disponibles: 1\n",
      "2026-01-04 16:05:30,669 - INFO - Nombre de la GPU actual: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Versión de PyTorch: {torch.__version__}\")\n",
    "logger.info(f\"¿CUDA está disponible?: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(\n",
    "        f\"Versión de CUDA con la que PyTorch fue compilado: {torch.version.cuda}\"\n",
    "    )\n",
    "    logger.info(f\"Número de GPUs disponibles: {torch.cuda.device_count()}\")\n",
    "    logger.info(f\"Nombre de la GPU actual: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logger.info(\n",
    "        \"PyTorch no puede encontrar CUDA. Es probable que hayas instalado la versión de solo CPU.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8478fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 16:05:30,717 - INFO - --- Hyperparámetros de Entrenamiento ---\n",
      "2026-01-04 16:05:30,719 - INFO - Batch Size: 64\n",
      "2026-01-04 16:05:30,720 - INFO - Num Epochs: 250\n",
      "2026-01-04 16:05:30,745 - INFO - Num Workers: 4\n"
     ]
    }
   ],
   "source": [
    "# --- 2. PARÁMETROS DE ENTRENAMIENTO ---\n",
    "set_seed(74)  # [SEED] Establecer la semilla para reproducibilidad\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 250\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# print hyperparameters\n",
    "logging.info(f\"--- Hyperparámetros de Entrenamiento ---\")\n",
    "logging.info(f\"Batch Size: {BATCH_SIZE}\")\n",
    "logging.info(f\"Num Epochs: {NUM_EPOCHS}\")\n",
    "logging.info(f\"Num Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0521c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde: C:\\Users\\Admin-Cidis\\.cache\\kagglehub\\datasets\\akash2sharma\\tiny-imagenet\\versions\\1\\tiny-imagenet-200/train\n",
      "Usando 6 clases: ['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172']\n",
      "Dataset listo.\n",
      "Entrenamiento : 2400 imágenes\n",
      "Validación    : 300 imágenes\n",
      "Test          : 300 imágenes\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset, random_split, DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "# --- 1. Clase Wrapper (Se mantiene igual) ---\n",
    "class ApplyTransform(Dataset):\n",
    "    \"\"\"\n",
    "    Envuelve un dataset (o subset) y aplica una transformación específica on-the-fly.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "# --- 2. Transformaciones ---\n",
    "\n",
    "# TRAIN: Augmentations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    #crop\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# VAL: Estándar\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# TEST: Igual a Val (Sin augmentations, solo evaluar)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# --- 3. Carga y Filtrado ---\n",
    "data_dir = IMAGENET_PATH + \"/train\" # Ajusta tu path si es necesario\n",
    "print(f\"Cargando datos desde: {data_dir}\")\n",
    "\n",
    "full_dataset_raw = torchvision.datasets.ImageFolder(data_dir)\n",
    "\n",
    "# Seleccionamos solo las primeras 6 clases\n",
    "selected_classes = full_dataset_raw.classes[:6]\n",
    "print(f\"Usando {len(selected_classes)} clases: {selected_classes}\")\n",
    "\n",
    "selected_indices = [i for i, (_, label) in enumerate(full_dataset_raw) if label < 6]\n",
    "subset_dataset = Subset(full_dataset_raw, selected_indices)\n",
    "\n",
    "\n",
    "# --- 4. Split 80/10/10 (Train/Val/Test) ---\n",
    "total_len = len(subset_dataset)\n",
    "train_len = int(0.8 * total_len)\n",
    "val_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - val_len  # El resto para test\n",
    "\n",
    "# Ahora random_split recibe 3 longitudes\n",
    "train_subset, val_subset, test_subset = random_split(\n",
    "    subset_dataset, [train_len, val_len, test_len]\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. Aplicar Wrapper ---\n",
    "# Asignamos transformaciones: Train con ruido, Val y Test limpias\n",
    "train_dataset = ApplyTransform(train_subset, transform=transform_train)\n",
    "val_dataset = ApplyTransform(val_subset, transform=transform_val)\n",
    "test_dataset = ApplyTransform(test_subset, transform=transform_test)\n",
    "\n",
    "\n",
    "# --- 6. DataLoaders ---\n",
    "trainloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "valloader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset listo.\")\n",
    "print(f\"Entrenamiento : {len(train_dataset)} imágenes\")\n",
    "print(f\"Validación    : {len(val_dataset)} imágenes\")\n",
    "print(f\"Test          : {len(test_dataset)} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe621b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 16:15:46,231 - INFO - \n",
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 4. INICIALIZACIÓN DEL MODELO, CRITERIO Y OPTIMIZADOR ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"\\nUsando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4daaea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x18aaeadc3a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7777979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(learning_rate=0.001, dropout_1=0.4, dropout_2=0.5, weight_decay=1e-3):\n",
    "    # Instanciar el modelo (Asegúrate que SBTAYLOR_KAN.Net es tu clase corregida)\n",
    "    model_ft = KAN_Model(\n",
    "        num_classes=len(selected_classes),\n",
    "        input_size=(3, 224, 224),\n",
    "        dropout_1=dropout_1,\n",
    "        dropout_2=dropout_2,\n",
    "    ).to(device)\n",
    "\n",
    "    # En lugar de nn.CrossEntropyLoss() simple:\n",
    "    criterion = nn.CrossEntropyLoss() #(label_smoothing=0.1)\n",
    "    optimizer = optim.Adam(\n",
    "        model_ft.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    return model_ft, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc522b",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9b21e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones calculadas automáticamente para FC1: 25088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 16:15:48,037 - INFO - Iniciando entrenamiento por 250 épocas...\n",
      "2026-01-04 16:15:48,038 - INFO - Paciencia configurada: 50 épocas.\n",
      "2026-01-04 16:15:48,039 - INFO - --- Época 1/250 ---\n",
      "2026-01-04 16:17:30,795 - INFO - Train Loss: 1.7915 Acc: 0.2467  \n",
      "2026-01-04 16:17:33,919 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:17:33,921 - INFO -   [Mejora Loss] inf -> 1.5710. Reseteando paciencia.\n",
      "2026-01-04 16:17:34,448 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:17:34,450 - INFO - Val Loss: 1.5710 Acc: 0.3300\n",
      "2026-01-04 16:17:34,451 - INFO - --- Época 2/250 ---\n",
      "2026-01-04 16:19:13,652 - INFO - Train Loss: 1.5885 Acc: 0.3321  \n",
      "2026-01-04 16:19:15,912 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:19:15,913 - INFO -   [Mejora Loss] 1.5710 -> 1.4811. Reseteando paciencia.\n",
      "2026-01-04 16:19:16,706 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:19:16,709 - INFO - Val Loss: 1.4811 Acc: 0.3233\n",
      "2026-01-04 16:19:16,712 - INFO - --- Época 3/250 ---\n",
      "2026-01-04 16:20:28,700 - INFO - Train Loss: 1.5577 Acc: 0.3358  \n",
      "2026-01-04 16:20:29,342 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:20:29,343 - INFO -   [Mejora Loss] 1.4811 -> 1.4290. Reseteando paciencia.\n",
      "2026-01-04 16:20:29,872 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:20:29,874 - INFO - Val Loss: 1.4290 Acc: 0.3500\n",
      "2026-01-04 16:20:29,875 - INFO - --- Época 4/250 ---\n",
      "2026-01-04 16:21:10,036 - INFO - Train Loss: 1.4913 Acc: 0.3717  \n",
      "2026-01-04 16:21:10,724 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:21:10,725 - INFO -   [Mejora Loss] 1.4290 -> 1.3339. Reseteando paciencia.\n",
      "2026-01-04 16:21:11,177 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:21:11,178 - INFO - Val Loss: 1.3339 Acc: 0.4800\n",
      "2026-01-04 16:21:11,179 - INFO - --- Época 5/250 ---\n",
      "2026-01-04 16:21:51,640 - INFO - Train Loss: 1.4418 Acc: 0.4038  \n",
      "2026-01-04 16:21:52,273 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:21:52,274 - INFO -   [Mejora Loss] 1.3339 -> 1.3181. Reseteando paciencia.\n",
      "2026-01-04 16:21:52,698 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:21:52,699 - INFO - Val Loss: 1.3181 Acc: 0.4800\n",
      "2026-01-04 16:21:52,700 - INFO - --- Época 6/250 ---\n",
      "2026-01-04 16:22:32,280 - INFO - Train Loss: 1.4337 Acc: 0.4117  \n",
      "2026-01-04 16:22:33,038 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:22:33,039 - INFO -   [Mejora Loss] 1.3181 -> 1.3179. Reseteando paciencia.\n",
      "2026-01-04 16:22:33,538 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:22:33,539 - INFO - Val Loss: 1.3179 Acc: 0.5100\n",
      "2026-01-04 16:22:33,541 - INFO - --- Época 7/250 ---\n",
      "2026-01-04 16:23:13,068 - INFO - Train Loss: 1.4062 Acc: 0.4179  \n",
      "2026-01-04 16:23:13,723 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:23:13,724 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:23:13,725 - INFO - Val Loss: 1.3880 Acc: 0.4867\n",
      "2026-01-04 16:23:13,726 - INFO - --- Época 8/250 ---\n",
      "2026-01-04 16:23:53,565 - INFO - Train Loss: 1.3852 Acc: 0.4442  \n",
      "2026-01-04 16:23:54,283 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:23:54,284 - INFO -   [Mejora Loss] 1.3179 -> 1.3095. Reseteando paciencia.\n",
      "2026-01-04 16:23:54,705 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:23:54,706 - INFO - Val Loss: 1.3095 Acc: 0.5000\n",
      "2026-01-04 16:23:54,707 - INFO - --- Época 9/250 ---\n",
      "2026-01-04 16:24:34,064 - INFO - Train Loss: 1.3691 Acc: 0.4538  \n",
      "2026-01-04 16:24:34,729 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:24:34,730 - INFO -   [Mejora Loss] 1.3095 -> 1.2820. Reseteando paciencia.\n",
      "2026-01-04 16:24:35,166 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:24:35,168 - INFO - Val Loss: 1.2820 Acc: 0.5033\n",
      "2026-01-04 16:24:35,169 - INFO - --- Época 10/250 ---\n",
      "2026-01-04 16:25:15,676 - INFO - Train Loss: 1.3748 Acc: 0.4488  \n",
      "2026-01-04 16:25:16,469 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:25:16,470 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:25:16,472 - INFO - Val Loss: 1.3412 Acc: 0.5000\n",
      "2026-01-04 16:25:16,473 - INFO - --- Época 11/250 ---\n",
      "2026-01-04 16:25:57,070 - INFO - Train Loss: 1.3371 Acc: 0.4579  \n",
      "2026-01-04 16:25:57,733 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:25:57,734 - INFO -   [Mejora Loss] 1.2820 -> 1.2421. Reseteando paciencia.\n",
      "2026-01-04 16:25:58,172 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:25:58,174 - INFO - Val Loss: 1.2421 Acc: 0.5267\n",
      "2026-01-04 16:25:58,175 - INFO - --- Época 12/250 ---\n",
      "2026-01-04 16:26:38,769 - INFO - Train Loss: 1.3117 Acc: 0.4808  \n",
      "2026-01-04 16:26:39,558 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:26:39,559 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:26:39,560 - INFO - Val Loss: 1.2448 Acc: 0.5333\n",
      "2026-01-04 16:26:39,561 - INFO - --- Época 13/250 ---\n",
      "2026-01-04 16:27:19,662 - INFO - Train Loss: 1.3177 Acc: 0.4729  \n",
      "2026-01-04 16:27:20,311 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:27:20,312 - INFO -   [Mejora Loss] 1.2421 -> 1.2207. Reseteando paciencia.\n",
      "2026-01-04 16:27:20,762 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:27:20,763 - INFO - Val Loss: 1.2207 Acc: 0.5267\n",
      "2026-01-04 16:27:20,764 - INFO - --- Época 14/250 ---\n",
      "2026-01-04 16:28:01,331 - INFO - Train Loss: 1.2768 Acc: 0.4879  \n",
      "2026-01-04 16:28:02,057 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:28:02,058 - INFO -   [Mejora Loss] 1.2207 -> 1.1791. Reseteando paciencia.\n",
      "2026-01-04 16:28:02,525 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:28:02,526 - INFO - Val Loss: 1.1791 Acc: 0.5833\n",
      "2026-01-04 16:28:02,527 - INFO - --- Época 15/250 ---\n",
      "2026-01-04 16:28:44,223 - INFO - Train Loss: 1.2750 Acc: 0.4800  \n",
      "2026-01-04 16:28:44,954 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:28:44,956 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:28:44,957 - INFO - Val Loss: 1.1877 Acc: 0.5500\n",
      "2026-01-04 16:28:44,958 - INFO - --- Época 16/250 ---\n",
      "2026-01-04 16:29:27,117 - INFO - Train Loss: 1.2569 Acc: 0.4808   \n",
      "2026-01-04 16:29:29,305 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:29:29,306 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 16:29:29,308 - INFO - Val Loss: 1.1889 Acc: 0.6033\n",
      "2026-01-04 16:29:29,309 - INFO - --- Época 17/250 ---\n",
      "2026-01-04 16:30:12,184 - INFO - Train Loss: 1.2481 Acc: 0.5013   \n",
      "2026-01-04 16:30:13,016 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:30:13,017 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 16:30:13,018 - INFO - Val Loss: 1.2294 Acc: 0.5300\n",
      "2026-01-04 16:30:13,019 - INFO - --- Época 18/250 ---\n",
      "2026-01-04 16:30:54,653 - INFO - Train Loss: 1.2338 Acc: 0.5013   \n",
      "2026-01-04 16:30:55,385 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:30:55,385 - INFO -   [Mejora Loss] 1.1791 -> 1.1254. Reseteando paciencia.\n",
      "2026-01-04 16:30:55,857 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:30:55,859 - INFO - Val Loss: 1.1254 Acc: 0.6033\n",
      "2026-01-04 16:30:55,861 - INFO - --- Época 19/250 ---\n",
      "2026-01-04 16:31:38,007 - INFO - Train Loss: 1.2483 Acc: 0.5117  \n",
      "2026-01-04 16:31:38,917 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:31:38,918 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:31:38,919 - INFO - Val Loss: 1.1643 Acc: 0.5433\n",
      "2026-01-04 16:31:38,920 - INFO - --- Época 20/250 ---\n",
      "2026-01-04 16:32:20,819 - INFO - Train Loss: 1.1858 Acc: 0.5333   \n",
      "2026-01-04 16:32:21,539 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:32:21,540 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 16:32:21,542 - INFO - Val Loss: 1.1308 Acc: 0.5700\n",
      "2026-01-04 16:32:21,543 - INFO - --- Época 21/250 ---\n",
      "2026-01-04 16:33:03,340 - INFO - Train Loss: 1.2057 Acc: 0.5242  \n",
      "2026-01-04 16:33:04,077 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:33:04,078 - INFO -   [Mejora Loss] 1.1254 -> 1.1055. Reseteando paciencia.\n",
      "2026-01-04 16:33:04,539 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:33:04,541 - INFO - Val Loss: 1.1055 Acc: 0.6000\n",
      "2026-01-04 16:33:04,542 - INFO - --- Época 22/250 ---\n",
      "2026-01-04 16:33:46,488 - INFO - Train Loss: 1.1845 Acc: 0.5312  \n",
      "2026-01-04 16:33:47,219 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:33:47,220 - INFO -   [Mejora Loss] 1.1055 -> 1.0265. Reseteando paciencia.\n",
      "2026-01-04 16:33:47,714 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:33:47,716 - INFO - Val Loss: 1.0265 Acc: 0.6433\n",
      "2026-01-04 16:33:47,717 - INFO - --- Época 23/250 ---\n",
      "2026-01-04 16:34:29,317 - INFO - Train Loss: 1.2018 Acc: 0.5271   \n",
      "2026-01-04 16:34:30,115 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:34:30,116 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:34:30,117 - INFO - Val Loss: 1.0716 Acc: 0.5767\n",
      "2026-01-04 16:34:30,117 - INFO - --- Época 24/250 ---\n",
      "2026-01-04 16:35:12,711 - INFO - Train Loss: 1.1737 Acc: 0.5233  \n",
      "2026-01-04 16:35:13,659 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:35:13,661 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 16:35:13,662 - INFO - Val Loss: 1.1046 Acc: 0.5800\n",
      "2026-01-04 16:35:13,663 - INFO - --- Época 25/250 ---\n",
      "2026-01-04 16:35:55,639 - INFO - Train Loss: 1.1586 Acc: 0.5383   \n",
      "2026-01-04 16:35:56,317 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:35:56,318 - INFO -   [Mejora Loss] 1.0265 -> 1.0132. Reseteando paciencia.\n",
      "2026-01-04 16:35:56,782 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:35:56,784 - INFO - Val Loss: 1.0132 Acc: 0.6300\n",
      "2026-01-04 16:35:56,785 - INFO - --- Época 26/250 ---\n",
      "2026-01-04 16:36:37,603 - INFO - Train Loss: 1.1589 Acc: 0.5538   \n",
      "2026-01-04 16:36:38,315 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:36:38,316 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:36:38,317 - INFO - Val Loss: 1.0925 Acc: 0.5867\n",
      "2026-01-04 16:36:38,318 - INFO - --- Época 27/250 ---\n",
      "2026-01-04 16:37:19,669 - INFO - Train Loss: 1.1343 Acc: 0.5579   \n",
      "2026-01-04 16:37:20,530 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:37:20,531 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 16:37:20,532 - INFO - Val Loss: 1.1710 Acc: 0.5733\n",
      "2026-01-04 16:37:20,534 - INFO - --- Época 28/250 ---\n",
      "2026-01-04 16:38:01,975 - INFO - Train Loss: 1.1282 Acc: 0.5513   \n",
      "2026-01-04 16:38:02,715 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:38:02,716 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 16:38:02,717 - INFO - Val Loss: 1.0524 Acc: 0.6133\n",
      "2026-01-04 16:38:02,718 - INFO - --- Época 29/250 ---\n",
      "2026-01-04 16:38:43,805 - INFO - Train Loss: 1.1248 Acc: 0.5650   \n",
      "2026-01-04 16:38:44,545 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:38:44,545 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 16:38:44,546 - INFO - Val Loss: 1.0328 Acc: 0.6100\n",
      "2026-01-04 16:38:44,547 - INFO - --- Época 30/250 ---\n",
      "2026-01-04 16:39:26,922 - INFO - Train Loss: 1.1206 Acc: 0.5608   \n",
      "2026-01-04 16:39:27,706 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:39:27,707 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 16:39:27,708 - INFO - Val Loss: 1.0516 Acc: 0.5867\n",
      "2026-01-04 16:39:27,709 - INFO - --- Época 31/250 ---\n",
      "2026-01-04 16:40:09,231 - INFO - Train Loss: 1.1059 Acc: 0.5471   \n",
      "2026-01-04 16:40:09,940 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:40:09,941 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 16:40:09,942 - INFO - Val Loss: 1.1192 Acc: 0.6000\n",
      "2026-01-04 16:40:09,943 - INFO - --- Época 32/250 ---\n",
      "2026-01-04 16:40:51,804 - INFO - Train Loss: 1.1261 Acc: 0.5725   \n",
      "2026-01-04 16:40:52,485 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:40:52,485 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 16:40:52,487 - INFO - Val Loss: 1.0464 Acc: 0.6600\n",
      "2026-01-04 16:40:52,487 - INFO - --- Época 33/250 ---\n",
      "2026-01-04 16:42:12,299 - INFO - Train Loss: 1.1106 Acc: 0.5675   \n",
      "2026-01-04 16:42:13,175 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:42:13,175 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 16:42:13,177 - INFO - Val Loss: 1.0493 Acc: 0.6200\n",
      "2026-01-04 16:42:13,178 - INFO - --- Época 34/250 ---\n",
      "2026-01-04 16:43:50,893 - INFO - Train Loss: 1.1208 Acc: 0.5554   \n",
      "2026-01-04 16:43:53,065 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:43:53,066 - INFO -   [Mejora Loss] 1.0132 -> 0.9780. Reseteando paciencia.\n",
      "2026-01-04 16:43:53,750 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:43:53,752 - INFO - Val Loss: 0.9780 Acc: 0.6567\n",
      "2026-01-04 16:43:53,754 - INFO - --- Época 35/250 ---\n",
      "2026-01-04 16:45:33,127 - INFO - Train Loss: 1.1169 Acc: 0.5646   \n",
      "2026-01-04 16:45:35,406 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:45:35,407 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:45:35,409 - INFO - Val Loss: 1.0675 Acc: 0.6100\n",
      "2026-01-04 16:45:35,410 - INFO - --- Época 36/250 ---\n",
      "2026-01-04 16:47:09,283 - INFO - Train Loss: 1.1152 Acc: 0.5742   \n",
      "2026-01-04 16:47:14,953 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:47:14,955 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 16:47:14,957 - INFO - Val Loss: 1.0126 Acc: 0.6167\n",
      "2026-01-04 16:47:14,958 - INFO - --- Época 37/250 ---\n",
      "2026-01-04 16:48:52,007 - INFO - Train Loss: 1.0937 Acc: 0.5575   \n",
      "2026-01-04 16:48:54,245 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:48:54,246 - INFO -   [Mejora Loss] 0.9780 -> 0.9628. Reseteando paciencia.\n",
      "2026-01-04 16:48:55,083 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 16:48:55,086 - INFO - Val Loss: 0.9628 Acc: 0.6833\n",
      "2026-01-04 16:48:55,087 - INFO - --- Época 38/250 ---\n",
      "2026-01-04 16:50:25,987 - INFO - Train Loss: 1.0405 Acc: 0.5792   \n",
      "2026-01-04 16:50:28,082 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:50:28,083 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 16:50:28,084 - INFO - Val Loss: 1.0869 Acc: 0.5800\n",
      "2026-01-04 16:50:28,085 - INFO - --- Época 39/250 ---\n",
      "2026-01-04 16:51:59,274 - INFO - Train Loss: 1.0684 Acc: 0.5737   \n",
      "2026-01-04 16:52:01,182 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:52:01,183 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 16:52:01,185 - INFO - Val Loss: 1.0061 Acc: 0.6833\n",
      "2026-01-04 16:52:01,186 - INFO - --- Época 40/250 ---\n",
      "2026-01-04 16:53:30,290 - INFO - Train Loss: 1.0693 Acc: 0.5833   \n",
      "2026-01-04 16:53:32,243 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:53:32,244 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 16:53:32,245 - INFO - Val Loss: 1.0047 Acc: 0.6367\n",
      "2026-01-04 16:53:32,246 - INFO - --- Época 41/250 ---\n",
      "2026-01-04 16:55:00,069 - INFO - Train Loss: 1.0466 Acc: 0.5929   \n",
      "2026-01-04 16:55:02,231 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:55:02,232 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 16:55:02,235 - INFO - Val Loss: 1.0612 Acc: 0.6000\n",
      "2026-01-04 16:55:02,237 - INFO - --- Época 42/250 ---\n",
      "2026-01-04 16:56:31,882 - INFO - Train Loss: 1.0526 Acc: 0.5950   \n",
      "2026-01-04 16:56:33,461 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:56:33,462 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 16:56:33,465 - INFO - Val Loss: 1.0121 Acc: 0.6133\n",
      "2026-01-04 16:56:33,467 - INFO - --- Época 43/250 ---\n",
      "2026-01-04 16:58:01,094 - INFO - Train Loss: 1.0683 Acc: 0.5904   \n",
      "2026-01-04 16:58:03,045 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:58:03,063 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 16:58:03,066 - INFO - Val Loss: 1.0251 Acc: 0.6000\n",
      "2026-01-04 16:58:03,067 - INFO - --- Época 44/250 ---\n",
      "2026-01-04 16:59:23,017 - INFO - Train Loss: 1.0460 Acc: 0.5921   \n",
      "2026-01-04 16:59:23,587 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:59:23,588 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 16:59:23,589 - INFO - Val Loss: 0.9866 Acc: 0.6433\n",
      "2026-01-04 16:59:23,590 - INFO - --- Época 45/250 ---\n",
      "2026-01-04 16:59:56,889 - INFO - Train Loss: 1.0376 Acc: 0.5900   \n",
      "2026-01-04 16:59:57,526 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 16:59:57,527 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 16:59:57,528 - INFO - Val Loss: 1.0498 Acc: 0.6333\n",
      "2026-01-04 16:59:57,529 - INFO - --- Época 46/250 ---\n",
      "2026-01-04 17:00:30,796 - INFO - Train Loss: 1.0380 Acc: 0.5925   \n",
      "2026-01-04 17:00:31,549 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 17:00:31,550 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 17:00:31,551 - INFO - Val Loss: 1.0032 Acc: 0.6500\n",
      "2026-01-04 17:00:31,552 - INFO - --- Época 47/250 ---\n",
      "2026-01-04 17:01:04,806 - INFO - Train Loss: 1.0535 Acc: 0.5842   \n",
      "2026-01-04 17:01:05,385 - INFO -   [LR] Tasa de aprendizaje actual: 0.001000\n",
      "2026-01-04 17:01:05,386 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 17:01:05,387 - INFO - Val Loss: 1.0597 Acc: 0.6433\n",
      "2026-01-04 17:01:05,388 - INFO - --- Época 48/250 ---\n",
      "2026-01-04 17:01:40,147 - INFO - Train Loss: 1.0603 Acc: 0.5863   \n",
      "2026-01-04 17:01:40,779 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:01:40,780 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 17:01:40,781 - INFO - Val Loss: 0.9852 Acc: 0.6467\n",
      "2026-01-04 17:01:40,782 - INFO - --- Época 49/250 ---\n",
      "2026-01-04 17:02:15,092 - INFO - Train Loss: 1.0035 Acc: 0.6108   \n",
      "2026-01-04 17:02:15,786 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:02:15,787 - INFO -   [Mejora Loss] 0.9628 -> 0.9178. Reseteando paciencia.\n",
      "2026-01-04 17:02:16,220 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:02:16,221 - INFO - Val Loss: 0.9178 Acc: 0.6700\n",
      "2026-01-04 17:02:16,223 - INFO - --- Época 50/250 ---\n",
      "2026-01-04 17:02:49,653 - INFO - Train Loss: 0.9860 Acc: 0.6129   \n",
      "2026-01-04 17:02:50,271 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:02:50,272 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 17:02:50,273 - INFO - Val Loss: 0.9547 Acc: 0.6400\n",
      "2026-01-04 17:02:50,274 - INFO - --- Época 51/250 ---\n",
      "2026-01-04 17:03:24,119 - INFO - Train Loss: 0.9850 Acc: 0.6221   \n",
      "2026-01-04 17:03:24,662 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:03:24,664 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 17:03:24,665 - INFO - Val Loss: 0.9712 Acc: 0.6467\n",
      "2026-01-04 17:03:24,666 - INFO - --- Época 52/250 ---\n",
      "2026-01-04 17:03:57,795 - INFO - Train Loss: 0.9657 Acc: 0.6288   \n",
      "2026-01-04 17:03:58,346 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:03:58,347 - INFO -   [Mejora Loss] 0.9178 -> 0.8997. Reseteando paciencia.\n",
      "2026-01-04 17:03:58,758 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:03:58,760 - INFO - Val Loss: 0.8997 Acc: 0.7033\n",
      "2026-01-04 17:03:58,761 - INFO - --- Época 53/250 ---\n",
      "2026-01-04 17:04:32,245 - INFO - Train Loss: 0.9535 Acc: 0.6225   \n",
      "2026-01-04 17:04:32,873 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:04:32,874 - INFO -   [Mejora Loss] 0.8997 -> 0.8878. Reseteando paciencia.\n",
      "2026-01-04 17:04:33,300 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:04:33,302 - INFO - Val Loss: 0.8878 Acc: 0.6900\n",
      "2026-01-04 17:04:33,303 - INFO - --- Época 54/250 ---\n",
      "2026-01-04 17:05:06,768 - INFO - Train Loss: 0.9443 Acc: 0.6313   \n",
      "2026-01-04 17:05:07,411 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:05:07,412 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 17:05:07,413 - INFO - Val Loss: 0.8918 Acc: 0.6833\n",
      "2026-01-04 17:05:07,414 - INFO - --- Época 55/250 ---\n",
      "2026-01-04 17:05:40,919 - INFO - Train Loss: 0.9886 Acc: 0.6142   \n",
      "2026-01-04 17:05:41,601 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:05:41,601 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 17:05:41,602 - INFO - Val Loss: 0.9316 Acc: 0.6667\n",
      "2026-01-04 17:05:41,603 - INFO - --- Época 56/250 ---\n",
      "2026-01-04 17:06:15,035 - INFO - Train Loss: 0.9607 Acc: 0.6246   \n",
      "2026-01-04 17:06:15,661 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:06:15,662 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 17:06:15,662 - INFO - Val Loss: 0.8908 Acc: 0.6867\n",
      "2026-01-04 17:06:15,663 - INFO - --- Época 57/250 ---\n",
      "2026-01-04 17:06:52,527 - INFO - Train Loss: 0.9722 Acc: 0.6088   \n",
      "2026-01-04 17:06:53,245 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:06:53,247 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 17:06:53,248 - INFO - Val Loss: 0.9347 Acc: 0.6433\n",
      "2026-01-04 17:06:53,250 - INFO - --- Época 58/250 ---\n",
      "2026-01-04 17:07:34,527 - INFO - Train Loss: 0.9388 Acc: 0.6288   \n",
      "2026-01-04 17:07:35,394 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:07:35,395 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 17:07:35,396 - INFO - Val Loss: 0.9151 Acc: 0.6567\n",
      "2026-01-04 17:07:35,397 - INFO - --- Época 59/250 ---\n",
      "2026-01-04 17:08:17,066 - INFO - Train Loss: 0.9588 Acc: 0.6342   \n",
      "2026-01-04 17:08:17,832 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:08:17,833 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 17:08:17,834 - INFO - Val Loss: 0.8911 Acc: 0.6767\n",
      "2026-01-04 17:08:17,835 - INFO - --- Época 60/250 ---\n",
      "2026-01-04 17:08:59,547 - INFO - Train Loss: 0.9239 Acc: 0.6371   \n",
      "2026-01-04 17:09:00,478 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:09:00,479 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 17:09:00,480 - INFO - Val Loss: 0.8989 Acc: 0.6900\n",
      "2026-01-04 17:09:00,481 - INFO - --- Época 61/250 ---\n",
      "2026-01-04 17:09:42,138 - INFO - Train Loss: 0.9370 Acc: 0.6325   \n",
      "2026-01-04 17:09:42,987 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:09:42,988 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 17:09:42,990 - INFO - Val Loss: 0.9256 Acc: 0.6567\n",
      "2026-01-04 17:09:42,991 - INFO - --- Época 62/250 ---\n",
      "2026-01-04 17:10:16,288 - INFO - Train Loss: 0.9527 Acc: 0.6329   \n",
      "2026-01-04 17:10:16,905 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:10:16,905 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 17:10:16,907 - INFO - Val Loss: 0.9672 Acc: 0.6767\n",
      "2026-01-04 17:10:16,907 - INFO - --- Época 63/250 ---\n",
      "2026-01-04 17:10:50,202 - INFO - Train Loss: 0.9543 Acc: 0.6279   \n",
      "2026-01-04 17:10:50,850 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:10:50,851 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 17:10:50,852 - INFO - Val Loss: 0.9537 Acc: 0.6700\n",
      "2026-01-04 17:10:50,852 - INFO - --- Época 64/250 ---\n",
      "2026-01-04 17:11:24,557 - INFO - Train Loss: 0.9336 Acc: 0.6296   \n",
      "2026-01-04 17:11:25,152 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:11:25,153 - INFO -   [Mejora Loss] 0.8878 -> 0.8872. Reseteando paciencia.\n",
      "2026-01-04 17:11:25,608 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:11:25,609 - INFO - Val Loss: 0.8872 Acc: 0.6800\n",
      "2026-01-04 17:11:25,610 - INFO - --- Época 65/250 ---\n",
      "2026-01-04 17:11:59,160 - INFO - Train Loss: 0.9546 Acc: 0.6400   \n",
      "2026-01-04 17:11:59,944 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:11:59,945 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 17:11:59,946 - INFO - Val Loss: 0.9163 Acc: 0.6800\n",
      "2026-01-04 17:11:59,946 - INFO - --- Época 66/250 ---\n",
      "2026-01-04 17:12:33,753 - INFO - Train Loss: 0.9175 Acc: 0.6379   \n",
      "2026-01-04 17:12:34,398 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:12:34,399 - INFO -   [Mejora Loss] 0.8872 -> 0.8383. Reseteando paciencia.\n",
      "2026-01-04 17:12:34,817 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:12:34,819 - INFO - Val Loss: 0.8383 Acc: 0.6900\n",
      "2026-01-04 17:12:34,822 - INFO - --- Época 67/250 ---\n",
      "2026-01-04 17:13:08,549 - INFO - Train Loss: 0.9136 Acc: 0.6417   \n",
      "2026-01-04 17:13:09,172 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:13:09,173 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 17:13:09,174 - INFO - Val Loss: 1.0399 Acc: 0.6267\n",
      "2026-01-04 17:13:09,175 - INFO - --- Época 68/250 ---\n",
      "2026-01-04 17:13:43,300 - INFO - Train Loss: 0.8985 Acc: 0.6458   \n",
      "2026-01-04 17:13:43,846 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:13:43,847 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 17:13:43,848 - INFO - Val Loss: 0.8888 Acc: 0.6967\n",
      "2026-01-04 17:13:43,849 - INFO - --- Época 69/250 ---\n",
      "2026-01-04 17:14:17,057 - INFO - Train Loss: 0.9306 Acc: 0.6458   \n",
      "2026-01-04 17:14:17,758 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:14:17,758 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 17:14:17,760 - INFO - Val Loss: 0.9629 Acc: 0.6733\n",
      "2026-01-04 17:14:17,761 - INFO - --- Época 70/250 ---\n",
      "2026-01-04 17:14:58,403 - INFO - Train Loss: 0.9306 Acc: 0.6388   \n",
      "2026-01-04 17:14:59,333 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:14:59,333 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 17:14:59,335 - INFO - Val Loss: 0.8836 Acc: 0.6867\n",
      "2026-01-04 17:14:59,336 - INFO - --- Época 71/250 ---\n",
      "2026-01-04 17:15:41,763 - INFO - Train Loss: 0.9397 Acc: 0.6454   \n",
      "2026-01-04 17:15:42,715 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:15:42,716 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 17:15:42,718 - INFO - Val Loss: 0.9117 Acc: 0.6800\n",
      "2026-01-04 17:15:42,719 - INFO - --- Época 72/250 ---\n",
      "2026-01-04 17:16:24,180 - INFO - Train Loss: 0.9128 Acc: 0.6446   \n",
      "2026-01-04 17:16:24,821 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:16:24,822 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 17:16:24,823 - INFO - Val Loss: 0.8598 Acc: 0.7067\n",
      "2026-01-04 17:16:24,824 - INFO - --- Época 73/250 ---\n",
      "2026-01-04 17:17:06,318 - INFO - Train Loss: 0.9076 Acc: 0.6467   \n",
      "2026-01-04 17:17:07,170 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:17:07,171 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 17:17:07,172 - INFO - Val Loss: 0.9099 Acc: 0.6533\n",
      "2026-01-04 17:17:07,173 - INFO - --- Época 74/250 ---\n",
      "2026-01-04 17:17:49,322 - INFO - Train Loss: 0.9257 Acc: 0.6433   \n",
      "2026-01-04 17:17:50,127 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:17:50,128 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 17:17:50,129 - INFO - Val Loss: 0.8807 Acc: 0.6700\n",
      "2026-01-04 17:17:50,130 - INFO - --- Época 75/250 ---\n",
      "2026-01-04 17:18:58,143 - INFO - Train Loss: 0.8979 Acc: 0.6533   \n",
      "2026-01-04 17:19:00,278 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:19:00,278 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 17:19:00,279 - INFO - Val Loss: 0.8991 Acc: 0.6867\n",
      "2026-01-04 17:19:00,280 - INFO - --- Época 76/250 ---\n",
      "2026-01-04 17:20:40,906 - INFO - Train Loss: 0.9116 Acc: 0.6496   \n",
      "2026-01-04 17:20:43,160 - INFO -   [LR] Tasa de aprendizaje actual: 0.000500\n",
      "2026-01-04 17:20:43,161 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 17:20:43,162 - INFO - Val Loss: 0.9189 Acc: 0.6500\n",
      "2026-01-04 17:20:43,163 - INFO - --- Época 77/250 ---\n",
      "2026-01-04 17:21:38,126 - INFO - Train Loss: 0.8819 Acc: 0.6533   \n",
      "2026-01-04 17:21:38,864 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:21:38,865 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 17:21:38,866 - INFO - Val Loss: 0.8943 Acc: 0.6667\n",
      "2026-01-04 17:21:38,867 - INFO - --- Época 78/250 ---\n",
      "2026-01-04 17:23:11,995 - INFO - Train Loss: 0.8795 Acc: 0.6675   \n",
      "2026-01-04 17:23:14,069 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:23:14,070 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2026-01-04 17:23:14,071 - INFO - Val Loss: 0.8537 Acc: 0.6867\n",
      "2026-01-04 17:23:14,072 - INFO - --- Época 79/250 ---\n",
      "2026-01-04 17:24:51,549 - INFO - Train Loss: 0.8561 Acc: 0.6692   \n",
      "2026-01-04 17:24:53,735 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:24:53,736 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2026-01-04 17:24:53,738 - INFO - Val Loss: 0.8894 Acc: 0.6967\n",
      "2026-01-04 17:24:53,739 - INFO - --- Época 80/250 ---\n",
      "2026-01-04 17:26:13,100 - INFO - Train Loss: 0.8573 Acc: 0.6708   \n",
      "2026-01-04 17:26:13,885 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:26:13,886 - INFO -   [Sin mejora Loss] Paciencia: 14/50\n",
      "2026-01-04 17:26:13,886 - INFO - Val Loss: 0.8979 Acc: 0.6867\n",
      "2026-01-04 17:26:13,887 - INFO - --- Época 81/250 ---\n",
      "2026-01-04 17:26:55,816 - INFO - Train Loss: 0.8650 Acc: 0.6754   \n",
      "2026-01-04 17:26:56,545 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:26:56,546 - INFO -   [Sin mejora Loss] Paciencia: 15/50\n",
      "2026-01-04 17:26:56,547 - INFO - Val Loss: 0.8637 Acc: 0.7067\n",
      "2026-01-04 17:26:56,547 - INFO - --- Época 82/250 ---\n",
      "2026-01-04 17:27:38,972 - INFO - Train Loss: 0.8687 Acc: 0.6629   \n",
      "2026-01-04 17:27:39,750 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:27:39,751 - INFO -   [Sin mejora Loss] Paciencia: 16/50\n",
      "2026-01-04 17:27:39,753 - INFO - Val Loss: 0.8741 Acc: 0.6833\n",
      "2026-01-04 17:27:39,754 - INFO - --- Época 83/250 ---\n",
      "2026-01-04 17:28:21,217 - INFO - Train Loss: 0.8458 Acc: 0.6733   \n",
      "2026-01-04 17:28:21,958 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:28:21,959 - INFO -   [Mejora Loss] 0.8383 -> 0.8122. Reseteando paciencia.\n",
      "2026-01-04 17:28:22,432 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:28:22,434 - INFO - Val Loss: 0.8122 Acc: 0.7033\n",
      "2026-01-04 17:28:22,435 - INFO - --- Época 84/250 ---\n",
      "2026-01-04 17:29:04,080 - INFO - Train Loss: 0.8415 Acc: 0.6646   \n",
      "2026-01-04 17:29:04,844 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:29:04,845 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 17:29:04,846 - INFO - Val Loss: 0.8592 Acc: 0.6900\n",
      "2026-01-04 17:29:04,847 - INFO - --- Época 85/250 ---\n",
      "2026-01-04 17:29:45,189 - INFO - Train Loss: 0.8555 Acc: 0.6679   \n",
      "2026-01-04 17:29:46,025 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:29:46,026 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 17:29:46,028 - INFO - Val Loss: 0.8376 Acc: 0.7200\n",
      "2026-01-04 17:29:46,028 - INFO - --- Época 86/250 ---\n",
      "2026-01-04 17:30:48,857 - INFO - Train Loss: 0.8467 Acc: 0.6742   \n",
      "2026-01-04 17:30:50,831 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:30:50,834 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 17:30:50,837 - INFO - Val Loss: 0.8636 Acc: 0.6967\n",
      "2026-01-04 17:30:50,839 - INFO - --- Época 87/250 ---\n",
      "2026-01-04 17:32:27,352 - INFO - Train Loss: 0.8370 Acc: 0.6692   \n",
      "2026-01-04 17:32:30,121 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:32:30,123 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 17:32:30,126 - INFO - Val Loss: 0.9001 Acc: 0.6800\n",
      "2026-01-04 17:32:30,131 - INFO - --- Época 88/250 ---\n",
      "2026-01-04 17:34:06,269 - INFO - Train Loss: 0.8168 Acc: 0.6850   \n",
      "2026-01-04 17:34:11,195 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:34:11,196 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 17:34:11,198 - INFO - Val Loss: 0.8383 Acc: 0.7033\n",
      "2026-01-04 17:34:11,199 - INFO - --- Época 89/250 ---\n",
      "2026-01-04 17:35:48,963 - INFO - Train Loss: 0.8326 Acc: 0.6713   \n",
      "2026-01-04 17:35:51,432 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:35:51,433 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 17:35:51,435 - INFO - Val Loss: 0.8283 Acc: 0.7000\n",
      "2026-01-04 17:35:51,437 - INFO - --- Época 90/250 ---\n",
      "2026-01-04 17:37:36,826 - INFO - Train Loss: 0.8708 Acc: 0.6679   \n",
      "2026-01-04 17:37:39,278 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:37:39,279 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 17:37:39,281 - INFO - Val Loss: 0.8414 Acc: 0.7100\n",
      "2026-01-04 17:37:39,282 - INFO - --- Época 91/250 ---\n",
      "2026-01-04 17:39:17,799 - INFO - Train Loss: 0.8346 Acc: 0.6829   \n",
      "2026-01-04 17:39:23,433 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:39:23,434 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 17:39:23,436 - INFO - Val Loss: 0.9130 Acc: 0.6567\n",
      "2026-01-04 17:39:23,437 - INFO - --- Época 92/250 ---\n",
      "2026-01-04 17:41:01,547 - INFO - Train Loss: 0.8151 Acc: 0.6863   \n",
      "2026-01-04 17:41:05,154 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:41:05,155 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 17:41:05,156 - INFO - Val Loss: 0.8878 Acc: 0.6733\n",
      "2026-01-04 17:41:05,157 - INFO - --- Época 93/250 ---\n",
      "2026-01-04 17:42:45,011 - INFO - Train Loss: 0.8327 Acc: 0.6725   \n",
      "2026-01-04 17:42:47,570 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:42:47,572 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 17:42:47,574 - INFO - Val Loss: 0.8561 Acc: 0.6933\n",
      "2026-01-04 17:42:47,575 - INFO - --- Época 94/250 ---\n",
      "2026-01-04 17:44:29,413 - INFO - Train Loss: 0.8165 Acc: 0.6825   \n",
      "2026-01-04 17:44:31,570 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:44:31,571 - INFO -   [Mejora Loss] 0.8122 -> 0.7932. Reseteando paciencia.\n",
      "2026-01-04 17:44:32,295 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 17:44:32,297 - INFO - Val Loss: 0.7932 Acc: 0.7233\n",
      "2026-01-04 17:44:32,298 - INFO - --- Época 95/250 ---\n",
      "2026-01-04 17:46:15,866 - INFO - Train Loss: 0.8329 Acc: 0.6875   \n",
      "2026-01-04 17:46:18,650 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:46:18,651 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 17:46:18,654 - INFO - Val Loss: 0.8878 Acc: 0.6867\n",
      "2026-01-04 17:46:18,655 - INFO - --- Época 96/250 ---\n",
      "2026-01-04 17:48:03,727 - INFO - Train Loss: 0.8114 Acc: 0.6900   \n",
      "2026-01-04 17:48:06,975 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:48:06,976 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 17:48:06,978 - INFO - Val Loss: 0.8611 Acc: 0.6800\n",
      "2026-01-04 17:48:06,980 - INFO - --- Época 97/250 ---\n",
      "2026-01-04 17:49:47,245 - INFO - Train Loss: 0.8110 Acc: 0.6942   \n",
      "2026-01-04 17:49:49,785 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:49:49,787 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 17:49:49,788 - INFO - Val Loss: 0.8901 Acc: 0.6667\n",
      "2026-01-04 17:49:49,789 - INFO - --- Época 98/250 ---\n",
      "2026-01-04 17:51:28,703 - INFO - Train Loss: 0.8121 Acc: 0.6817   \n",
      "2026-01-04 17:51:29,532 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:51:29,533 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 17:51:29,534 - INFO - Val Loss: 0.8152 Acc: 0.7100\n",
      "2026-01-04 17:51:29,535 - INFO - --- Época 99/250 ---\n",
      "2026-01-04 17:53:11,561 - INFO - Train Loss: 0.8393 Acc: 0.6871   \n",
      "2026-01-04 17:53:13,818 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:53:13,819 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 17:53:13,820 - INFO - Val Loss: 0.8254 Acc: 0.7133\n",
      "2026-01-04 17:53:13,821 - INFO - --- Época 100/250 ---\n",
      "2026-01-04 17:54:53,804 - INFO - Train Loss: 0.8064 Acc: 0.6917   \n",
      "2026-01-04 17:54:56,019 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:54:56,035 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 17:54:56,037 - INFO - Val Loss: 0.9089 Acc: 0.6667\n",
      "2026-01-04 17:54:56,039 - INFO - --- Época 101/250 ---\n",
      "2026-01-04 17:56:31,995 - INFO - Train Loss: 0.8350 Acc: 0.6775   \n",
      "2026-01-04 17:56:34,368 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:56:34,370 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 17:56:34,373 - INFO - Val Loss: 0.8392 Acc: 0.7000\n",
      "2026-01-04 17:56:34,376 - INFO - --- Época 102/250 ---\n",
      "2026-01-04 17:58:14,721 - INFO - Train Loss: 0.8300 Acc: 0.6813   \n",
      "2026-01-04 17:58:16,932 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 17:58:16,933 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 17:58:16,934 - INFO - Val Loss: 0.8483 Acc: 0.6833\n",
      "2026-01-04 17:58:16,935 - INFO - --- Época 103/250 ---\n",
      "2026-01-04 17:59:58,997 - INFO - Train Loss: 0.8145 Acc: 0.6883   \n",
      "2026-01-04 18:00:01,303 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 18:00:01,304 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 18:00:01,306 - INFO - Val Loss: 0.9813 Acc: 0.6533\n",
      "2026-01-04 18:00:01,319 - INFO - --- Época 104/250 ---\n",
      "2026-01-04 18:01:38,108 - INFO - Train Loss: 0.8092 Acc: 0.6800   \n",
      "2026-01-04 18:01:41,251 - INFO -   [LR] Tasa de aprendizaje actual: 0.000250\n",
      "2026-01-04 18:01:41,254 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 18:01:41,257 - INFO - Val Loss: 0.8093 Acc: 0.6800\n",
      "2026-01-04 18:01:41,261 - INFO - --- Época 105/250 ---\n",
      "2026-01-04 18:03:19,609 - INFO - Train Loss: 0.7905 Acc: 0.6975   \n",
      "2026-01-04 18:03:25,323 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:03:25,324 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 18:03:25,325 - INFO - Val Loss: 0.8656 Acc: 0.6833\n",
      "2026-01-04 18:03:25,325 - INFO - --- Época 106/250 ---\n",
      "2026-01-04 18:05:00,913 - INFO - Train Loss: 0.7842 Acc: 0.6946   \n",
      "2026-01-04 18:05:04,292 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:05:04,294 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2026-01-04 18:05:04,296 - INFO - Val Loss: 0.8189 Acc: 0.7000\n",
      "2026-01-04 18:05:04,299 - INFO - --- Época 107/250 ---\n",
      "2026-01-04 18:06:45,331 - INFO - Train Loss: 0.7796 Acc: 0.7004   \n",
      "2026-01-04 18:06:48,515 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:06:48,517 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2026-01-04 18:06:48,518 - INFO - Val Loss: 0.8162 Acc: 0.6967\n",
      "2026-01-04 18:06:48,519 - INFO - --- Época 108/250 ---\n",
      "2026-01-04 18:08:28,632 - INFO - Train Loss: 0.7821 Acc: 0.7079   \n",
      "2026-01-04 18:08:30,950 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:08:30,951 - INFO -   [Mejora Loss] 0.7932 -> 0.7856. Reseteando paciencia.\n",
      "2026-01-04 18:08:31,454 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:08:31,477 - INFO - Val Loss: 0.7856 Acc: 0.7000\n",
      "2026-01-04 18:08:31,479 - INFO - --- Época 109/250 ---\n",
      "2026-01-04 18:10:08,720 - INFO - Train Loss: 0.7699 Acc: 0.7050   \n",
      "2026-01-04 18:10:10,926 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:10:10,927 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:10:10,943 - INFO - Val Loss: 0.8323 Acc: 0.7000\n",
      "2026-01-04 18:10:10,945 - INFO - --- Época 110/250 ---\n",
      "2026-01-04 18:11:50,838 - INFO - Train Loss: 0.7654 Acc: 0.7092   \n",
      "2026-01-04 18:11:53,016 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:11:53,017 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:11:53,018 - INFO - Val Loss: 0.7958 Acc: 0.6933\n",
      "2026-01-04 18:11:53,019 - INFO - --- Época 111/250 ---\n",
      "2026-01-04 18:13:33,329 - INFO - Train Loss: 0.7603 Acc: 0.6983   \n",
      "2026-01-04 18:13:37,143 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:13:37,145 - INFO -   [Mejora Loss] 0.7856 -> 0.7788. Reseteando paciencia.\n",
      "2026-01-04 18:13:37,705 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:13:37,706 - INFO - Val Loss: 0.7788 Acc: 0.7267\n",
      "2026-01-04 18:13:37,707 - INFO - --- Época 112/250 ---\n",
      "2026-01-04 18:15:17,686 - INFO - Train Loss: 0.7567 Acc: 0.7188   \n",
      "2026-01-04 18:15:21,618 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:15:21,619 - INFO -   [Mejora Loss] 0.7788 -> 0.7685. Reseteando paciencia.\n",
      "2026-01-04 18:15:22,102 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:15:22,105 - INFO - Val Loss: 0.7685 Acc: 0.7300\n",
      "2026-01-04 18:15:22,106 - INFO - --- Época 113/250 ---\n",
      "2026-01-04 18:17:06,259 - INFO - Train Loss: 0.7226 Acc: 0.7183   \n",
      "2026-01-04 18:17:10,129 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:17:10,131 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:17:10,132 - INFO - Val Loss: 0.8049 Acc: 0.7133\n",
      "2026-01-04 18:17:10,133 - INFO - --- Época 114/250 ---\n",
      "2026-01-04 18:18:54,896 - INFO - Train Loss: 0.7751 Acc: 0.6996   \n",
      "2026-01-04 18:18:57,278 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:18:57,280 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:18:57,282 - INFO - Val Loss: 0.7992 Acc: 0.7167\n",
      "2026-01-04 18:18:57,284 - INFO - --- Época 115/250 ---\n",
      "2026-01-04 18:20:32,614 - INFO - Train Loss: 0.7652 Acc: 0.7067   \n",
      "2026-01-04 18:20:33,364 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:20:33,365 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:20:33,366 - INFO - Val Loss: 0.8218 Acc: 0.6933\n",
      "2026-01-04 18:20:33,367 - INFO - --- Época 116/250 ---\n",
      "2026-01-04 18:21:15,028 - INFO - Train Loss: 0.7671 Acc: 0.7046   \n",
      "2026-01-04 18:21:15,775 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:21:15,776 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 18:21:15,777 - INFO - Val Loss: 0.7715 Acc: 0.7133\n",
      "2026-01-04 18:21:15,778 - INFO - --- Época 117/250 ---\n",
      "2026-01-04 18:21:56,966 - INFO - Train Loss: 0.7534 Acc: 0.7058   \n",
      "2026-01-04 18:21:57,683 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:21:57,684 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 18:21:57,685 - INFO - Val Loss: 0.7916 Acc: 0.7200\n",
      "2026-01-04 18:21:57,686 - INFO - --- Época 118/250 ---\n",
      "2026-01-04 18:22:38,439 - INFO - Train Loss: 0.7441 Acc: 0.7208   \n",
      "2026-01-04 18:22:39,146 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:22:39,147 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 18:22:39,148 - INFO - Val Loss: 0.8309 Acc: 0.6833\n",
      "2026-01-04 18:22:39,149 - INFO - --- Época 119/250 ---\n",
      "2026-01-04 18:23:20,081 - INFO - Train Loss: 0.7590 Acc: 0.7079   \n",
      "2026-01-04 18:23:20,812 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:23:20,813 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 18:23:20,814 - INFO - Val Loss: 0.8328 Acc: 0.7033\n",
      "2026-01-04 18:23:20,815 - INFO - --- Época 120/250 ---\n",
      "2026-01-04 18:24:00,591 - INFO - Train Loss: 0.7431 Acc: 0.7146   \n",
      "2026-01-04 18:24:01,243 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:24:01,244 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 18:24:01,245 - INFO - Val Loss: 0.8059 Acc: 0.7167\n",
      "2026-01-04 18:24:01,246 - INFO - --- Época 121/250 ---\n",
      "2026-01-04 18:24:40,587 - INFO - Train Loss: 0.7572 Acc: 0.7192   \n",
      "2026-01-04 18:24:41,260 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:24:41,261 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 18:24:41,262 - INFO - Val Loss: 0.7808 Acc: 0.7267\n",
      "2026-01-04 18:24:41,263 - INFO - --- Época 122/250 ---\n",
      "2026-01-04 18:25:20,747 - INFO - Train Loss: 0.7450 Acc: 0.7154   \n",
      "2026-01-04 18:25:21,430 - INFO -   [LR] Tasa de aprendizaje actual: 0.000125\n",
      "2026-01-04 18:25:21,430 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 18:25:21,431 - INFO - Val Loss: 0.7743 Acc: 0.7233\n",
      "2026-01-04 18:25:21,432 - INFO - --- Época 123/250 ---\n",
      "2026-01-04 18:26:01,972 - INFO - Train Loss: 0.7291 Acc: 0.7167   \n",
      "2026-01-04 18:26:02,637 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:26:02,639 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 18:26:02,640 - INFO - Val Loss: 0.7727 Acc: 0.7100\n",
      "2026-01-04 18:26:02,640 - INFO - --- Época 124/250 ---\n",
      "2026-01-04 18:26:42,764 - INFO - Train Loss: 0.7130 Acc: 0.7229   \n",
      "2026-01-04 18:26:43,440 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:26:43,441 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2026-01-04 18:26:43,442 - INFO - Val Loss: 0.7804 Acc: 0.7233\n",
      "2026-01-04 18:26:43,443 - INFO - --- Época 125/250 ---\n",
      "2026-01-04 18:27:19,174 - INFO - Train Loss: 0.7342 Acc: 0.7275   \n",
      "2026-01-04 18:27:19,795 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:27:19,796 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2026-01-04 18:27:19,797 - INFO - Val Loss: 0.7712 Acc: 0.7367\n",
      "2026-01-04 18:27:19,798 - INFO - --- Época 126/250 ---\n",
      "2026-01-04 18:27:53,439 - INFO - Train Loss: 0.7232 Acc: 0.7254   \n",
      "2026-01-04 18:27:54,028 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:27:54,029 - INFO -   [Mejora Loss] 0.7685 -> 0.7489. Reseteando paciencia.\n",
      "2026-01-04 18:27:54,460 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:27:54,462 - INFO - Val Loss: 0.7489 Acc: 0.7300\n",
      "2026-01-04 18:27:54,463 - INFO - --- Época 127/250 ---\n",
      "2026-01-04 18:28:27,886 - INFO - Train Loss: 0.7338 Acc: 0.7275   \n",
      "2026-01-04 18:28:28,530 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:28:28,531 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:28:28,532 - INFO - Val Loss: 0.7555 Acc: 0.7367\n",
      "2026-01-04 18:28:28,533 - INFO - --- Época 128/250 ---\n",
      "2026-01-04 18:29:02,337 - INFO - Train Loss: 0.7120 Acc: 0.7279   \n",
      "2026-01-04 18:29:02,896 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:29:02,897 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:29:02,899 - INFO - Val Loss: 0.7580 Acc: 0.7167\n",
      "2026-01-04 18:29:02,901 - INFO - --- Época 129/250 ---\n",
      "2026-01-04 18:29:37,288 - INFO - Train Loss: 0.7123 Acc: 0.7217   \n",
      "2026-01-04 18:29:37,966 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:29:37,967 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:29:37,968 - INFO - Val Loss: 0.7629 Acc: 0.7200\n",
      "2026-01-04 18:29:37,969 - INFO - --- Época 130/250 ---\n",
      "2026-01-04 18:30:12,239 - INFO - Train Loss: 0.7092 Acc: 0.7288   \n",
      "2026-01-04 18:30:12,873 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:30:12,875 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 18:30:12,876 - INFO - Val Loss: 0.7828 Acc: 0.7267\n",
      "2026-01-04 18:30:12,876 - INFO - --- Época 131/250 ---\n",
      "2026-01-04 18:30:45,881 - INFO - Train Loss: 0.7118 Acc: 0.7388   \n",
      "2026-01-04 18:30:46,488 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:30:46,489 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 18:30:46,490 - INFO - Val Loss: 0.7551 Acc: 0.7233\n",
      "2026-01-04 18:30:46,492 - INFO - --- Época 132/250 ---\n",
      "2026-01-04 18:31:20,070 - INFO - Train Loss: 0.7262 Acc: 0.7279   \n",
      "2026-01-04 18:31:20,700 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:31:20,700 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 18:31:20,702 - INFO - Val Loss: 0.7753 Acc: 0.7267\n",
      "2026-01-04 18:31:20,703 - INFO - --- Época 133/250 ---\n",
      "2026-01-04 18:31:54,072 - INFO - Train Loss: 0.7089 Acc: 0.7329   \n",
      "2026-01-04 18:31:54,679 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:31:54,680 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 18:31:54,681 - INFO - Val Loss: 0.7601 Acc: 0.7267\n",
      "2026-01-04 18:31:54,682 - INFO - --- Época 134/250 ---\n",
      "2026-01-04 18:32:27,868 - INFO - Train Loss: 0.6999 Acc: 0.7371   \n",
      "2026-01-04 18:32:28,554 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:32:28,555 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 18:32:28,556 - INFO - Val Loss: 0.7640 Acc: 0.7267\n",
      "2026-01-04 18:32:28,557 - INFO - --- Época 135/250 ---\n",
      "2026-01-04 18:33:03,027 - INFO - Train Loss: 0.7272 Acc: 0.7233   \n",
      "2026-01-04 18:33:03,668 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:33:03,669 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 18:33:03,670 - INFO - Val Loss: 0.7667 Acc: 0.7300\n",
      "2026-01-04 18:33:03,671 - INFO - --- Época 136/250 ---\n",
      "2026-01-04 18:33:38,487 - INFO - Train Loss: 0.7147 Acc: 0.7163   \n",
      "2026-01-04 18:33:39,121 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:33:39,122 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 18:33:39,123 - INFO - Val Loss: 0.7505 Acc: 0.7300\n",
      "2026-01-04 18:33:39,124 - INFO - --- Época 137/250 ---\n",
      "2026-01-04 18:34:12,871 - INFO - Train Loss: 0.7152 Acc: 0.7296   \n",
      "2026-01-04 18:34:13,518 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:34:13,519 - INFO -   [Mejora Loss] 0.7489 -> 0.7465. Reseteando paciencia.\n",
      "2026-01-04 18:34:14,004 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:34:14,006 - INFO - Val Loss: 0.7465 Acc: 0.7333\n",
      "2026-01-04 18:34:14,007 - INFO - --- Época 138/250 ---\n",
      "2026-01-04 18:34:47,863 - INFO - Train Loss: 0.6903 Acc: 0.7346   \n",
      "2026-01-04 18:34:48,477 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:34:48,478 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:34:48,479 - INFO - Val Loss: 0.7665 Acc: 0.7233\n",
      "2026-01-04 18:34:48,480 - INFO - --- Época 139/250 ---\n",
      "2026-01-04 18:35:22,521 - INFO - Train Loss: 0.7114 Acc: 0.7271   \n",
      "2026-01-04 18:35:23,131 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:35:23,132 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:35:23,133 - INFO - Val Loss: 0.7607 Acc: 0.7233\n",
      "2026-01-04 18:35:23,134 - INFO - --- Época 140/250 ---\n",
      "2026-01-04 18:35:56,263 - INFO - Train Loss: 0.7347 Acc: 0.7229   \n",
      "2026-01-04 18:35:56,892 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:35:56,893 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:35:56,894 - INFO - Val Loss: 0.7472 Acc: 0.7267\n",
      "2026-01-04 18:35:56,895 - INFO - --- Época 141/250 ---\n",
      "2026-01-04 18:36:30,465 - INFO - Train Loss: 0.7062 Acc: 0.7233   \n",
      "2026-01-04 18:36:31,163 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:36:31,165 - INFO -   [Mejora Loss] 0.7465 -> 0.7413. Reseteando paciencia.\n",
      "2026-01-04 18:36:31,596 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:36:31,598 - INFO - Val Loss: 0.7413 Acc: 0.7433\n",
      "2026-01-04 18:36:31,599 - INFO - --- Época 142/250 ---\n",
      "2026-01-04 18:37:05,070 - INFO - Train Loss: 0.7022 Acc: 0.7283   \n",
      "2026-01-04 18:37:05,688 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:37:05,689 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:37:05,690 - INFO - Val Loss: 0.7481 Acc: 0.7267\n",
      "2026-01-04 18:37:05,691 - INFO - --- Época 143/250 ---\n",
      "2026-01-04 18:37:39,474 - INFO - Train Loss: 0.7034 Acc: 0.7279   \n",
      "2026-01-04 18:37:40,096 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:37:40,096 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:37:40,097 - INFO - Val Loss: 0.7559 Acc: 0.7233\n",
      "2026-01-04 18:37:40,098 - INFO - --- Época 144/250 ---\n",
      "2026-01-04 18:38:13,206 - INFO - Train Loss: 0.6991 Acc: 0.7317   \n",
      "2026-01-04 18:38:13,853 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:38:13,854 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:38:13,855 - INFO - Val Loss: 0.7559 Acc: 0.7333\n",
      "2026-01-04 18:38:13,857 - INFO - --- Época 145/250 ---\n",
      "2026-01-04 18:38:46,999 - INFO - Train Loss: 0.7058 Acc: 0.7308   \n",
      "2026-01-04 18:38:47,650 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:38:47,651 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 18:38:47,652 - INFO - Val Loss: 0.7643 Acc: 0.7200\n",
      "2026-01-04 18:38:47,653 - INFO - --- Época 146/250 ---\n",
      "2026-01-04 18:39:20,655 - INFO - Train Loss: 0.6925 Acc: 0.7354   \n",
      "2026-01-04 18:39:21,281 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:39:21,282 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 18:39:21,283 - INFO - Val Loss: 0.7429 Acc: 0.7333\n",
      "2026-01-04 18:39:21,284 - INFO - --- Época 147/250 ---\n",
      "2026-01-04 18:39:55,594 - INFO - Train Loss: 0.6742 Acc: 0.7258   \n",
      "2026-01-04 18:39:56,222 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:39:56,223 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 18:39:56,224 - INFO - Val Loss: 0.7664 Acc: 0.7267\n",
      "2026-01-04 18:39:56,225 - INFO - --- Época 148/250 ---\n",
      "2026-01-04 18:40:29,634 - INFO - Train Loss: 0.6853 Acc: 0.7383   \n",
      "2026-01-04 18:40:30,276 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:40:30,277 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 18:40:30,279 - INFO - Val Loss: 0.7606 Acc: 0.7233\n",
      "2026-01-04 18:40:30,280 - INFO - --- Época 149/250 ---\n",
      "2026-01-04 18:41:03,789 - INFO - Train Loss: 0.6908 Acc: 0.7321   \n",
      "2026-01-04 18:41:04,349 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:41:04,350 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 18:41:04,351 - INFO - Val Loss: 0.7646 Acc: 0.7267\n",
      "2026-01-04 18:41:04,352 - INFO - --- Época 150/250 ---\n",
      "2026-01-04 18:41:37,316 - INFO - Train Loss: 0.7090 Acc: 0.7283   \n",
      "2026-01-04 18:41:37,912 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:41:37,913 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 18:41:37,914 - INFO - Val Loss: 0.7567 Acc: 0.7300\n",
      "2026-01-04 18:41:37,915 - INFO - --- Época 151/250 ---\n",
      "2026-01-04 18:42:11,011 - INFO - Train Loss: 0.6807 Acc: 0.7408   \n",
      "2026-01-04 18:42:11,684 - INFO -   [LR] Tasa de aprendizaje actual: 0.000063\n",
      "2026-01-04 18:42:11,685 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 18:42:11,685 - INFO - Val Loss: 0.7524 Acc: 0.7333\n",
      "2026-01-04 18:42:11,686 - INFO - --- Época 152/250 ---\n",
      "2026-01-04 18:42:45,457 - INFO - Train Loss: 0.7046 Acc: 0.7350   \n",
      "2026-01-04 18:42:46,070 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:42:46,071 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 18:42:46,072 - INFO - Val Loss: 0.7630 Acc: 0.7233\n",
      "2026-01-04 18:42:46,073 - INFO - --- Época 153/250 ---\n",
      "2026-01-04 18:43:19,703 - INFO - Train Loss: 0.6839 Acc: 0.7438   \n",
      "2026-01-04 18:43:20,335 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:43:20,336 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2026-01-04 18:43:20,338 - INFO - Val Loss: 0.7422 Acc: 0.7333\n",
      "2026-01-04 18:43:20,338 - INFO - --- Época 154/250 ---\n",
      "2026-01-04 18:43:53,705 - INFO - Train Loss: 0.6915 Acc: 0.7404   \n",
      "2026-01-04 18:43:54,338 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:43:54,340 - INFO -   [Mejora Loss] 0.7413 -> 0.7396. Reseteando paciencia.\n",
      "2026-01-04 18:43:54,776 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:43:54,778 - INFO - Val Loss: 0.7396 Acc: 0.7300\n",
      "2026-01-04 18:43:54,780 - INFO - --- Época 155/250 ---\n",
      "2026-01-04 18:44:28,946 - INFO - Train Loss: 0.6734 Acc: 0.7421   \n",
      "2026-01-04 18:44:29,615 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:44:29,617 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:44:29,618 - INFO - Val Loss: 0.7506 Acc: 0.7300\n",
      "2026-01-04 18:44:29,619 - INFO - --- Época 156/250 ---\n",
      "2026-01-04 18:45:03,533 - INFO - Train Loss: 0.6710 Acc: 0.7433   \n",
      "2026-01-04 18:45:04,164 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:45:04,165 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:45:04,166 - INFO - Val Loss: 0.7450 Acc: 0.7300\n",
      "2026-01-04 18:45:04,167 - INFO - --- Época 157/250 ---\n",
      "2026-01-04 18:45:38,062 - INFO - Train Loss: 0.6646 Acc: 0.7438   \n",
      "2026-01-04 18:45:38,720 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:45:38,721 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:45:38,722 - INFO - Val Loss: 0.7444 Acc: 0.7367\n",
      "2026-01-04 18:45:38,723 - INFO - --- Época 158/250 ---\n",
      "2026-01-04 18:46:12,206 - INFO - Train Loss: 0.6801 Acc: 0.7392   \n",
      "2026-01-04 18:46:12,858 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:46:12,858 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 18:46:12,860 - INFO - Val Loss: 0.7618 Acc: 0.7367\n",
      "2026-01-04 18:46:12,860 - INFO - --- Época 159/250 ---\n",
      "2026-01-04 18:46:46,683 - INFO - Train Loss: 0.6888 Acc: 0.7317   \n",
      "2026-01-04 18:46:47,287 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:46:47,289 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 18:46:47,290 - INFO - Val Loss: 0.7487 Acc: 0.7300\n",
      "2026-01-04 18:46:47,290 - INFO - --- Época 160/250 ---\n",
      "2026-01-04 18:47:21,185 - INFO - Train Loss: 0.6769 Acc: 0.7467   \n",
      "2026-01-04 18:47:21,754 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:47:21,754 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 18:47:21,755 - INFO - Val Loss: 0.7601 Acc: 0.7233\n",
      "2026-01-04 18:47:21,756 - INFO - --- Época 161/250 ---\n",
      "2026-01-04 18:47:54,915 - INFO - Train Loss: 0.6824 Acc: 0.7450   \n",
      "2026-01-04 18:47:55,576 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:47:55,577 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 18:47:55,579 - INFO - Val Loss: 0.7459 Acc: 0.7433\n",
      "2026-01-04 18:47:55,580 - INFO - --- Época 162/250 ---\n",
      "2026-01-04 18:48:29,328 - INFO - Train Loss: 0.6484 Acc: 0.7588   \n",
      "2026-01-04 18:48:29,935 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:48:29,936 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 18:48:29,937 - INFO - Val Loss: 0.7399 Acc: 0.7300\n",
      "2026-01-04 18:48:29,938 - INFO - --- Época 163/250 ---\n",
      "2026-01-04 18:49:04,396 - INFO - Train Loss: 0.6904 Acc: 0.7379   \n",
      "2026-01-04 18:49:05,013 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:49:05,013 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 18:49:05,014 - INFO - Val Loss: 0.7631 Acc: 0.7333\n",
      "2026-01-04 18:49:05,015 - INFO - --- Época 164/250 ---\n",
      "2026-01-04 18:49:40,328 - INFO - Train Loss: 0.6481 Acc: 0.7500   \n",
      "2026-01-04 18:49:40,967 - INFO -   [LR] Tasa de aprendizaje actual: 0.000031\n",
      "2026-01-04 18:49:40,968 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 18:49:40,969 - INFO - Val Loss: 0.7451 Acc: 0.7267\n",
      "2026-01-04 18:49:40,970 - INFO - --- Época 165/250 ---\n",
      "2026-01-04 18:50:14,668 - INFO - Train Loss: 0.6816 Acc: 0.7358   \n",
      "2026-01-04 18:50:15,275 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:50:15,275 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 18:50:15,277 - INFO - Val Loss: 0.7425 Acc: 0.7367\n",
      "2026-01-04 18:50:15,278 - INFO - --- Época 166/250 ---\n",
      "2026-01-04 18:50:49,073 - INFO - Train Loss: 0.6642 Acc: 0.7471   \n",
      "2026-01-04 18:50:49,688 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:50:49,688 - INFO -   [Mejora Loss] 0.7396 -> 0.7390. Reseteando paciencia.\n",
      "2026-01-04 18:50:50,110 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:50:50,111 - INFO - Val Loss: 0.7390 Acc: 0.7300\n",
      "2026-01-04 18:50:50,113 - INFO - --- Época 167/250 ---\n",
      "2026-01-04 18:51:23,221 - INFO - Train Loss: 0.6703 Acc: 0.7446   \n",
      "2026-01-04 18:51:23,837 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:51:23,838 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:51:23,839 - INFO - Val Loss: 0.7408 Acc: 0.7233\n",
      "2026-01-04 18:51:23,839 - INFO - --- Época 168/250 ---\n",
      "2026-01-04 18:51:58,554 - INFO - Train Loss: 0.6574 Acc: 0.7467   \n",
      "2026-01-04 18:51:59,163 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:51:59,164 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:51:59,165 - INFO - Val Loss: 0.7463 Acc: 0.7300\n",
      "2026-01-04 18:51:59,166 - INFO - --- Época 169/250 ---\n",
      "2026-01-04 18:52:32,998 - INFO - Train Loss: 0.6695 Acc: 0.7521   \n",
      "2026-01-04 18:52:33,599 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:52:33,600 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:52:33,602 - INFO - Val Loss: 0.7486 Acc: 0.7300\n",
      "2026-01-04 18:52:33,603 - INFO - --- Época 170/250 ---\n",
      "2026-01-04 18:53:07,181 - INFO - Train Loss: 0.6674 Acc: 0.7446   \n",
      "2026-01-04 18:53:07,821 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:53:07,822 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 18:53:07,823 - INFO - Val Loss: 0.7435 Acc: 0.7267\n",
      "2026-01-04 18:53:07,824 - INFO - --- Época 171/250 ---\n",
      "2026-01-04 18:53:41,810 - INFO - Train Loss: 0.6760 Acc: 0.7383   \n",
      "2026-01-04 18:53:42,469 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:53:42,470 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 18:53:42,472 - INFO - Val Loss: 0.7407 Acc: 0.7333\n",
      "2026-01-04 18:53:42,473 - INFO - --- Época 172/250 ---\n",
      "2026-01-04 18:54:17,007 - INFO - Train Loss: 0.6626 Acc: 0.7488   \n",
      "2026-01-04 18:54:17,715 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:54:17,716 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 18:54:17,717 - INFO - Val Loss: 0.7407 Acc: 0.7400\n",
      "2026-01-04 18:54:17,718 - INFO - --- Época 173/250 ---\n",
      "2026-01-04 18:54:51,372 - INFO - Train Loss: 0.6602 Acc: 0.7479   \n",
      "2026-01-04 18:54:51,975 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:54:51,975 - INFO -   [Mejora Loss] 0.7390 -> 0.7382. Reseteando paciencia.\n",
      "2026-01-04 18:54:52,432 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:54:52,435 - INFO - Val Loss: 0.7382 Acc: 0.7400\n",
      "2026-01-04 18:54:52,437 - INFO - --- Época 174/250 ---\n",
      "2026-01-04 18:55:26,615 - INFO - Train Loss: 0.6569 Acc: 0.7579   \n",
      "2026-01-04 18:55:27,326 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:55:27,327 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:55:27,328 - INFO - Val Loss: 0.7442 Acc: 0.7433\n",
      "2026-01-04 18:55:27,328 - INFO - --- Época 175/250 ---\n",
      "2026-01-04 18:56:00,718 - INFO - Train Loss: 0.6717 Acc: 0.7500   \n",
      "2026-01-04 18:56:01,350 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:56:01,351 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:56:01,352 - INFO - Val Loss: 0.7400 Acc: 0.7367\n",
      "2026-01-04 18:56:01,353 - INFO - --- Época 176/250 ---\n",
      "2026-01-04 18:56:34,400 - INFO - Train Loss: 0.6555 Acc: 0.7404   \n",
      "2026-01-04 18:56:34,991 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:56:34,992 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:56:34,994 - INFO - Val Loss: 0.7416 Acc: 0.7333\n",
      "2026-01-04 18:56:34,995 - INFO - --- Época 177/250 ---\n",
      "2026-01-04 18:57:09,540 - INFO - Train Loss: 0.6782 Acc: 0.7450   \n",
      "2026-01-04 18:57:10,160 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:57:10,161 - INFO -   [Mejora Loss] 0.7382 -> 0.7317. Reseteando paciencia.\n",
      "2026-01-04 18:57:10,576 - INFO -   [Nuevo Récord Loss] Guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\best_model.pth\n",
      "2026-01-04 18:57:10,578 - INFO - Val Loss: 0.7317 Acc: 0.7333\n",
      "2026-01-04 18:57:10,579 - INFO - --- Época 178/250 ---\n",
      "2026-01-04 18:57:44,339 - INFO - Train Loss: 0.6675 Acc: 0.7429   \n",
      "2026-01-04 18:57:44,982 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:57:44,983 - INFO -   [Sin mejora Loss] Paciencia: 1/50\n",
      "2026-01-04 18:57:44,985 - INFO - Val Loss: 0.7400 Acc: 0.7233\n",
      "2026-01-04 18:57:44,986 - INFO - --- Época 179/250 ---\n",
      "2026-01-04 18:58:19,012 - INFO - Train Loss: 0.6836 Acc: 0.7396   \n",
      "2026-01-04 18:58:19,574 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:58:19,575 - INFO -   [Sin mejora Loss] Paciencia: 2/50\n",
      "2026-01-04 18:58:19,576 - INFO - Val Loss: 0.7417 Acc: 0.7300\n",
      "2026-01-04 18:58:19,577 - INFO - --- Época 180/250 ---\n",
      "2026-01-04 18:58:52,956 - INFO - Train Loss: 0.6686 Acc: 0.7379   \n",
      "2026-01-04 18:58:53,673 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:58:53,674 - INFO -   [Sin mejora Loss] Paciencia: 3/50\n",
      "2026-01-04 18:58:53,676 - INFO - Val Loss: 0.7554 Acc: 0.7300\n",
      "2026-01-04 18:58:53,677 - INFO - --- Época 181/250 ---\n",
      "2026-01-04 18:59:28,129 - INFO - Train Loss: 0.6554 Acc: 0.7396   \n",
      "2026-01-04 18:59:28,756 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 18:59:28,757 - INFO -   [Sin mejora Loss] Paciencia: 4/50\n",
      "2026-01-04 18:59:28,758 - INFO - Val Loss: 0.7451 Acc: 0.7200\n",
      "2026-01-04 18:59:28,759 - INFO - --- Época 182/250 ---\n",
      "2026-01-04 19:00:02,397 - INFO - Train Loss: 0.6705 Acc: 0.7458   \n",
      "2026-01-04 19:00:03,044 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 19:00:03,045 - INFO -   [Sin mejora Loss] Paciencia: 5/50\n",
      "2026-01-04 19:00:03,046 - INFO - Val Loss: 0.7442 Acc: 0.7233\n",
      "2026-01-04 19:00:03,047 - INFO - --- Época 183/250 ---\n",
      "2026-01-04 19:00:36,002 - INFO - Train Loss: 0.6740 Acc: 0.7567   \n",
      "2026-01-04 19:00:36,636 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 19:00:36,637 - INFO -   [Sin mejora Loss] Paciencia: 6/50\n",
      "2026-01-04 19:00:36,637 - INFO - Val Loss: 0.7372 Acc: 0.7267\n",
      "2026-01-04 19:00:36,639 - INFO - --- Época 184/250 ---\n",
      "2026-01-04 19:01:09,828 - INFO - Train Loss: 0.6758 Acc: 0.7467   \n",
      "2026-01-04 19:01:10,481 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 19:01:10,482 - INFO -   [Sin mejora Loss] Paciencia: 7/50\n",
      "2026-01-04 19:01:10,484 - INFO - Val Loss: 0.7412 Acc: 0.7267\n",
      "2026-01-04 19:01:10,485 - INFO - --- Época 185/250 ---\n",
      "2026-01-04 19:01:44,226 - INFO - Train Loss: 0.6614 Acc: 0.7529   \n",
      "2026-01-04 19:01:44,860 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 19:01:44,860 - INFO -   [Sin mejora Loss] Paciencia: 8/50\n",
      "2026-01-04 19:01:44,862 - INFO - Val Loss: 0.7385 Acc: 0.7267\n",
      "2026-01-04 19:01:44,863 - INFO - --- Época 186/250 ---\n",
      "2026-01-04 19:02:17,890 - INFO - Train Loss: 0.6622 Acc: 0.7404   \n",
      "2026-01-04 19:02:18,494 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 19:02:18,495 - INFO -   [Sin mejora Loss] Paciencia: 9/50\n",
      "2026-01-04 19:02:18,496 - INFO - Val Loss: 0.7501 Acc: 0.7267\n",
      "2026-01-04 19:02:18,498 - INFO - --- Época 187/250 ---\n",
      "2026-01-04 19:02:51,831 - INFO - Train Loss: 0.6754 Acc: 0.7404   \n",
      "2026-01-04 19:02:52,459 - INFO -   [LR] Tasa de aprendizaje actual: 0.000016\n",
      "2026-01-04 19:02:52,460 - INFO -   [Sin mejora Loss] Paciencia: 10/50\n",
      "2026-01-04 19:02:52,461 - INFO - Val Loss: 0.7522 Acc: 0.7267\n",
      "2026-01-04 19:02:52,462 - INFO - --- Época 188/250 ---\n",
      "2026-01-04 19:03:25,651 - INFO - Train Loss: 0.6729 Acc: 0.7475   \n",
      "2026-01-04 19:03:26,271 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:03:26,272 - INFO -   [Sin mejora Loss] Paciencia: 11/50\n",
      "2026-01-04 19:03:26,273 - INFO - Val Loss: 0.7376 Acc: 0.7367\n",
      "2026-01-04 19:03:26,274 - INFO - --- Época 189/250 ---\n",
      "2026-01-04 19:03:59,916 - INFO - Train Loss: 0.6429 Acc: 0.7596   \n",
      "2026-01-04 19:04:00,619 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:04:00,620 - INFO -   [Sin mejora Loss] Paciencia: 12/50\n",
      "2026-01-04 19:04:00,621 - INFO - Val Loss: 0.7392 Acc: 0.7333\n",
      "2026-01-04 19:04:00,622 - INFO - --- Época 190/250 ---\n",
      "2026-01-04 19:04:36,216 - INFO - Train Loss: 0.6418 Acc: 0.7571   \n",
      "2026-01-04 19:04:36,870 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:04:36,871 - INFO -   [Sin mejora Loss] Paciencia: 13/50\n",
      "2026-01-04 19:04:36,872 - INFO - Val Loss: 0.7381 Acc: 0.7333\n",
      "2026-01-04 19:04:36,873 - INFO - --- Época 191/250 ---\n",
      "2026-01-04 19:05:11,018 - INFO - Train Loss: 0.6615 Acc: 0.7396   \n",
      "2026-01-04 19:05:11,689 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:05:11,690 - INFO -   [Sin mejora Loss] Paciencia: 14/50\n",
      "2026-01-04 19:05:11,692 - INFO - Val Loss: 0.7449 Acc: 0.7300\n",
      "2026-01-04 19:05:11,693 - INFO - --- Época 192/250 ---\n",
      "2026-01-04 19:05:45,110 - INFO - Train Loss: 0.6626 Acc: 0.7425   \n",
      "2026-01-04 19:05:45,730 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:05:45,731 - INFO -   [Sin mejora Loss] Paciencia: 15/50\n",
      "2026-01-04 19:05:45,733 - INFO - Val Loss: 0.7379 Acc: 0.7367\n",
      "2026-01-04 19:05:45,734 - INFO - --- Época 193/250 ---\n",
      "2026-01-04 19:06:18,641 - INFO - Train Loss: 0.6502 Acc: 0.7496   \n",
      "2026-01-04 19:06:19,237 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:06:19,238 - INFO -   [Sin mejora Loss] Paciencia: 16/50\n",
      "2026-01-04 19:06:19,239 - INFO - Val Loss: 0.7443 Acc: 0.7333\n",
      "2026-01-04 19:06:19,240 - INFO - --- Época 194/250 ---\n",
      "2026-01-04 19:06:59,671 - INFO - Train Loss: 0.6515 Acc: 0.7500   \n",
      "2026-01-04 19:07:01,802 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:07:01,803 - INFO -   [Sin mejora Loss] Paciencia: 17/50\n",
      "2026-01-04 19:07:01,805 - INFO - Val Loss: 0.7438 Acc: 0.7333\n",
      "2026-01-04 19:07:01,806 - INFO - --- Época 195/250 ---\n",
      "2026-01-04 19:08:40,181 - INFO - Train Loss: 0.6352 Acc: 0.7538   \n",
      "2026-01-04 19:08:43,458 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:08:43,459 - INFO -   [Sin mejora Loss] Paciencia: 18/50\n",
      "2026-01-04 19:08:43,461 - INFO - Val Loss: 0.7401 Acc: 0.7233\n",
      "2026-01-04 19:08:43,461 - INFO - --- Época 196/250 ---\n",
      "2026-01-04 19:10:17,166 - INFO - Train Loss: 0.6511 Acc: 0.7488   \n",
      "2026-01-04 19:10:19,383 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:10:19,384 - INFO -   [Sin mejora Loss] Paciencia: 19/50\n",
      "2026-01-04 19:10:19,385 - INFO - Val Loss: 0.7403 Acc: 0.7267\n",
      "2026-01-04 19:10:19,386 - INFO - --- Época 197/250 ---\n",
      "2026-01-04 19:11:54,895 - INFO - Train Loss: 0.6578 Acc: 0.7538   \n",
      "2026-01-04 19:11:57,466 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:11:57,467 - INFO -   [Sin mejora Loss] Paciencia: 20/50\n",
      "2026-01-04 19:11:57,468 - INFO - Val Loss: 0.7388 Acc: 0.7267\n",
      "2026-01-04 19:11:57,469 - INFO - --- Época 198/250 ---\n",
      "2026-01-04 19:13:31,805 - INFO - Train Loss: 0.6563 Acc: 0.7492   \n",
      "2026-01-04 19:13:34,034 - INFO -   [LR] Tasa de aprendizaje actual: 0.000008\n",
      "2026-01-04 19:13:34,035 - INFO -   [Sin mejora Loss] Paciencia: 21/50\n",
      "2026-01-04 19:13:34,036 - INFO - Val Loss: 0.7421 Acc: 0.7267\n",
      "2026-01-04 19:13:34,037 - INFO - --- Época 199/250 ---\n",
      "2026-01-04 19:15:10,658 - INFO - Train Loss: 0.6512 Acc: 0.7475   \n",
      "2026-01-04 19:15:12,958 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:15:12,959 - INFO -   [Sin mejora Loss] Paciencia: 22/50\n",
      "2026-01-04 19:15:12,961 - INFO - Val Loss: 0.7413 Acc: 0.7367\n",
      "2026-01-04 19:15:12,963 - INFO - --- Época 200/250 ---\n",
      "2026-01-04 19:16:50,305 - INFO - Train Loss: 0.6540 Acc: 0.7392   \n",
      "2026-01-04 19:16:52,655 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:16:52,656 - INFO -   [Sin mejora Loss] Paciencia: 23/50\n",
      "2026-01-04 19:16:52,678 - INFO - Val Loss: 0.7405 Acc: 0.7333\n",
      "2026-01-04 19:16:52,683 - INFO - --- Época 201/250 ---\n",
      "2026-01-04 19:18:29,632 - INFO - Train Loss: 0.6610 Acc: 0.7521   \n",
      "2026-01-04 19:18:31,838 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:18:31,839 - INFO -   [Sin mejora Loss] Paciencia: 24/50\n",
      "2026-01-04 19:18:31,840 - INFO - Val Loss: 0.7436 Acc: 0.7333\n",
      "2026-01-04 19:18:31,841 - INFO - --- Época 202/250 ---\n",
      "2026-01-04 19:20:09,606 - INFO - Train Loss: 0.6581 Acc: 0.7479   \n",
      "2026-01-04 19:20:11,768 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:20:11,769 - INFO -   [Sin mejora Loss] Paciencia: 25/50\n",
      "2026-01-04 19:20:11,770 - INFO - Val Loss: 0.7406 Acc: 0.7300\n",
      "2026-01-04 19:20:11,771 - INFO - --- Época 203/250 ---\n",
      "2026-01-04 19:21:44,066 - INFO - Train Loss: 0.6566 Acc: 0.7438   \n",
      "2026-01-04 19:21:46,267 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:21:46,268 - INFO -   [Sin mejora Loss] Paciencia: 26/50\n",
      "2026-01-04 19:21:46,270 - INFO - Val Loss: 0.7410 Acc: 0.7300\n",
      "2026-01-04 19:21:46,271 - INFO - --- Época 204/250 ---\n",
      "2026-01-04 19:23:22,933 - INFO - Train Loss: 0.6472 Acc: 0.7538   \n",
      "2026-01-04 19:23:25,301 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:23:25,302 - INFO -   [Sin mejora Loss] Paciencia: 27/50\n",
      "2026-01-04 19:23:25,304 - INFO - Val Loss: 0.7441 Acc: 0.7233\n",
      "2026-01-04 19:23:25,305 - INFO - --- Época 205/250 ---\n",
      "2026-01-04 19:24:59,720 - INFO - Train Loss: 0.6632 Acc: 0.7471   \n",
      "2026-01-04 19:25:01,985 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:25:01,986 - INFO -   [Sin mejora Loss] Paciencia: 28/50\n",
      "2026-01-04 19:25:01,987 - INFO - Val Loss: 0.7347 Acc: 0.7300\n",
      "2026-01-04 19:25:01,988 - INFO - --- Época 206/250 ---\n",
      "2026-01-04 19:26:35,793 - INFO - Train Loss: 0.6351 Acc: 0.7571   \n",
      "2026-01-04 19:26:37,509 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:26:37,510 - INFO -   [Sin mejora Loss] Paciencia: 29/50\n",
      "2026-01-04 19:26:37,511 - INFO - Val Loss: 0.7394 Acc: 0.7267\n",
      "2026-01-04 19:26:37,512 - INFO - --- Época 207/250 ---\n",
      "2026-01-04 19:28:13,276 - INFO - Train Loss: 0.6505 Acc: 0.7546   \n",
      "2026-01-04 19:28:14,192 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:28:14,193 - INFO -   [Sin mejora Loss] Paciencia: 30/50\n",
      "2026-01-04 19:28:14,194 - INFO - Val Loss: 0.7408 Acc: 0.7300\n",
      "2026-01-04 19:28:14,196 - INFO - --- Época 208/250 ---\n",
      "2026-01-04 19:29:45,749 - INFO - Train Loss: 0.6504 Acc: 0.7513   \n",
      "2026-01-04 19:29:49,116 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:29:49,118 - INFO -   [Sin mejora Loss] Paciencia: 31/50\n",
      "2026-01-04 19:29:49,122 - INFO - Val Loss: 0.7384 Acc: 0.7267\n",
      "2026-01-04 19:29:49,124 - INFO - --- Época 209/250 ---\n",
      "2026-01-04 19:31:29,771 - INFO - Train Loss: 0.6561 Acc: 0.7533   \n",
      "2026-01-04 19:31:32,028 - INFO -   [LR] Tasa de aprendizaje actual: 0.000004\n",
      "2026-01-04 19:31:32,029 - INFO -   [Sin mejora Loss] Paciencia: 32/50\n",
      "2026-01-04 19:31:32,030 - INFO - Val Loss: 0.7350 Acc: 0.7267\n",
      "2026-01-04 19:31:32,031 - INFO - --- Época 210/250 ---\n",
      "2026-01-04 19:33:09,143 - INFO - Train Loss: 0.6513 Acc: 0.7538   \n",
      "2026-01-04 19:33:12,676 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:33:12,677 - INFO -   [Sin mejora Loss] Paciencia: 33/50\n",
      "2026-01-04 19:33:12,679 - INFO - Val Loss: 0.7437 Acc: 0.7300\n",
      "2026-01-04 19:33:12,680 - INFO - --- Época 211/250 ---\n",
      "2026-01-04 19:34:49,148 - INFO - Train Loss: 0.6632 Acc: 0.7508   \n",
      "2026-01-04 19:34:52,742 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:34:52,743 - INFO -   [Sin mejora Loss] Paciencia: 34/50\n",
      "2026-01-04 19:34:52,744 - INFO - Val Loss: 0.7373 Acc: 0.7333\n",
      "2026-01-04 19:34:52,744 - INFO - --- Época 212/250 ---\n",
      "2026-01-04 19:36:32,126 - INFO - Train Loss: 0.6318 Acc: 0.7575   \n",
      "2026-01-04 19:36:34,351 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:36:34,352 - INFO -   [Sin mejora Loss] Paciencia: 35/50\n",
      "2026-01-04 19:36:34,354 - INFO - Val Loss: 0.7446 Acc: 0.7267\n",
      "2026-01-04 19:36:34,355 - INFO - --- Época 213/250 ---\n",
      "2026-01-04 19:38:12,034 - INFO - Train Loss: 0.6348 Acc: 0.7483   \n",
      "2026-01-04 19:38:15,601 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:38:15,603 - INFO -   [Sin mejora Loss] Paciencia: 36/50\n",
      "2026-01-04 19:38:15,606 - INFO - Val Loss: 0.7416 Acc: 0.7267\n",
      "2026-01-04 19:38:15,608 - INFO - --- Época 214/250 ---\n",
      "2026-01-04 19:39:55,586 - INFO - Train Loss: 0.6527 Acc: 0.7521   \n",
      "2026-01-04 19:39:57,888 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:39:57,889 - INFO -   [Sin mejora Loss] Paciencia: 37/50\n",
      "2026-01-04 19:39:57,891 - INFO - Val Loss: 0.7426 Acc: 0.7233\n",
      "2026-01-04 19:39:57,892 - INFO - --- Época 215/250 ---\n",
      "2026-01-04 19:41:36,250 - INFO - Train Loss: 0.6428 Acc: 0.7629   \n",
      "2026-01-04 19:41:39,301 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:41:39,302 - INFO -   [Sin mejora Loss] Paciencia: 38/50\n",
      "2026-01-04 19:41:39,303 - INFO - Val Loss: 0.7477 Acc: 0.7267\n",
      "2026-01-04 19:41:39,305 - INFO - --- Época 216/250 ---\n",
      "2026-01-04 19:43:18,627 - INFO - Train Loss: 0.6619 Acc: 0.7458   \n",
      "2026-01-04 19:43:20,830 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:43:20,831 - INFO -   [Sin mejora Loss] Paciencia: 39/50\n",
      "2026-01-04 19:43:20,832 - INFO - Val Loss: 0.7440 Acc: 0.7300\n",
      "2026-01-04 19:43:20,833 - INFO - --- Época 217/250 ---\n",
      "2026-01-04 19:44:57,873 - INFO - Train Loss: 0.6607 Acc: 0.7600   \n",
      "2026-01-04 19:45:00,203 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:45:00,204 - INFO -   [Sin mejora Loss] Paciencia: 40/50\n",
      "2026-01-04 19:45:00,205 - INFO - Val Loss: 0.7430 Acc: 0.7233\n",
      "2026-01-04 19:45:00,206 - INFO - --- Época 218/250 ---\n",
      "2026-01-04 19:46:38,135 - INFO - Train Loss: 0.6389 Acc: 0.7488   \n",
      "2026-01-04 19:46:40,522 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:46:40,523 - INFO -   [Sin mejora Loss] Paciencia: 41/50\n",
      "2026-01-04 19:46:40,525 - INFO - Val Loss: 0.7394 Acc: 0.7233\n",
      "2026-01-04 19:46:40,525 - INFO - --- Época 219/250 ---\n",
      "2026-01-04 19:48:20,845 - INFO - Train Loss: 0.6436 Acc: 0.7529   \n",
      "2026-01-04 19:48:23,270 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:48:23,271 - INFO -   [Sin mejora Loss] Paciencia: 42/50\n",
      "2026-01-04 19:48:23,273 - INFO - Val Loss: 0.7440 Acc: 0.7267\n",
      "2026-01-04 19:48:23,275 - INFO - --- Época 220/250 ---\n",
      "2026-01-04 19:50:02,548 - INFO - Train Loss: 0.6663 Acc: 0.7583   \n",
      "2026-01-04 19:50:04,903 - INFO -   [LR] Tasa de aprendizaje actual: 0.000002\n",
      "2026-01-04 19:50:04,904 - INFO -   [Sin mejora Loss] Paciencia: 43/50\n",
      "2026-01-04 19:50:04,905 - INFO - Val Loss: 0.7412 Acc: 0.7267\n",
      "2026-01-04 19:50:04,906 - INFO - --- Época 221/250 ---\n",
      "2026-01-04 19:51:46,698 - INFO - Train Loss: 0.6504 Acc: 0.7567   \n",
      "2026-01-04 19:51:47,493 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 19:51:47,494 - INFO -   [Sin mejora Loss] Paciencia: 44/50\n",
      "2026-01-04 19:51:47,495 - INFO - Val Loss: 0.7441 Acc: 0.7233\n",
      "2026-01-04 19:51:47,496 - INFO - --- Época 222/250 ---\n",
      "2026-01-04 19:53:25,456 - INFO - Train Loss: 0.6553 Acc: 0.7563   \n",
      "2026-01-04 19:53:29,221 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 19:53:29,222 - INFO -   [Sin mejora Loss] Paciencia: 45/50\n",
      "2026-01-04 19:53:29,224 - INFO - Val Loss: 0.7404 Acc: 0.7200\n",
      "2026-01-04 19:53:29,225 - INFO - --- Época 223/250 ---\n",
      "2026-01-04 19:55:09,014 - INFO - Train Loss: 0.6474 Acc: 0.7546   \n",
      "2026-01-04 19:55:11,361 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 19:55:11,362 - INFO -   [Sin mejora Loss] Paciencia: 46/50\n",
      "2026-01-04 19:55:11,364 - INFO - Val Loss: 0.7361 Acc: 0.7233\n",
      "2026-01-04 19:55:11,365 - INFO - --- Época 224/250 ---\n",
      "2026-01-04 19:56:50,759 - INFO - Train Loss: 0.6273 Acc: 0.7579   \n",
      "2026-01-04 19:56:56,512 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 19:56:56,513 - INFO -   [Sin mejora Loss] Paciencia: 47/50\n",
      "2026-01-04 19:56:56,514 - INFO - Val Loss: 0.7383 Acc: 0.7233\n",
      "2026-01-04 19:56:56,515 - INFO - --- Época 225/250 ---\n",
      "2026-01-04 19:58:35,561 - INFO - Train Loss: 0.6530 Acc: 0.7500   \n",
      "2026-01-04 19:58:38,755 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 19:58:38,757 - INFO -   [Sin mejora Loss] Paciencia: 48/50\n",
      "2026-01-04 19:58:38,759 - INFO - Val Loss: 0.7370 Acc: 0.7267\n",
      "2026-01-04 19:58:38,762 - INFO - --- Época 226/250 ---\n",
      "2026-01-04 20:00:21,978 - INFO - Train Loss: 0.6550 Acc: 0.7454   \n",
      "2026-01-04 20:00:25,139 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 20:00:25,147 - INFO -   [Sin mejora Loss] Paciencia: 49/50\n",
      "2026-01-04 20:00:25,150 - INFO - Val Loss: 0.7412 Acc: 0.7267\n",
      "2026-01-04 20:00:25,152 - INFO - --- Época 227/250 ---\n",
      "2026-01-04 20:02:09,939 - INFO - Train Loss: 0.6601 Acc: 0.7567   \n",
      "2026-01-04 20:02:12,304 - INFO -   [LR] Tasa de aprendizaje actual: 0.000001\n",
      "2026-01-04 20:02:12,314 - INFO -   [Sin mejora Loss] Paciencia: 50/50\n",
      "2026-01-04 20:02:12,316 - INFO - ¡EARLY STOPPING ACTIVADO!\n",
      "2026-01-04 20:02:12,318 - INFO - Val Loss: 0.7426 Acc: 0.7233\n",
      "2026-01-04 20:02:12,319 - INFO - Entrenamiento finalizado en 226m 24s\n",
      "2026-01-04 20:02:12,320 - INFO - Mejor Val Loss lograda: 0.7317\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    output_dir,\n",
    "    logger,\n",
    "    scheduler=None,\n",
    "):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # --- CONFIGURACIÓN DE EARLY STOPPING ---\n",
    "    patience = 50\n",
    "    patience_counter = 0\n",
    "    min_val_loss = np.inf\n",
    "    early_stop = False\n",
    "    # ---------------------------------------\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    logger.info(f\"Iniciando entrenamiento por {num_epochs} épocas...\")\n",
    "    logger.info(f\"Paciencia configurada: {patience} épocas.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            break\n",
    "\n",
    "        logger.info(f\"--- Época {epoch+1}/{num_epochs} ---\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            loop = tqdm(dataloader, desc=f\"{phase.capitalize()}\", leave=False)\n",
    "\n",
    "            for inputs, labels in loop:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "                history[\"train_acc\"].append(epoch_acc.item())\n",
    "            else:\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "                history[\"val_acc\"].append(epoch_acc.item())\n",
    "\n",
    "                # ==========================================\n",
    "                #      AQUÍ ESTÁ LA LÓGICA DEL SCHEDULER\n",
    "                # ==========================================\n",
    "                if scheduler is not None:\n",
    "                    # ReduceLROnPlateau necesita el valor de la pérdida (loss)\n",
    "                    scheduler.step(epoch_loss)\n",
    "\n",
    "                    # Log para ver si el LR cambia\n",
    "                    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "                    logger.info(f\"  [LR] Tasa de aprendizaje actual: {current_lr:.6f}\")\n",
    "                # ==========================================\n",
    "\n",
    "                # --- LÓGICA DE EARLY STOPPING ---\n",
    "                if epoch_loss < min_val_loss:\n",
    "                    logger.info(\n",
    "                        f\"  [Mejora Loss] {min_val_loss:.4f} -> {epoch_loss:.4f}. Reseteando paciencia.\"\n",
    "                    )\n",
    "                    min_val_loss = epoch_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    save_path = os.path.join(output_dir, \"best_model.pth\")\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    logger.info(f\"  [Nuevo Récord Loss] Guardado en: {save_path}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    logger.info(\n",
    "                        f\"  [Sin mejora Loss] Paciencia: {patience_counter}/{patience}\"\n",
    "                    )\n",
    "                    if patience_counter >= patience:\n",
    "                        logger.info(\"¡EARLY STOPPING ACTIVADO!\")\n",
    "                        early_stop = True\n",
    "\n",
    "            logger.info(\n",
    "                f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\"\n",
    "            )\n",
    "                \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    logger.info(\n",
    "        f\"Entrenamiento finalizado en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\"\n",
    "    )\n",
    "    logger.info(f\"Mejor Val Loss lograda: {min_val_loss:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    last_path = os.path.join(output_dir, \"last_model.pth\")\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# --- EJECUCIÓN ---\n",
    "\n",
    "# Instanciar el modelo (Asegúrate que SBTAYLOR_KAN.Net es tu clase corregida)\n",
    "# Nota: 'input_size' debe coincidir con el tamaño de tus imágenes en el dataloader\n",
    "model_ft, criterion, optimizer = model_init()\n",
    "#     best_params[\"lr\"],\n",
    "#     best_params[\"dropout_1\"],\n",
    "#     best_params[\"dropout_2\"],\n",
    "#     best_params[\"weight_decay\"],\n",
    "# )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=10,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150\n",
    "\n",
    "# Llamar a entrenar pasando el scheduler\n",
    "model_ft, history = train_model(\n",
    "    model=model_ft,\n",
    "    train_loader=trainloader,\n",
    "    val_loader=valloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    output_dir=RUN_SAVE_DIR,\n",
    "    logger=logger,\n",
    "    scheduler=scheduler,  # <--- Se pasa aquí\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0992da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
      "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
      "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
      "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
      "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
      "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
      "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
      "├─KANLinear: 1-3                         [-1, 256]                 --\n",
      "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
      "├─Dropout: 1-4                           [-1, 256]                 --\n",
      "├─KANLinear: 1-5                         [-1, 128]                 --\n",
      "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
      "├─Dropout: 1-6                           [-1, 128]                 --\n",
      "├─KANLinear: 1-7                         [-1, 6]                   --\n",
      "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
      "==========================================================================================\n",
      "Total params: 241,536\n",
      "Trainable params: 241,536\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 679.73\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 44.41\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 45.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
       "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
       "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
       "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
       "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
       "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
       "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
       "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
       "├─KANLinear: 1-3                         [-1, 256]                 --\n",
       "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
       "├─Dropout: 1-4                           [-1, 256]                 --\n",
       "├─KANLinear: 1-5                         [-1, 128]                 --\n",
       "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
       "├─Dropout: 1-6                           [-1, 128]                 --\n",
       "├─KANLinear: 1-7                         [-1, 6]                   --\n",
       "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
       "==========================================================================================\n",
       "Total params: 241,536\n",
       "Trainable params: 241,536\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 679.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 44.41\n",
       "Params size (MB): 0.92\n",
       "Estimated Total Size (MB): 45.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_ft, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d80c1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfica guardada en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\training_history.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history[\"train_acc\"]\n",
    "    val_acc = history[\"val_acc\"]\n",
    "    loss = history[\"train_loss\"]\n",
    "    val_loss = history[\"val_loss\"]\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Gráfica de Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.grid(True)\n",
    "    # --- CORRECCIÓN AQUÍ ---\n",
    "    # 1. Guardar PRIMERO\n",
    "    save_path = os.path.join(RUN_SAVE_DIR, \"training_history.png\")\n",
    "    plt.savefig(\n",
    "        save_path, dpi=300, bbox_inches=\"tight\"\n",
    "    )  # dpi=300 para alta calidad, bbox_inches corta bordes blancos extra\n",
    "    print(f\"Gráfica guardada en: {save_path}\")\n",
    "\n",
    "    # 2. Mostrar DESPUÉS\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf7a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging  # Necesario para el type hinting o manejo interno\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names, output_dir, logger):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo entrenado y genera reporte.\n",
    "    Ahora recibe 'logger' como argumento para asegurar que escriba en tu archivo .log.\n",
    "    \"\"\"\n",
    "    logger.info(\"\\n\" + \"=\" * 40)\n",
    "    logger.info(\"--- INICIANDO EVALUACIÓN EN TEST SET ---\")\n",
    "    logger.info(\"=\" * 40)\n",
    "\n",
    "    # 1. Poner el modelo en modo de evaluación (Apaga Dropout/BatchNorm)\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    total_inference_time = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # 2. Iterar sobre el conjunto de prueba\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # --- BLOQUE DE MEDICIÓN DE TIEMPO PRECISA ---\n",
    "            # Si usas GPU, es obligatorio sincronizar antes y después del forward\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            end_time = time.time()\n",
    "            # ---------------------------------------------\n",
    "\n",
    "            # Acumular tiempo real de procesamiento\n",
    "            total_inference_time += end_time - start_time\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Convertir a numpy\n",
    "    true_labels = np.array(all_labels)\n",
    "    predicted_labels = np.array(all_preds)\n",
    "\n",
    "    # 3. Calcular Métricas\n",
    "    logger.info(\"Calculando métricas estadísticas...\")\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # zero_division=0 evita errores si una clase no tiene predicciones\n",
    "    precision_per_class = precision_score(\n",
    "        true_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "    recall_per_class = recall_score(\n",
    "        true_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "    f1_per_class = f1_score(\n",
    "        true_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Promedios Macro (trata todas las clases igual, útil si hay desbalance)\n",
    "    avg_precision = np.mean(precision_per_class)\n",
    "    avg_recall = np.mean(recall_per_class)\n",
    "    avg_f1 = np.mean(f1_per_class)\n",
    "\n",
    "    # Tiempo promedio por imagen (Métrica Clave para KAN vs VGG)\n",
    "    avg_inference_time_ms = (total_inference_time / total_samples) * 1000\n",
    "\n",
    "    # 4. Matriz de Confusión Visual\n",
    "    logger.info(\"Generando matriz de confusión...\")\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",  # 'd' es para enteros (decimal), mejor que 'g' para conteos\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicción del Modelo\", fontsize=12)\n",
    "    plt.ylabel(\"Realidad (Ground Truth)\", fontsize=12)\n",
    "    plt.title(f\"Matriz de Confusión - Accuracy: {accuracy:.2%}\", fontsize=14)\n",
    "\n",
    "    cm_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()  # Cierra la figura para liberar memoria\n",
    "    logger.info(f\"Gráfico guardado en: {cm_path}\")\n",
    "\n",
    "    # 5. Reporte de Texto\n",
    "    logger.info(\"Escribiendo reporte final...\")\n",
    "\n",
    "    metrics_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Clase\": class_names,\n",
    "            \"Precision\": np.round(precision_per_class, 4),\n",
    "            \"Recall\": np.round(recall_per_class, 4),\n",
    "            \"F1-Score\": np.round(f1_per_class, 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    report_path = os.path.join(output_dir, \"test_metrics_report.txt\")\n",
    "\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\" REPORTE DE EVALUACIÓN: {time.strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"Métricas Globales:\\n\")\n",
    "        f.write(f\"- Accuracy:          {accuracy:.4f} ({accuracy:.2%})\\n\")\n",
    "        f.write(f\"- Macro Precision:   {avg_precision:.4f}\\n\")\n",
    "        f.write(f\"- Macro Recall:      {avg_recall:.4f}\\n\")\n",
    "        f.write(f\"- Macro F1-Score:    {avg_f1:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"EFICIENCIA (Velocidad)\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"- Muestras totales:  {total_samples}\\n\")\n",
    "        f.write(f\"- Tiempo total:      {total_inference_time:.4f} seg\\n\")\n",
    "        f.write(f\"- Tiempo por imagen: {avg_inference_time_ms:.4f} ms\\n\\n\")\n",
    "\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"DETALLE POR CLASE\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        # Usamos to_markdown si pandas es reciente, sino to_string\n",
    "        try:\n",
    "            f.write(metrics_df.to_markdown(index=False))\n",
    "        except:\n",
    "            f.write(metrics_df.to_string(index=False))\n",
    "\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"Matriz de Confusión (Texto):\\n\")\n",
    "        f.write(np.array2string(cm, separator=\", \"))\n",
    "\n",
    "    logger.info(f\"Reporte de texto guardado en: {report_path}\")\n",
    "    logger.info(\"--- EVALUACIÓN FINALIZADA ---\")\n",
    "\n",
    "    return (\n",
    "        accuracy,\n",
    "        avg_f1,\n",
    "    )  # Retorna valores por si los necesitas en el script principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02c1eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:02:18,705 - INFO - Cargando el mejor modelo para la evaluación...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones calculadas automáticamente para FC1: 25088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640', 'n01742172']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(RUN_SAVE_DIR, \"best_model.pth\")\n",
    "# 2. Crear una nueva instancia del modelo y cargar los mejores pesos\n",
    "logger.info(\"Cargando el mejor modelo para la evaluación...\")\n",
    "eval_model = KAN_Model(num_classes=len(selected_classes), input_size=(3, 224, 224)).to(\n",
    "    device\n",
    ")\n",
    "eval_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "class_names = (\n",
    "    selected_classes  # Obtener los nombres de las clases desde el dataset de prueba\n",
    ")\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8c9eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:02:20,059 - INFO - \n",
      "========================================\n",
      "2026-01-04 20:02:20,060 - INFO - --- INICIANDO EVALUACIÓN EN TEST SET ---\n",
      "2026-01-04 20:02:20,061 - INFO - ========================================\n",
      "2026-01-04 20:02:23,682 - INFO - Calculando métricas estadísticas...\n",
      "2026-01-04 20:02:23,692 - INFO - Generando matriz de confusión...\n",
      "2026-01-04 20:02:24,602 - INFO - Gráfico guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\confusion_matrix.png\n",
      "2026-01-04 20:02:24,605 - INFO - Escribiendo reporte final...\n",
      "2026-01-04 20:02:24,617 - INFO - Reporte de texto guardado en: models/sbtaylor_kan_tiny_imagenet\\run_20260104_160530\\test_metrics_report.txt\n",
      "2026-01-04 20:02:24,619 - INFO - --- EVALUACIÓN FINALIZADA ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7366666666666667, np.float64(0.728358244358842))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Llamar a la función de evaluación\n",
    "# Suponiendo que tienes un 'test_loader' y un 'RUN_DIR' definidos\n",
    "evaluate_model(\n",
    "    model=eval_model,\n",
    "    test_loader=testloader,  # Usando val_loader como ejemplo; reemplaza con test_loader si tienes uno\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    output_dir=RUN_SAVE_DIR,  # El directorio de la ejecución actual para guardar los resultados\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daad25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
