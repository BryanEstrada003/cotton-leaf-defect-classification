{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73d921-1334-42f5-a125-a673bfcdd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow -y\n",
    "# !pip install tensorflow==2.10.1  # Versión compatible con CUDA 11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1befb732-9265-464d-99d3-4d06322e1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install tensorflow==2.13.1 numpy==1.23.5 albumentations==1.2.1 typing-extensions==4.5.0 opencv-python-headless==4.5.5.64 scikit-image==0.19.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "importaciones",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885f444-1b22-48ac-a09e-31c8bed8df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEMILLA\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9abcd7-61c1-41a1-9c42-91e2bff1932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b22cc-f430-476a-a0df-827afc4ee740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     # Asignar 8GB a cada modelo (24GB total / 3 modelos)\n",
    "#     tf.config.set_logical_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]  # 8GB en MB\n",
    "#     )\n",
    "#     print(\"GPU limitada a 10GB para este notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ddd29d-f223-483f-9698-acca25d67da4",
   "metadata": {},
   "source": [
    "# Implementación personalizada de ruido sal y pimienta\n",
    "class SaltAndPepperNoise(ImageOnlyTransform):\n",
    "    def __init__(self, salt_prob=0.01, pepper_prob=0.01, always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.salt_prob = salt_prob\n",
    "        self.pepper_prob = pepper_prob\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        noise = np.random.rand(*img.shape[:2])\n",
    "        img = img.copy()\n",
    "        img[noise < self.salt_prob] = [255, 255, 255]  # Sal\n",
    "        img[(noise >= self.salt_prob) & (noise < (self.salt_prob + self.pepper_prob))] = [0, 0, 0]  # Pimienta\n",
    "        return img\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"salt_prob\", \"pepper_prob\")\n",
    "\n",
    "# Transformaciones para aumento de datos en entrenamiento\n",
    "transform_entrenamiento = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "    # ⚠️ Comentamos transformaciones que pueden alterar el color drásticamente\n",
    "    A.GaussNoise(var_limit=(5.0, 10.0), mean=0, p=0.4),\n",
    "    # SaltAndPepperNoise(salt_prob=0.01, pepper_prob=0.01, p=0.3),\n",
    "    \n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=(-0.15, 0),  # Limitamos el cambio de brillo\n",
    "        contrast_limit=0.0,\n",
    "        p=0.3\n",
    "    ),\n",
    "    \n",
    "    A.CoarseDropout(\n",
    "        max_holes=1,\n",
    "        max_height=int(forma_entrada[0] * 0.1),\n",
    "        max_width=int(forma_entrada[1] * 0.1),\n",
    "        min_holes=1,\n",
    "        min_height=int(forma_entrada[0] * 0.05),\n",
    "        min_width=int(forma_entrada[1] * 0.05),\n",
    "        fill_value=0,\n",
    "        p=0.3\n",
    "    )\n",
    "])\n",
    "\n",
    "# Función de aumento corregida\n",
    "def augment_image_alb(image):\n",
    "    \"\"\"\n",
    "    Aplica transformaciones de Albumentations a una imagen.\n",
    "    \"\"\"\n",
    "    # Si la imagen tiene 4 canales (RGBA), convertir a RGB\n",
    "    if image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Si ya viene normalizada [0, 1], desnormalizar a [0, 255]\n",
    "    if image.max() <= 1.0:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "    # Asegurar que tenga 3 canales\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif image.shape[2] == 1:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Aplicar transformaciones\n",
    "    augmented = transform_entrenamiento(image=image)[\"image\"]\n",
    "\n",
    "    # Convertir a float32 y normalizar a [0, 1]\n",
    "    return augmented.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec4649-22e2-4ff2-9c06-8ccae14ddc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parametros_generadores",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "forma_entrada = (224, 224, 3)\n",
    "tamaño_lote = 64 # si es con la data base, usar 32\n",
    "épocas = 60\n",
    "initial_learning_rate = 1e-3\n",
    "\n",
    "preprocess_fn = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Rutas\n",
    "ruta_entrenamiento = './datasets/2D/data_augmentation/color_2/train'\n",
    "ruta_validacion = './datasets/2D/data_augmentation/color_2/validation'\n",
    "ruta_test = './datasets/2D/data_augmentation/color_2/test'\n",
    "# Generadores\n",
    "datagen = ImageDataGenerator(\n",
    "    # preprocessing_function=preprocess_fn,\n",
    "    rescale=1./255\n",
    ")\n",
    "datagen_valid = ImageDataGenerator(\n",
    "    # preprocessing_function=preprocess_fn,\n",
    "    rescale=1./255\n",
    ") # ANTES APLIQUE RESCALE\n",
    "datagen_test = ImageDataGenerator(\n",
    "    # preprocessing_function=preprocess_fn,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "generador_entrenamiento = datagen.flow_from_directory(\n",
    "    ruta_entrenamiento,\n",
    "    target_size=forma_entrada[:2],\n",
    "    batch_size=tamaño_lote,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "generador_validacion = datagen_valid.flow_from_directory(\n",
    "    ruta_validacion,\n",
    "    target_size=forma_entrada[:2],\n",
    "    batch_size=tamaño_lote,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "generador_test = datagen_test.flow_from_directory(\n",
    "    ruta_test,\n",
    "    target_size=forma_entrada[:2],\n",
    "    batch_size=tamaño_lote,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b22b29-1330-49be-9503-482456c4773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supón que `x, y = generador_entrenamiento.next()`\n",
    "x_batch, y_batch = next(generador_entrenamiento)\n",
    "\n",
    "plt.imshow(x_batch[0])\n",
    "plt.axis('off')\n",
    "plt.title(\"Imagen aumentada\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38e6a5-36b2-4806-882f-879e161a2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def mostrar_imagenes(generador, num_imagenes=5):\n",
    "    \"\"\"\n",
    "    Muestra imágenes y sus etiquetas de un generador de Keras.\n",
    "    \n",
    "    Args:\n",
    "        generador: Objeto ImageDataGenerator (ej: generador_entrenamiento)\n",
    "        num_imagenes: Número de imágenes a mostrar (por defecto 5)\n",
    "    \"\"\"\n",
    "    # Obtener un batch de imágenes\n",
    "    batch = next(generador)\n",
    "    images, labels = batch[0], batch[1]\n",
    "    \n",
    "    # Crear figura\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i in range(min(num_imagenes, len(images))):\n",
    "        # Mostrar imagen\n",
    "        plt.subplot(1, num_imagenes, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "        # Obtener etiqueta (asumiendo one-hot encoding)\n",
    "        class_idx = np.argmax(labels[i])\n",
    "        class_name = list(generador.class_indices.keys())[class_idx]\n",
    "        \n",
    "        plt.title(f\"Clase: {class_name}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar imágenes de entrenamiento (con aumentación)\n",
    "print(\"Imágenes de entrenamiento (con aumentación):\")\n",
    "mostrar_imagenes(generador_entrenamiento)\n",
    "\n",
    "# Mostrar imágenes de validación (sin aumentación)\n",
    "print(\"\\nImágenes de validación (con aumentación):\")\n",
    "mostrar_imagenes(generador_validacion)\n",
    "\n",
    "\n",
    "print(\"\\nImágenes de testeo (sin aumentación):\")\n",
    "mostrar_imagenes(generador_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab054a-a325-4016-a674-806d27658831",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = len(generador_entrenamiento.filepaths) // generador_entrenamiento.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745c8d3-ef57-42a2-b536-34e4563bb484",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### AÑADIR LR DECAY FACTOR #####\n",
    "import tensorflow as tf\n",
    "# learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=30*steps,  # Decaimiento más frecuente\n",
    "#     decay_rate=0.9,  # Decaimiento más fuerte\n",
    "#     staircase=True)\n",
    "\n",
    "learning_rate=initial_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5ca15-d535-4540-b4ca-5b1eb1e273f6",
   "metadata": {},
   "source": [
    "# # #### USAR PESOS YA GUARDADOS\n",
    "latest = \"./models/MobilNet2/siamese_model_mobilnet_apple_data_REF.h5\"\n",
    "base_model = tf.keras.models.load_model(latest, compile=False)\n",
    "base_model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f8236-f50f-4b6a-abeb-366a64ed3d48",
   "metadata": {},
   "source": [
    "# Extraer el componente MobileNetV2 del modelo siamesa\n",
    "mobilenet_layer = base_model.get_layer('mobilenetv2_1.00_224')  # Nombre exacto de la capa en tu modelo\n",
    "mobilenet_layer.trainable = False  # Congelar pesos\n",
    "\n",
    "entrada = layers.Input(shape=forma_entrada)\n",
    "x = mobilenet_layer(entrada)  # Usar la VGG16 cargada\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "x = layers.Dropout(0.65)(x) # 0.7\n",
    "salida = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "# 3. Compilar\n",
    "modelo = Model(inputs=entrada, outputs=salida)\n",
    "optimizador = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "modelo.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizador, \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modelo_unico_input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelo base usando MobileNetV2\n",
    "def model_init(learning_rate, dropout_rate, l2_reg):\n",
    "    modelo_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=forma_entrada)\n",
    "    # modelo_base = MobileNetV2(weights=None, include_top=False, input_shape=forma_entrada)\n",
    "    for capa in modelo_base.layers:\n",
    "        capa.trainable = False\n",
    "    # # Definición del modelo de un solo input (RGB)\n",
    "    entrada = layers.Input(shape=forma_entrada)\n",
    "    x = modelo_base(entrada)\n",
    "    x = layers.Flatten()(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = layers.Dense(\n",
    "        256,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    salida = layers.Dense(4, activation='softmax')(x)\n",
    "    \n",
    "    modelo = Model(inputs=entrada, outputs=salida)\n",
    "    optimizador = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer=optimizador, metrics=['accuracy'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d032995-8297-4629-8bbf-72fa48ce3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 1. Definir función objetivo a optimizar\n",
    "def optimize_model(lr, dropout_rate, l2_reg):\n",
    "    # Convertir parámetros\n",
    "    lr = 10**lr  # Usar escala logarítmica\n",
    "    l2_reg = 10**l2_reg\n",
    "    \n",
    "    # Construir modelo con hiperparámetros actuales\n",
    "    modelo = model_init(\n",
    "        learning_rate=lr,\n",
    "        dropout_rate=dropout_rate,\n",
    "        l2_reg=l2_reg\n",
    "    )\n",
    "    \n",
    "    # Entrenamiento reducido para evaluación rápida\n",
    "    history = modelo.fit(\n",
    "        generador_entrenamiento,\n",
    "        # steps_per_epoch=train_samples // tamaño_lote,  # Subconjunto para optimización\n",
    "        validation_data=generador_validacion,\n",
    "        # validation_steps=val_samples // tamaño_lote,\n",
    "        epochs=3,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Retornar el mejor valor de val_accuracy\n",
    "    return np.max(history.history['val_accuracy'])\n",
    "\n",
    "# 2. Definir espacio de búsqueda\n",
    "pbounds = {\n",
    "    'lr': (-5, -3),       # 10^-5 a 10^-3\n",
    "    'dropout_rate': (0.6, 0.9),\n",
    "    'l2_reg': (-5, -3),   # 10^-5 a 10^-2\n",
    "}\n",
    "\n",
    "# 3. Crear optimizador bayesiano\n",
    "optimizer = BayesianOptimization(\n",
    "    f=optimize_model,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. Ejecutar optimización\n",
    "optimizer.maximize(\n",
    "    init_points=2,  # Exploración inicial aleatoria\n",
    "    n_iter=15,      # Iteraciones bayesianas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b51a75-5585-433d-898b-b7c176314078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener mejores parámetros\n",
    "best_params = optimizer.max['params']\n",
    "\n",
    "# Construir modelo final con mejores parámetros\n",
    "modelo = model_init(\n",
    "    learning_rate=10**best_params['lr'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    l2_reg=10**best_params['l2_reg']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2185076-31f8-4e52-b240-e14000483eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.max['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e290fef-d423-4ae0-9f3b-cf889448465a",
   "metadata": {},
   "source": [
    "### Batch actualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df85a4b-b547-44a1-a138-bf071e716a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de callbacks\n",
    "import os\n",
    "path_models = './models/pruebas/MobilNet2_RGB_bayesian_batchdef/'\n",
    "os.makedirs(path_models, exist_ok=True)\n",
    "arch = 'MOBILNET_SINGLE_INPUT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87bfaa6-a05a-496b-9b5c-71ae27818861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde se guardará el archivo (ej: 'C:/Users/tu_usuario/proyecto/resultados/hiperparametros.txt')\n",
    "ruta_archivo = path_models + \"hiperparametros.txt\"  # ¡Cambia esto!\n",
    "\n",
    "# Asegurarse de que la carpeta exista (si no, la crea)\n",
    "os.makedirs(os.path.dirname(ruta_archivo), exist_ok=True)\n",
    "\n",
    "# Guardar en formato legible (clave = valor)\n",
    "with open(ruta_archivo, \"w\") as f:\n",
    "    for key, value in best_params.items():\n",
    "        f.write(f\"{key} = {value}\\n\")\n",
    "\n",
    "print(f\"¡Hiperparámetros guardados en: {ruta_archivo}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "callbacks",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    path_models + \"model_single_input_silhouette_0_0.h5\",\n",
    "    monitor='val_loss', # <-- Guarda el mejor modelo basado en val_loss (más estable que val_accuracy)\n",
    "    verbose=1,\n",
    "    save_best_only=True, # guarda cuando haya mejoras\n",
    "    save_weights_only=True,\n",
    "    mode='min', #estaba en auto\n",
    "    period=10  # Guarda pesos cada 10 épocas\n",
    ")\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.001, \n",
    "    patience=10,  # <-- Detén el entrenamiento cuando val_accuracy no mejore en 10 épocas\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    mode='max'\n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitorear pérdida de validación\n",
    "    mode='min',         # Reducir LR cuando val_loss deje de disminuir\n",
    "    factor=0.5,         # Reducción moderada del LR\n",
    "    patience=3,        # Esperar 5 épocas sin mejora\n",
    "    verbose=1,\n",
    "    min_lr=1e-6         # LR mínimo permitido+\n",
    ")\n",
    "\n",
    "\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# lr_scheduler = ReduceLROnPlateau(\n",
    "#     monitor='val_accuracy',\n",
    "#     factor=0.5,  # Reducir LR a la mitad\n",
    "#     patience=10,  # Esperar 10 épocas sin mejora\n",
    "#     min_lr=1e-6,  # LR mínimo\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# Añadir a los callbacks\n",
    "callbacks = [checkpoint, reduce_lr, early]  # <-- Añadido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf827c-4bc0-41cd-b3a8-9e3d198a8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "generador_entrenamiento.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entrenamiento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "historia = modelo.fit(\n",
    "    generador_entrenamiento,\n",
    "    #steps_per_epoch=generador_entrenamiento.samples // tamaño_lote,\n",
    "    epochs=épocas,\n",
    "    validation_data=generador_validacion,\n",
    "    #validation_steps=generador_validacion.samples // tamaño_lote,\n",
    "    callbacks=callbacks,\n",
    "    # class_weight=class_weights  # <-- Añadir esto\n",
    ")\n",
    "\n",
    "modelo.save(path_models + arch + '/model_single_input_silhouette_0_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0750f-25dd-48a6-9315-3d9424d721fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_lr = modelo.optimizer.lr.numpy()\n",
    "print(f\"Learning rate actual: {current_lr}\")\n",
    "\n",
    "# Graficar el learning rate a lo largo de las épocas\n",
    "plt.plot(historia.history['lr'])\n",
    "plt.title('Learning Rate durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('LR')\n",
    "plt.savefig(path_models + \"MobileNetV2_silhouette_0_0_lr_plot.png\")  # Guarda el gráfico en accuracy_plot.png\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006185d-35d9-4357-b796-24a4135236ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save(path_models + arch + '/model_single_input_silhouette_0_0.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graficas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de Pérdida\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(historia.history['loss'], label='Training Loss')\n",
    "plt.plot(historia.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Plot\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(path_models + \"MobileNetV2_silhouette_0_0_loss_plot.png\")  # Guarda el gráfico en loss_plot.png\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de Precisión\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(historia.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(historia.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Plot\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(path_models + \"MobileNetV2_silhouette_0_0_accuracy_plot.png\")  # Guarda el gráfico en accuracy_plot.png\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce29a11-6ef1-4f99-bd5a-2355ecf7b670",
   "metadata": {},
   "source": [
    "# # #### USAR PESOS YA GUARDADOS\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "latest = path_models + arch + '/model_single_input_silhouette_0_0.h5'\n",
    "modelo = tf.keras.models.load_model(latest)\n",
    "modelo.summary()\n",
    "\n",
    "# Evaluación sobre el set de prueba\n",
    "y_pred = modelo.predict(generador_test, verbose=1)\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "true_labels = generador_test.classes\n",
    "\n",
    "\n",
    "categorias = ['Class 1', 'Class 2', 'Class 3', 'Class 4']\n",
    "\n",
    "#class_names = [\"clase_1\", \"clase_2\", \"clase_3\", \"clase_4\"]\n",
    "# class_names = [\"clase_1\", \"clase_2\"]\n",
    "# Calcular métricas\n",
    "print('Accuracy:', accuracy_score(true_labels, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Suponiendo que tienes:\n",
    "# verdaderas: etiquetas verdaderas\n",
    "# predichas: etiquetas predichas\n",
    "# categorias: nombres de las clases\n",
    "\n",
    "# Generar el reporte\n",
    "reporte = classification_report(true_labels, y_pred, target_names=categorias)\n",
    "print(reporte)\n",
    "# Guardar en un archivo .txt\n",
    "with open(path_models+'reporte_clasificacion.txt', 'w') as archivo:\n",
    "    archivo.write(reporte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d421da-2413-4156-a822-509751206ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Check Current Learning Rate######\n",
    "# current_lr = learning_rate(modelo.optimizer.iterations)\n",
    "# print(f\"Current learning rate: {current_lr.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluacion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Evaluación sobre el set de prueba\n",
    "y_pred = modelo.predict(generador_test, verbose=1)\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "true_labels = generador_test.classes\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average=None)\n",
    "recall = recall_score(true_labels, predicted_labels, average=None)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "categories = ['Class 1', 'Class 2', 'Class 3', 'Class 4']\n",
    "\n",
    "# Crear la gráfica de la matriz de confusión\n",
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Pastel1_r', xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(path_models + \"MobileNetV2_silhouette_0_0_confusion_matrix.png\")  # Guarda la imagen en un archivo PNG\n",
    "plt.close()  # Cierra la figura\n",
    "\n",
    "class_counts = cm.sum(axis=1)  # número total de instancias reales por clase\n",
    "diag = np.diag(cm)             # verdaderos positivos por clase\n",
    "class_accuracy = diag / class_counts\n",
    "\n",
    "# Tabla en pandas\n",
    "df = pd.DataFrame({\n",
    "    'Clase': categories,\n",
    "    'Accuracy': class_accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "})\n",
    "\n",
    "# Imprimir en pantalla (opcional)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(df)\n",
    "print(\"Average Precision:\", df[\"Precision\"].mean())\n",
    "print(\"Average Recall:\", df[\"Recall\"].mean())\n",
    "print(\"Average F1-Score:\", df[\"F1-Score\"].mean())\n",
    "\n",
    "# Guardar las métricas en un archivo de texto\n",
    "with open(path_models + \"MobileNetV2_silhouette_0_0_metrics.txt\", \"w\") as f:\n",
    "    f.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
    "    f.write(\"Confusion Matrix:\\n\")\n",
    "    f.write(np.array2string(cm))\n",
    "    f.write(\"\\n\\nMetrics Table:\\n\")\n",
    "    f.write(df.to_string(index=False))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(f\"Average Precision: {df['Precision'].mean()}\\n\")\n",
    "    f.write(f\"Average Recall: {df['Recall'].mean()}\\n\")\n",
    "    f.write(f\"Average F1-Score: {df['F1-Score'].mean()}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
