{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc69ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging  # [LOGGING] Importar la librería de logging\n",
    "import random  # [SEED] Importar la librería random de Python\n",
    "import numpy as np  # [SEED] Importar NumPy\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm # Para barra de progreso\n",
    "from prettytable import PrettyTable # Para tabla de parámetros (pip install prettytable)\n",
    "\n",
    "# Importar tu modelo corregido (asegúrate de que el archivo .py esté en la carpeta)\n",
    "sys.path.append(\"KAN_models\")\n",
    "from SBTAYLOR_KAN import Net as KAN_Model \n",
    "\n",
    "# Configuración de Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Semilla\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f10aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_tiny_imagenet = \"models\\\\sbtaylor_kan_tiny_imagenet\\\\run_20251224_013331\\\\best_model.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ef72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COTTON_PATH = \"./processed_dataset\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "RUN_SAVE_DIR = os.path.join(\"models/sbtaylor_kan_cotton\", f\"run_{timestamp}\")\n",
    "os.makedirs(RUN_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"sbtaylor_kan.best_weights.pth\"\n",
    "MODEL_SAVE_PATH = os.path.join(RUN_SAVE_DIR, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfee12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE_PATH = os.path.join(RUN_SAVE_DIR, \"training_run.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8887fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:53:49,229 - INFO - Modelo SBTAYLOR_KAN.Net importado correctamente.\n",
      "2026-01-02 01:53:49,231 - INFO - Los pesos del modelo se guardarán en: 'models/sbtaylor_kan_cotton\\run_20260102_015349\\sbtaylor_kan.best_weights.pth'\n",
      "2026-01-02 01:53:49,232 - INFO - El registro de entrenamiento se guardará en: 'models/sbtaylor_kan_cotton\\run_20260102_015349\\training_run.log'\n"
     ]
    }
   ],
   "source": [
    "# --- [LOGGING] CONFIGURACIÓN DEL LOGGER ---\n",
    "# Configura el logger para que escriba en un archivo y en la consola.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Nivel mínimo de mensajes a registrar (INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # Formato del mensaje\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            LOG_FILE_PATH, mode=\"w\"\n",
    "        ),  # Escribe en el archivo .log (modo 'w' para sobreescribir en cada ejecución)\n",
    "        logging.StreamHandler(),  # Muestra los logs en la consola\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Ahora, en lugar de print(), usaremos logging.info()\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.info(\"Modelo SBTAYLOR_KAN.Net importado correctamente.\")\n",
    "logger.info(f\"Los pesos del modelo se guardarán en: '{MODEL_SAVE_PATH}'\")\n",
    "logger.info(f\"El registro de entrenamiento se guardará en: '{LOG_FILE_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19af029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:53:49,260 - INFO - Versión de PyTorch: 2.9.0+cu126\n",
      "2026-01-02 01:53:49,261 - INFO - ¿CUDA está disponible?: True\n",
      "2026-01-02 01:53:49,262 - INFO - Versión de CUDA con la que PyTorch fue compilado: 12.6\n",
      "2026-01-02 01:53:49,264 - INFO - Número de GPUs disponibles: 1\n",
      "2026-01-02 01:53:49,269 - INFO - Nombre de la GPU actual: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Versión de PyTorch: {torch.__version__}\")\n",
    "logger.info(f\"¿CUDA está disponible?: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(\n",
    "        f\"Versión de CUDA con la que PyTorch fue compilado: {torch.version.cuda}\"\n",
    "    )\n",
    "    logger.info(f\"Número de GPUs disponibles: {torch.cuda.device_count()}\")\n",
    "    logger.info(f\"Nombre de la GPU actual: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logger.info(\n",
    "        \"PyTorch no puede encontrar CUDA. Es probable que hayas instalado la versión de solo CPU.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8478fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:53:49,292 - INFO - --- Hyperparámetros de Entrenamiento ---\n",
      "2026-01-02 01:53:49,293 - INFO - Batch Size: 64\n",
      "2026-01-02 01:53:49,294 - INFO - Num Epochs: 150\n",
      "2026-01-02 01:53:49,296 - INFO - Learning Rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# --- 2. PARÁMETROS DE ENTRENAMIENTO ---\n",
    "set_seed(42)  # [SEED] Establecer la semilla para reproducibilidad\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 150\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# print hyperparameters\n",
    "logging.info(f\"--- Hyperparámetros de Entrenamiento ---\")\n",
    "logging.info(f\"Batch Size: {BATCH_SIZE}\")\n",
    "logging.info(f\"Num Epochs: {NUM_EPOCHS}\")\n",
    "logging.info(f\"Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe23f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:53:49,327 - INFO - \n",
      "Cargando dataset de ./processed_dataset...\n",
      "2026-01-02 01:53:49,349 - INFO - Clases detectadas: ['Aphids', 'Army worm', 'Bacterial Blight', 'Healthy', 'Powdery Mildew', 'Target spot']\n"
     ]
    }
   ],
   "source": [
    "# --- 3. PREPARACIÓN DEL DATASET IMAGENET ---\n",
    "# (El código interno no cambia, solo los prints)\n",
    "transform_train = transforms.Compose([\n",
    "    # 1. Zoom y Recorte Aleatorio: Simula diferentes distancias de la cámara\n",
    "    # Toma un área de entre el 80% y 100% de la hoja y la estira a 224x224\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    \n",
    "    # 2. Rotación Total: Las hojas pueden estar en cualquier ángulo\n",
    "    transforms.RandomRotation(degrees=180), \n",
    "    \n",
    "    # 3. Flips: Muy efectivos para hojas\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    \n",
    "    # 4. Jitter de Color: Vital para cambios de luz en el campo\n",
    "    # Varía brillo, contraste y saturación sutilmente\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    \n",
    "    # 5. Transformaciones finales obligatorias\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_val = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256), # Redimensionar para validación\n",
    "        transforms.CenterCrop(224), # Recorte central\n",
    "        transforms.ToTensor(), # Convertir a tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalización\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(f\"\\nCargando dataset de {COTTON_PATH}...\")\n",
    "if not os.path.isdir(COTTON_PATH):\n",
    "    logger.error(f\"Error: La ruta de ('{COTTON_PATH}') no es válida.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(COTTON_PATH, \"train\"), transform=transform_train\n",
    ")\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(COTTON_PATH, \"val\"), transform=transform_val\n",
    ")\n",
    "\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True),\n",
    "    'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}\n",
    "class_names = train_dataset.classes\n",
    "logger.info(f\"Clases detectadas: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe621b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:53:49,370 - INFO - \n",
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 4. INICIALIZACIÓN DEL MODELO, CRITERIO Y OPTIMIZADOR ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"\\nUsando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063639c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones calculadas automáticamente para FC1: 25088\n",
      "✅ Pesos cargados correctamente. Se ignoraron las capas incompatibles (fc3).\n",
      "Capas cargadas: 38 de 41\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
      "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
      "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
      "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
      "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
      "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
      "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
      "├─KANLinear: 1-3                         [-1, 256]                 --\n",
      "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
      "├─Dropout: 1-4                           [-1, 256]                 --\n",
      "├─KANLinear: 1-5                         [-1, 128]                 --\n",
      "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
      "├─Dropout: 1-6                           [-1, 128]                 --\n",
      "├─KANLinear: 1-7                         [-1, 6]                   --\n",
      "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
      "==========================================================================================\n",
      "Total params: 241,536\n",
      "Trainable params: 241,536\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 679.73\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 44.41\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 45.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
       "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
       "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
       "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
       "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
       "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
       "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
       "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
       "├─KANLinear: 1-3                         [-1, 256]                 --\n",
       "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
       "├─Dropout: 1-4                           [-1, 256]                 --\n",
       "├─KANLinear: 1-5                         [-1, 128]                 --\n",
       "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
       "├─Dropout: 1-6                           [-1, 128]                 --\n",
       "├─KANLinear: 1-7                         [-1, 6]                   --\n",
       "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
       "==========================================================================================\n",
       "Total params: 241,536\n",
       "Trainable params: 241,536\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 679.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 44.41\n",
       "Params size (MB): 0.92\n",
       "Estimated Total Size (MB): 45.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instancia tu modelo con las clases de TU problema actual (Algodón = 6)\n",
    "num_classes_cotton = len(class_names) # Asumo que esto es 6\n",
    "model_ft = KAN_Model(num_classes=num_classes_cotton).to(device)\n",
    "\n",
    "# 2. Cargar el diccionario de pesos original\n",
    "pretrained_dict = torch.load(weights_tiny_imagenet)\n",
    "\n",
    "# 3. Obtener el diccionario de pesos del modelo actual\n",
    "model_dict = model_ft.state_dict()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# PASO CRÍTICO: FILTRADO DE PESOS\n",
    "# -----------------------------------------------------------\n",
    "# Vamos a filtrar los pesos, quedándonos solo con aquellos que:\n",
    "# 1. Existan en el modelo actual.\n",
    "# 2. Tengan el mismo tamaño (shape) que en el modelo actual.\n",
    "# Esto eliminará automáticamente 'fc3.weight', 'fc3.bias', etc.\n",
    "pretrained_dict = {\n",
    "    k: v for k, v in pretrained_dict.items() \n",
    "    if k in model_dict and v.shape == model_dict[k].shape\n",
    "}\n",
    "\n",
    "# 4. Actualizar el diccionario del modelo actual con los pesos filtrados\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# 5. Cargar el diccionario final en el modelo\n",
    "# Usamos strict=True porque ya hemos filtrado manualmente lo que no sirve\n",
    "model_ft.load_state_dict(model_dict)\n",
    "\n",
    "print(f\"✅ Pesos cargados correctamente. Se ignoraron las capas incompatibles (fc3).\")\n",
    "print(f\"Capas cargadas: {len(pretrained_dict)} de {len(model_dict)}\")\n",
    "\n",
    "# 6. Verificar\n",
    "from torchsummary import summary\n",
    "summary(model_ft, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b21e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 01:53:50,906 - INFO - Iniciando entrenamiento por 150 épocas...\n",
      "2026-01-02 01:53:50,907 - INFO - Paciencia configurada: 10 épocas.\n",
      "2026-01-02 01:53:50,908 - INFO - --- Época 1/150 ---\n",
      "2026-01-02 01:54:34,720 - INFO - Train Loss: 1.7976 Acc: 0.2165  \n",
      "2026-01-02 01:54:37,729 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:54:37,730 - INFO -   [Mejora Loss] inf -> 1.7263. Reseteando paciencia.\n",
      "2026-01-02 01:54:37,731 - INFO - Val Loss: 1.7263 Acc: 0.3137\n",
      "2026-01-02 01:54:38,187 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:54:38,188 - INFO - --- Época 2/150 ---\n",
      "2026-01-02 01:55:23,602 - INFO - Train Loss: 1.6496 Acc: 0.3013  \n",
      "2026-01-02 01:55:26,557 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:55:26,558 - INFO -   [Mejora Loss] 1.7263 -> 1.5630. Reseteando paciencia.\n",
      "2026-01-02 01:55:26,559 - INFO - Val Loss: 1.5630 Acc: 0.3697\n",
      "2026-01-02 01:55:27,108 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:55:27,110 - INFO - --- Época 3/150 ---\n",
      "2026-01-02 01:56:11,964 - INFO - Train Loss: 1.5079 Acc: 0.3910  \n",
      "2026-01-02 01:56:14,826 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:56:14,827 - INFO -   [Mejora Loss] 1.5630 -> 1.4642. Reseteando paciencia.\n",
      "2026-01-02 01:56:14,828 - INFO - Val Loss: 1.4642 Acc: 0.4314\n",
      "2026-01-02 01:56:15,278 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:56:15,280 - INFO - --- Época 4/150 ---\n",
      "2026-01-02 01:56:59,372 - INFO - Train Loss: 1.3875 Acc: 0.4473  \n",
      "2026-01-02 01:57:02,510 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:57:02,511 - INFO -   [Mejora Loss] 1.4642 -> 1.3825. Reseteando paciencia.\n",
      "2026-01-02 01:57:02,512 - INFO - Val Loss: 1.3825 Acc: 0.5462\n",
      "2026-01-02 01:57:02,967 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:57:02,969 - INFO - --- Época 5/150 ---\n",
      "2026-01-02 01:57:48,264 - INFO - Train Loss: 1.2808 Acc: 0.5085  \n",
      "2026-01-02 01:57:51,283 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:57:51,284 - INFO -   [Mejora Loss] 1.3825 -> 1.2924. Reseteando paciencia.\n",
      "2026-01-02 01:57:51,285 - INFO - Val Loss: 1.2924 Acc: 0.5994\n",
      "2026-01-02 01:57:51,763 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:57:51,764 - INFO - --- Época 6/150 ---\n",
      "2026-01-02 01:58:36,926 - INFO - Train Loss: 1.1951 Acc: 0.5502   \n",
      "2026-01-02 01:58:39,974 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:58:39,975 - INFO -   [Mejora Loss] 1.2924 -> 1.2258. Reseteando paciencia.\n",
      "2026-01-02 01:58:39,975 - INFO - Val Loss: 1.2258 Acc: 0.6275\n",
      "2026-01-02 01:58:40,418 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:58:40,419 - INFO - --- Época 7/150 ---\n",
      "2026-01-02 01:59:24,214 - INFO - Train Loss: 1.1364 Acc: 0.5726   \n",
      "2026-01-02 01:59:27,037 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 01:59:27,038 - INFO -   [Mejora Loss] 1.2258 -> 1.1570. Reseteando paciencia.\n",
      "2026-01-02 01:59:27,039 - INFO - Val Loss: 1.1570 Acc: 0.6331\n",
      "2026-01-02 01:59:27,459 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 01:59:27,461 - INFO - --- Época 8/150 ---\n",
      "2026-01-02 02:00:13,734 - INFO - Train Loss: 1.0721 Acc: 0.6122   \n",
      "2026-01-02 02:00:20,718 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:00:20,720 - INFO -   [Mejora Loss] 1.1570 -> 1.0981. Reseteando paciencia.\n",
      "2026-01-02 02:00:20,723 - INFO - Val Loss: 1.0981 Acc: 0.6443\n",
      "2026-01-02 02:00:21,316 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:00:21,318 - INFO - --- Época 9/150 ---\n",
      "2026-01-02 02:02:27,967 - INFO - Train Loss: 1.0212 Acc: 0.6250   \n",
      "2026-01-02 02:02:36,345 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:02:36,346 - INFO -   [Mejora Loss] 1.0981 -> 1.0632. Reseteando paciencia.\n",
      "2026-01-02 02:02:36,348 - INFO - Val Loss: 1.0632 Acc: 0.6639\n",
      "2026-01-02 02:02:36,874 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:02:36,876 - INFO - --- Época 10/150 ---\n",
      "2026-01-02 02:04:44,889 - INFO - Train Loss: 0.9886 Acc: 0.6549   \n",
      "2026-01-02 02:04:53,253 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:04:53,254 - INFO -   [Mejora Loss] 1.0632 -> 1.0165. Reseteando paciencia.\n",
      "2026-01-02 02:04:53,256 - INFO - Val Loss: 1.0165 Acc: 0.6863\n",
      "2026-01-02 02:04:54,129 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:04:54,130 - INFO - --- Época 11/150 ---\n",
      "2026-01-02 02:07:03,301 - INFO - Train Loss: 0.9510 Acc: 0.6620   \n",
      "2026-01-02 02:07:12,105 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:07:12,107 - INFO -   [Mejora Loss] 1.0165 -> 0.9696. Reseteando paciencia.\n",
      "2026-01-02 02:07:12,108 - INFO - Val Loss: 0.9696 Acc: 0.7059\n",
      "2026-01-02 02:07:13,077 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:07:13,078 - INFO - --- Época 12/150 ---\n",
      "2026-01-02 02:09:23,007 - INFO - Train Loss: 0.9234 Acc: 0.6763   \n",
      "2026-01-02 02:09:31,246 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:09:31,247 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 02:09:31,251 - INFO - Val Loss: 0.9822 Acc: 0.7227\n",
      "2026-01-02 02:09:32,112 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:09:32,114 - INFO - --- Época 13/150 ---\n",
      "2026-01-02 02:11:36,883 - INFO - Train Loss: 0.8821 Acc: 0.6866   \n",
      "2026-01-02 02:11:45,322 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:11:45,323 - INFO -   [Mejora Loss] 0.9696 -> 0.9065. Reseteando paciencia.\n",
      "2026-01-02 02:11:45,326 - INFO - Val Loss: 0.9065 Acc: 0.7255\n",
      "2026-01-02 02:11:45,816 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:11:45,818 - INFO - --- Época 14/150 ---\n",
      "2026-01-02 02:13:55,126 - INFO - Train Loss: 0.8797 Acc: 0.6827   \n",
      "2026-01-02 02:14:05,230 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:14:05,231 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 02:14:05,232 - INFO - Val Loss: 0.9593 Acc: 0.7031\n",
      "2026-01-02 02:14:05,237 - INFO - --- Época 15/150 ---\n",
      "2026-01-02 02:16:10,888 - INFO - Train Loss: 0.8042 Acc: 0.7251   \n",
      "2026-01-02 02:16:19,229 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:16:19,232 - INFO -   [Mejora Loss] 0.9065 -> 0.8754. Reseteando paciencia.\n",
      "2026-01-02 02:16:19,234 - INFO - Val Loss: 0.8754 Acc: 0.7451\n",
      "2026-01-02 02:16:20,999 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:16:21,002 - INFO - --- Época 16/150 ---\n",
      "2026-01-02 02:18:29,448 - INFO - Train Loss: 0.8022 Acc: 0.7233   \n",
      "2026-01-02 02:18:38,953 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:18:38,954 - INFO -   [Mejora Loss] 0.8754 -> 0.8646. Reseteando paciencia.\n",
      "2026-01-02 02:18:38,955 - INFO - Val Loss: 0.8646 Acc: 0.7395\n",
      "2026-01-02 02:18:38,957 - INFO - --- Época 17/150 ---\n",
      "2026-01-02 02:20:47,316 - INFO - Train Loss: 0.7791 Acc: 0.7390   \n",
      "2026-01-02 02:20:56,539 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:20:56,540 - INFO -   [Mejora Loss] 0.8646 -> 0.8449. Reseteando paciencia.\n",
      "2026-01-02 02:20:56,542 - INFO - Val Loss: 0.8449 Acc: 0.7451\n",
      "2026-01-02 02:20:56,544 - INFO - --- Época 18/150 ---\n",
      "2026-01-02 02:23:02,373 - INFO - Train Loss: 0.7314 Acc: 0.7539   \n",
      "2026-01-02 02:23:11,443 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:23:11,445 - INFO -   [Mejora Loss] 0.8449 -> 0.8087. Reseteando paciencia.\n",
      "2026-01-02 02:23:11,448 - INFO - Val Loss: 0.8087 Acc: 0.7395\n",
      "2026-01-02 02:23:11,450 - INFO - --- Época 19/150 ---\n",
      "2026-01-02 02:25:19,495 - INFO - Train Loss: 0.7211 Acc: 0.7561   \n",
      "2026-01-02 02:25:28,329 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:25:28,330 - INFO -   [Mejora Loss] 0.8087 -> 0.7520. Reseteando paciencia.\n",
      "2026-01-02 02:25:28,331 - INFO - Val Loss: 0.7520 Acc: 0.7675\n",
      "2026-01-02 02:25:28,892 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:25:28,894 - INFO - --- Época 20/150 ---\n",
      "2026-01-02 02:27:38,468 - INFO - Train Loss: 0.6711 Acc: 0.7728   \n",
      "2026-01-02 02:27:47,222 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:27:47,223 - INFO -   [Mejora Loss] 0.7520 -> 0.7505. Reseteando paciencia.\n",
      "2026-01-02 02:27:47,225 - INFO - Val Loss: 0.7505 Acc: 0.7703\n",
      "2026-01-02 02:27:47,864 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:27:47,866 - INFO - --- Época 21/150 ---\n",
      "2026-01-02 02:29:55,645 - INFO - Train Loss: 0.6628 Acc: 0.7774   \n",
      "2026-01-02 02:30:03,429 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:30:03,430 - INFO -   [Mejora Loss] 0.7505 -> 0.7435. Reseteando paciencia.\n",
      "2026-01-02 02:30:03,432 - INFO - Val Loss: 0.7435 Acc: 0.7619\n",
      "2026-01-02 02:30:03,433 - INFO - --- Época 22/150 ---\n",
      "2026-01-02 02:32:12,647 - INFO - Train Loss: 0.6444 Acc: 0.7799   \n",
      "2026-01-02 02:32:21,663 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:32:21,664 - INFO -   [Mejora Loss] 0.7435 -> 0.6649. Reseteando paciencia.\n",
      "2026-01-02 02:32:21,665 - INFO - Val Loss: 0.6649 Acc: 0.8095\n",
      "2026-01-02 02:32:22,216 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:32:22,218 - INFO - --- Época 23/150 ---\n",
      "2026-01-02 02:34:33,324 - INFO - Train Loss: 0.6403 Acc: 0.7838   \n",
      "2026-01-02 02:34:43,833 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:34:43,834 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 02:34:43,835 - INFO - Val Loss: 0.7123 Acc: 0.7815\n",
      "2026-01-02 02:34:43,864 - INFO - --- Época 24/150 ---\n",
      "2026-01-02 02:36:52,871 - INFO - Train Loss: 0.6551 Acc: 0.7785   \n",
      "2026-01-02 02:37:01,445 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:37:01,446 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 02:37:01,447 - INFO - Val Loss: 0.6658 Acc: 0.8011\n",
      "2026-01-02 02:37:01,449 - INFO - --- Época 25/150 ---\n",
      "2026-01-02 02:39:08,727 - INFO - Train Loss: 0.6163 Acc: 0.8002   \n",
      "2026-01-02 02:39:17,168 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:39:17,169 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 02:39:17,171 - INFO - Val Loss: 0.6999 Acc: 0.7843\n",
      "2026-01-02 02:39:17,172 - INFO - --- Época 26/150 ---\n",
      "2026-01-02 02:41:26,020 - INFO - Train Loss: 0.5906 Acc: 0.8127   \n",
      "2026-01-02 02:41:35,419 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:41:35,420 - INFO -   [Mejora Loss] 0.6649 -> 0.6578. Reseteando paciencia.\n",
      "2026-01-02 02:41:35,421 - INFO - Val Loss: 0.6578 Acc: 0.8207\n",
      "2026-01-02 02:41:36,227 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:41:36,232 - INFO - --- Época 27/150 ---\n",
      "2026-01-02 02:43:46,024 - INFO - Train Loss: 0.5805 Acc: 0.8105   \n",
      "2026-01-02 02:43:54,894 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:43:54,895 - INFO -   [Mejora Loss] 0.6578 -> 0.6486. Reseteando paciencia.\n",
      "2026-01-02 02:43:54,896 - INFO - Val Loss: 0.6486 Acc: 0.8011\n",
      "2026-01-02 02:43:54,897 - INFO - --- Época 28/150 ---\n",
      "2026-01-02 02:46:02,434 - INFO - Train Loss: 0.5740 Acc: 0.8088   \n",
      "2026-01-02 02:46:11,341 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:46:11,342 - INFO -   [Mejora Loss] 0.6486 -> 0.6315. Reseteando paciencia.\n",
      "2026-01-02 02:46:11,344 - INFO - Val Loss: 0.6315 Acc: 0.8095\n",
      "2026-01-02 02:46:11,345 - INFO - --- Época 29/150 ---\n",
      "2026-01-02 02:48:17,211 - INFO - Train Loss: 0.5653 Acc: 0.8180   \n",
      "2026-01-02 02:48:25,914 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:48:25,917 - INFO -   [Mejora Loss] 0.6315 -> 0.6290. Reseteando paciencia.\n",
      "2026-01-02 02:48:25,921 - INFO - Val Loss: 0.6290 Acc: 0.8319\n",
      "2026-01-02 02:48:26,633 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:48:26,636 - INFO - --- Época 30/150 ---\n",
      "2026-01-02 02:50:38,946 - INFO - Train Loss: 0.5723 Acc: 0.8219   \n",
      "2026-01-02 02:50:49,256 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:50:49,259 - INFO -   [Mejora Loss] 0.6290 -> 0.5944. Reseteando paciencia.\n",
      "2026-01-02 02:50:49,261 - INFO - Val Loss: 0.5944 Acc: 0.8431\n",
      "2026-01-02 02:50:49,892 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:50:49,894 - INFO - --- Época 31/150 ---\n",
      "2026-01-02 02:52:57,656 - INFO - Train Loss: 0.5718 Acc: 0.8127   \n",
      "2026-01-02 02:53:07,106 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:53:07,108 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 02:53:07,109 - INFO - Val Loss: 0.5948 Acc: 0.8319\n",
      "2026-01-02 02:53:07,111 - INFO - --- Época 32/150 ---\n",
      "2026-01-02 02:55:18,024 - INFO - Train Loss: 0.5415 Acc: 0.8259   \n",
      "2026-01-02 02:55:26,608 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:55:26,609 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 02:55:26,611 - INFO - Val Loss: 0.6483 Acc: 0.7899\n",
      "2026-01-02 02:55:26,613 - INFO - --- Época 33/150 ---\n",
      "2026-01-02 02:57:00,555 - INFO - Train Loss: 0.5408 Acc: 0.8234   \n",
      "2026-01-02 02:57:03,397 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:57:03,398 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 02:57:03,399 - INFO - Val Loss: 0.5965 Acc: 0.8319\n",
      "2026-01-02 02:57:03,400 - INFO - --- Época 34/150 ---\n",
      "2026-01-02 02:57:46,595 - INFO - Train Loss: 0.5137 Acc: 0.8344   \n",
      "2026-01-02 02:57:49,371 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:57:49,372 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 02:57:49,374 - INFO - Val Loss: 0.6459 Acc: 0.7703\n",
      "2026-01-02 02:57:49,375 - INFO - --- Época 35/150 ---\n",
      "2026-01-02 02:58:32,781 - INFO - Train Loss: 0.4977 Acc: 0.8390   \n",
      "2026-01-02 02:58:35,608 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:58:35,609 - INFO -   [Mejora Loss] 0.5944 -> 0.5625. Reseteando paciencia.\n",
      "2026-01-02 02:58:35,610 - INFO - Val Loss: 0.5625 Acc: 0.8515\n",
      "2026-01-02 02:58:36,045 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 02:58:36,048 - INFO - --- Época 36/150 ---\n",
      "2026-01-02 02:59:19,021 - INFO - Train Loss: 0.5093 Acc: 0.8458   \n",
      "2026-01-02 02:59:21,790 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 02:59:21,791 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 02:59:21,792 - INFO - Val Loss: 0.5981 Acc: 0.8235\n",
      "2026-01-02 02:59:21,793 - INFO - --- Época 37/150 ---\n",
      "2026-01-02 03:00:04,655 - INFO - Train Loss: 0.4931 Acc: 0.8501   \n",
      "2026-01-02 03:00:07,347 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:00:07,348 - INFO -   [Mejora Loss] 0.5625 -> 0.5264. Reseteando paciencia.\n",
      "2026-01-02 03:00:07,349 - INFO - Val Loss: 0.5264 Acc: 0.8599\n",
      "2026-01-02 03:00:07,763 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:00:07,764 - INFO - --- Época 38/150 ---\n",
      "2026-01-02 03:00:50,824 - INFO - Train Loss: 0.4923 Acc: 0.8429   \n",
      "2026-01-02 03:00:53,550 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:00:53,551 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:00:53,552 - INFO - Val Loss: 0.5321 Acc: 0.8459\n",
      "2026-01-02 03:00:53,553 - INFO - --- Época 39/150 ---\n",
      "2026-01-02 03:01:36,138 - INFO - Train Loss: 0.4764 Acc: 0.8451   \n",
      "2026-01-02 03:01:38,871 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:01:38,872 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:01:38,873 - INFO - Val Loss: 0.5706 Acc: 0.8263\n",
      "2026-01-02 03:01:38,874 - INFO - --- Época 40/150 ---\n",
      "2026-01-02 03:02:21,411 - INFO - Train Loss: 0.4750 Acc: 0.8508   \n",
      "2026-01-02 03:02:24,145 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:02:24,146 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:02:24,147 - INFO - Val Loss: 0.5501 Acc: 0.8319\n",
      "2026-01-02 03:02:24,147 - INFO - --- Época 41/150 ---\n",
      "2026-01-02 03:03:07,025 - INFO - Train Loss: 0.4905 Acc: 0.8444   \n",
      "2026-01-02 03:03:09,841 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:03:09,842 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:03:09,843 - INFO - Val Loss: 0.5532 Acc: 0.8515\n",
      "2026-01-02 03:03:09,844 - INFO - --- Época 42/150 ---\n",
      "2026-01-02 03:03:52,939 - INFO - Train Loss: 0.4586 Acc: 0.8533   \n",
      "2026-01-02 03:03:55,758 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:03:55,759 - INFO -   [Mejora Loss] 0.5264 -> 0.4853. Reseteando paciencia.\n",
      "2026-01-02 03:03:55,760 - INFO - Val Loss: 0.4853 Acc: 0.8711\n",
      "2026-01-02 03:03:56,183 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:03:56,185 - INFO - --- Época 43/150 ---\n",
      "2026-01-02 03:04:39,533 - INFO - Train Loss: 0.4432 Acc: 0.8636   \n",
      "2026-01-02 03:04:42,288 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:04:42,289 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:04:42,291 - INFO - Val Loss: 0.5654 Acc: 0.8067\n",
      "2026-01-02 03:04:42,292 - INFO - --- Época 44/150 ---\n",
      "2026-01-02 03:05:25,823 - INFO - Train Loss: 0.4539 Acc: 0.8572   \n",
      "2026-01-02 03:05:28,635 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:05:28,636 - INFO -   [Mejora Loss] 0.4853 -> 0.4713. Reseteando paciencia.\n",
      "2026-01-02 03:05:28,637 - INFO - Val Loss: 0.4713 Acc: 0.8683\n",
      "2026-01-02 03:05:28,638 - INFO - --- Época 45/150 ---\n",
      "2026-01-02 03:06:11,353 - INFO - Train Loss: 0.4637 Acc: 0.8575   \n",
      "2026-01-02 03:06:14,141 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:06:14,142 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:06:14,143 - INFO - Val Loss: 0.4790 Acc: 0.8824\n",
      "2026-01-02 03:06:14,559 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:06:14,561 - INFO - --- Época 46/150 ---\n",
      "2026-01-02 03:06:57,854 - INFO - Train Loss: 0.4244 Acc: 0.8618   \n",
      "2026-01-02 03:07:00,703 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:07:00,703 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:07:00,705 - INFO - Val Loss: 0.5021 Acc: 0.8543\n",
      "2026-01-02 03:07:00,706 - INFO - --- Época 47/150 ---\n",
      "2026-01-02 03:07:43,695 - INFO - Train Loss: 0.4282 Acc: 0.8643   \n",
      "2026-01-02 03:07:46,436 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:07:46,437 - INFO -   [Mejora Loss] 0.4713 -> 0.4688. Reseteando paciencia.\n",
      "2026-01-02 03:07:46,439 - INFO - Val Loss: 0.4688 Acc: 0.8739\n",
      "2026-01-02 03:07:46,440 - INFO - --- Época 48/150 ---\n",
      "2026-01-02 03:08:30,163 - INFO - Train Loss: 0.4291 Acc: 0.8672   \n",
      "2026-01-02 03:08:32,940 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:08:32,940 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:08:32,942 - INFO - Val Loss: 0.4944 Acc: 0.8571\n",
      "2026-01-02 03:08:32,943 - INFO - --- Época 49/150 ---\n",
      "2026-01-02 03:09:16,212 - INFO - Train Loss: 0.4236 Acc: 0.8704   \n",
      "2026-01-02 03:09:18,934 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:09:18,935 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:09:18,936 - INFO - Val Loss: 0.5446 Acc: 0.8347\n",
      "2026-01-02 03:09:18,936 - INFO - --- Época 50/150 ---\n",
      "2026-01-02 03:10:02,134 - INFO - Train Loss: 0.4213 Acc: 0.8665   \n",
      "2026-01-02 03:10:04,930 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:10:04,931 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:10:04,932 - INFO - Val Loss: 0.5001 Acc: 0.8543\n",
      "2026-01-02 03:10:04,933 - INFO - --- Época 51/150 ---\n",
      "2026-01-02 03:10:48,085 - INFO - Train Loss: 0.4248 Acc: 0.8672   \n",
      "2026-01-02 03:10:50,823 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:10:50,824 - INFO -   [Mejora Loss] 0.4688 -> 0.4497. Reseteando paciencia.\n",
      "2026-01-02 03:10:50,824 - INFO - Val Loss: 0.4497 Acc: 0.8768\n",
      "2026-01-02 03:10:50,825 - INFO - --- Época 52/150 ---\n",
      "2026-01-02 03:11:33,935 - INFO - Train Loss: 0.4090 Acc: 0.8718   \n",
      "2026-01-02 03:11:36,802 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:11:36,804 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:11:36,807 - INFO - Val Loss: 0.5005 Acc: 0.8487\n",
      "2026-01-02 03:11:36,808 - INFO - --- Época 53/150 ---\n",
      "2026-01-02 03:12:19,547 - INFO - Train Loss: 0.4317 Acc: 0.8579   \n",
      "2026-01-02 03:12:22,364 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:12:22,365 - INFO -   [Mejora Loss] 0.4497 -> 0.4490. Reseteando paciencia.\n",
      "2026-01-02 03:12:22,366 - INFO - Val Loss: 0.4490 Acc: 0.8852\n",
      "2026-01-02 03:12:22,778 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:12:22,780 - INFO - --- Época 54/150 ---\n",
      "2026-01-02 03:13:07,081 - INFO - Train Loss: 0.4024 Acc: 0.8789   \n",
      "2026-01-02 03:13:09,944 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:13:09,945 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:13:09,946 - INFO - Val Loss: 0.4730 Acc: 0.8768\n",
      "2026-01-02 03:13:09,947 - INFO - --- Época 55/150 ---\n",
      "2026-01-02 03:13:53,634 - INFO - Train Loss: 0.4173 Acc: 0.8689   \n",
      "2026-01-02 03:13:56,415 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:13:56,416 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:13:56,417 - INFO - Val Loss: 0.4990 Acc: 0.8571\n",
      "2026-01-02 03:13:56,418 - INFO - --- Época 56/150 ---\n",
      "2026-01-02 03:14:39,828 - INFO - Train Loss: 0.4114 Acc: 0.8686   \n",
      "2026-01-02 03:14:42,649 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:14:42,650 - INFO -   [Mejora Loss] 0.4490 -> 0.4444. Reseteando paciencia.\n",
      "2026-01-02 03:14:42,651 - INFO - Val Loss: 0.4444 Acc: 0.8880\n",
      "2026-01-02 03:14:43,068 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:14:43,069 - INFO - --- Época 57/150 ---\n",
      "2026-01-02 03:15:26,762 - INFO - Train Loss: 0.4019 Acc: 0.8722   \n",
      "2026-01-02 03:15:29,465 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:15:29,466 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:15:29,467 - INFO - Val Loss: 0.4779 Acc: 0.8543\n",
      "2026-01-02 03:15:29,468 - INFO - --- Época 58/150 ---\n",
      "2026-01-02 03:16:13,371 - INFO - Train Loss: 0.3905 Acc: 0.8764   \n",
      "2026-01-02 03:16:16,210 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:16:16,211 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:16:16,213 - INFO - Val Loss: 0.4545 Acc: 0.8683\n",
      "2026-01-02 03:16:16,213 - INFO - --- Época 59/150 ---\n",
      "2026-01-02 03:16:59,563 - INFO - Train Loss: 0.4029 Acc: 0.8743   \n",
      "2026-01-02 03:17:02,322 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:17:02,323 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:17:02,324 - INFO - Val Loss: 0.4802 Acc: 0.8599\n",
      "2026-01-02 03:17:02,325 - INFO - --- Época 60/150 ---\n",
      "2026-01-02 03:17:44,856 - INFO - Train Loss: 0.3960 Acc: 0.8914   \n",
      "2026-01-02 03:17:47,613 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:17:47,614 - INFO -   [Mejora Loss] 0.4444 -> 0.4259. Reseteando paciencia.\n",
      "2026-01-02 03:17:47,615 - INFO - Val Loss: 0.4259 Acc: 0.8739\n",
      "2026-01-02 03:17:47,617 - INFO - --- Época 61/150 ---\n",
      "2026-01-02 03:18:30,591 - INFO - Train Loss: 0.3822 Acc: 0.8825   \n",
      "2026-01-02 03:18:33,358 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:18:33,359 - INFO -   [Mejora Loss] 0.4259 -> 0.4245. Reseteando paciencia.\n",
      "2026-01-02 03:18:33,361 - INFO - Val Loss: 0.4245 Acc: 0.8880\n",
      "2026-01-02 03:18:33,362 - INFO - --- Época 62/150 ---\n",
      "2026-01-02 03:19:16,194 - INFO - Train Loss: 0.4264 Acc: 0.8647   \n",
      "2026-01-02 03:19:18,912 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:19:18,912 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:19:18,913 - INFO - Val Loss: 0.5017 Acc: 0.8571\n",
      "2026-01-02 03:19:18,914 - INFO - --- Época 63/150 ---\n",
      "2026-01-02 03:20:02,109 - INFO - Train Loss: 0.3933 Acc: 0.8892   \n",
      "2026-01-02 03:20:04,887 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:20:04,888 - INFO -   [Mejora Loss] 0.4245 -> 0.4193. Reseteando paciencia.\n",
      "2026-01-02 03:20:04,889 - INFO - Val Loss: 0.4193 Acc: 0.8852\n",
      "2026-01-02 03:20:04,890 - INFO - --- Época 64/150 ---\n",
      "2026-01-02 03:20:48,320 - INFO - Train Loss: 0.3950 Acc: 0.8768   \n",
      "2026-01-02 03:20:51,071 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:20:51,072 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:20:51,073 - INFO - Val Loss: 0.4401 Acc: 0.8824\n",
      "2026-01-02 03:20:51,075 - INFO - --- Época 65/150 ---\n",
      "2026-01-02 03:21:34,996 - INFO - Train Loss: 0.3688 Acc: 0.8910   \n",
      "2026-01-02 03:21:37,760 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:21:37,762 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:21:37,763 - INFO - Val Loss: 0.4235 Acc: 0.8711\n",
      "2026-01-02 03:21:37,764 - INFO - --- Época 66/150 ---\n",
      "2026-01-02 03:22:20,867 - INFO - Train Loss: 0.3831 Acc: 0.8789   \n",
      "2026-01-02 03:22:23,673 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:22:23,674 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:22:23,675 - INFO - Val Loss: 0.4225 Acc: 0.8739\n",
      "2026-01-02 03:22:23,676 - INFO - --- Época 67/150 ---\n",
      "2026-01-02 03:23:07,055 - INFO - Train Loss: 0.3737 Acc: 0.8889   \n",
      "2026-01-02 03:23:09,915 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:23:09,916 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:23:09,917 - INFO - Val Loss: 0.4757 Acc: 0.8431\n",
      "2026-01-02 03:23:09,919 - INFO - --- Época 68/150 ---\n",
      "2026-01-02 03:23:52,755 - INFO - Train Loss: 0.3699 Acc: 0.8882   \n",
      "2026-01-02 03:23:55,566 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:23:55,567 - INFO -   [Sin mejora Loss] Paciencia: 5/10\n",
      "2026-01-02 03:23:55,568 - INFO - Val Loss: 0.4281 Acc: 0.8880\n",
      "2026-01-02 03:23:55,570 - INFO - --- Época 69/150 ---\n",
      "2026-01-02 03:24:38,610 - INFO - Train Loss: 0.3580 Acc: 0.8967   \n",
      "2026-01-02 03:24:41,342 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:24:41,343 - INFO -   [Mejora Loss] 0.4193 -> 0.4184. Reseteando paciencia.\n",
      "2026-01-02 03:24:41,345 - INFO - Val Loss: 0.4184 Acc: 0.8796\n",
      "2026-01-02 03:24:41,346 - INFO - --- Época 70/150 ---\n",
      "2026-01-02 03:25:24,446 - INFO - Train Loss: 0.3512 Acc: 0.8942   \n",
      "2026-01-02 03:25:27,325 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:25:27,326 - INFO -   [Mejora Loss] 0.4184 -> 0.3971. Reseteando paciencia.\n",
      "2026-01-02 03:25:27,327 - INFO - Val Loss: 0.3971 Acc: 0.8936\n",
      "2026-01-02 03:25:27,737 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:25:27,738 - INFO - --- Época 71/150 ---\n",
      "2026-01-02 03:26:10,744 - INFO - Train Loss: 0.3654 Acc: 0.8892   \n",
      "2026-01-02 03:26:13,529 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:26:13,530 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:26:13,531 - INFO - Val Loss: 0.5324 Acc: 0.8319\n",
      "2026-01-02 03:26:13,533 - INFO - --- Época 72/150 ---\n",
      "2026-01-02 03:26:56,984 - INFO - Train Loss: 0.3560 Acc: 0.8910   \n",
      "2026-01-02 03:26:59,715 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:26:59,715 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:26:59,716 - INFO - Val Loss: 0.5272 Acc: 0.8347\n",
      "2026-01-02 03:26:59,717 - INFO - --- Época 73/150 ---\n",
      "2026-01-02 03:27:42,296 - INFO - Train Loss: 0.3684 Acc: 0.8889   \n",
      "2026-01-02 03:27:45,114 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:27:45,115 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:27:45,116 - INFO - Val Loss: 0.4959 Acc: 0.8515\n",
      "2026-01-02 03:27:45,117 - INFO - --- Época 74/150 ---\n",
      "2026-01-02 03:28:28,199 - INFO - Train Loss: 0.3774 Acc: 0.8771   \n",
      "2026-01-02 03:28:30,999 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:28:31,000 - INFO -   [Mejora Loss] 0.3971 -> 0.3904. Reseteando paciencia.\n",
      "2026-01-02 03:28:31,001 - INFO - Val Loss: 0.3904 Acc: 0.8711\n",
      "2026-01-02 03:28:31,002 - INFO - --- Época 75/150 ---\n",
      "2026-01-02 03:29:14,205 - INFO - Train Loss: 0.3566 Acc: 0.8910   \n",
      "2026-01-02 03:29:17,062 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:29:17,063 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:29:17,064 - INFO - Val Loss: 0.4051 Acc: 0.8880\n",
      "2026-01-02 03:29:17,065 - INFO - --- Época 76/150 ---\n",
      "2026-01-02 03:30:00,216 - INFO - Train Loss: 0.3358 Acc: 0.8989   \n",
      "2026-01-02 03:30:02,986 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:30:02,987 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:30:02,988 - INFO - Val Loss: 0.3977 Acc: 0.8824\n",
      "2026-01-02 03:30:02,990 - INFO - --- Época 77/150 ---\n",
      "2026-01-02 03:30:46,094 - INFO - Train Loss: 0.3448 Acc: 0.8974   \n",
      "2026-01-02 03:30:48,826 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:30:48,826 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:30:48,828 - INFO - Val Loss: 0.4203 Acc: 0.8880\n",
      "2026-01-02 03:30:48,829 - INFO - --- Época 78/150 ---\n",
      "2026-01-02 03:31:32,958 - INFO - Train Loss: 0.3575 Acc: 0.8921   \n",
      "2026-01-02 03:31:35,901 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:31:35,902 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:31:35,903 - INFO - Val Loss: 0.4420 Acc: 0.8571\n",
      "2026-01-02 03:31:35,904 - INFO - --- Época 79/150 ---\n",
      "2026-01-02 03:32:19,295 - INFO - Train Loss: 0.3563 Acc: 0.8935   \n",
      "2026-01-02 03:32:22,102 - INFO -   [LR] Tasa de aprendizaje actual: 0.000100\n",
      "2026-01-02 03:32:22,102 - INFO -   [Sin mejora Loss] Paciencia: 5/10\n",
      "2026-01-02 03:32:22,103 - INFO - Val Loss: 0.3996 Acc: 0.8964\n",
      "2026-01-02 03:32:22,539 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:32:22,541 - INFO - --- Época 80/150 ---\n",
      "2026-01-02 03:33:05,619 - INFO - Train Loss: 0.3357 Acc: 0.8985   \n",
      "2026-01-02 03:33:08,379 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:33:08,380 - INFO -   [Sin mejora Loss] Paciencia: 6/10\n",
      "2026-01-02 03:33:08,381 - INFO - Val Loss: 0.4779 Acc: 0.8403\n",
      "2026-01-02 03:33:08,382 - INFO - --- Época 81/150 ---\n",
      "2026-01-02 03:33:51,083 - INFO - Train Loss: 0.3249 Acc: 0.9081   \n",
      "2026-01-02 03:33:53,890 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:33:53,891 - INFO -   [Mejora Loss] 0.3904 -> 0.3701. Reseteando paciencia.\n",
      "2026-01-02 03:33:53,892 - INFO - Val Loss: 0.3701 Acc: 0.8992\n",
      "2026-01-02 03:33:54,298 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:33:54,299 - INFO - --- Época 82/150 ---\n",
      "2026-01-02 03:34:37,717 - INFO - Train Loss: 0.3041 Acc: 0.9124   \n",
      "2026-01-02 03:34:40,617 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:34:40,617 - INFO -   [Mejora Loss] 0.3701 -> 0.3519. Reseteando paciencia.\n",
      "2026-01-02 03:34:40,618 - INFO - Val Loss: 0.3519 Acc: 0.9076\n",
      "2026-01-02 03:34:41,024 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:34:41,026 - INFO - --- Época 83/150 ---\n",
      "2026-01-02 03:35:24,139 - INFO - Train Loss: 0.3031 Acc: 0.9174   \n",
      "2026-01-02 03:35:26,936 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:35:26,936 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:35:26,937 - INFO - Val Loss: 0.3611 Acc: 0.9104\n",
      "2026-01-02 03:35:27,360 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:35:27,361 - INFO - --- Época 84/150 ---\n",
      "2026-01-02 03:36:11,013 - INFO - Train Loss: 0.3056 Acc: 0.9120   \n",
      "2026-01-02 03:36:13,841 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:36:13,842 - INFO -   [Mejora Loss] 0.3519 -> 0.3472. Reseteando paciencia.\n",
      "2026-01-02 03:36:13,844 - INFO - Val Loss: 0.3472 Acc: 0.9104\n",
      "2026-01-02 03:36:13,845 - INFO - --- Época 85/150 ---\n",
      "2026-01-02 03:36:57,262 - INFO - Train Loss: 0.2947 Acc: 0.9138   \n",
      "2026-01-02 03:37:00,099 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:37:00,099 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:37:00,100 - INFO - Val Loss: 0.3861 Acc: 0.8936\n",
      "2026-01-02 03:37:00,101 - INFO - --- Época 86/150 ---\n",
      "2026-01-02 03:37:43,496 - INFO - Train Loss: 0.3104 Acc: 0.9120   \n",
      "2026-01-02 03:37:46,253 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:37:46,254 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:37:46,255 - INFO - Val Loss: 0.3579 Acc: 0.9020\n",
      "2026-01-02 03:37:46,256 - INFO - --- Época 87/150 ---\n",
      "2026-01-02 03:38:29,594 - INFO - Train Loss: 0.3128 Acc: 0.9149   \n",
      "2026-01-02 03:38:32,414 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:38:32,414 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:38:32,416 - INFO - Val Loss: 0.3640 Acc: 0.9076\n",
      "2026-01-02 03:38:32,417 - INFO - --- Época 88/150 ---\n",
      "2026-01-02 03:39:15,734 - INFO - Train Loss: 0.3078 Acc: 0.9085   \n",
      "2026-01-02 03:39:18,565 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:39:18,567 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:39:18,568 - INFO - Val Loss: 0.3915 Acc: 0.8908\n",
      "2026-01-02 03:39:18,570 - INFO - --- Época 89/150 ---\n",
      "2026-01-02 03:40:01,663 - INFO - Train Loss: 0.3100 Acc: 0.9067   \n",
      "2026-01-02 03:40:04,396 - INFO -   [LR] Tasa de aprendizaje actual: 0.000050\n",
      "2026-01-02 03:40:04,397 - INFO -   [Sin mejora Loss] Paciencia: 5/10\n",
      "2026-01-02 03:40:04,398 - INFO - Val Loss: 0.3752 Acc: 0.9020\n",
      "2026-01-02 03:40:04,399 - INFO - --- Época 90/150 ---\n",
      "2026-01-02 03:40:47,604 - INFO - Train Loss: 0.3106 Acc: 0.9010   \n",
      "2026-01-02 03:40:50,422 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:40:50,423 - INFO -   [Sin mejora Loss] Paciencia: 6/10\n",
      "2026-01-02 03:40:50,424 - INFO - Val Loss: 0.3687 Acc: 0.9048\n",
      "2026-01-02 03:40:50,425 - INFO - --- Época 91/150 ---\n",
      "2026-01-02 03:41:33,743 - INFO - Train Loss: 0.2949 Acc: 0.9174   \n",
      "2026-01-02 03:41:36,545 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:41:36,545 - INFO -   [Sin mejora Loss] Paciencia: 7/10\n",
      "2026-01-02 03:41:36,546 - INFO - Val Loss: 0.3491 Acc: 0.9244\n",
      "2026-01-02 03:41:36,943 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:41:36,945 - INFO - --- Época 92/150 ---\n",
      "2026-01-02 03:42:20,495 - INFO - Train Loss: 0.2954 Acc: 0.9213   \n",
      "2026-01-02 03:42:23,156 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:42:23,157 - INFO -   [Sin mejora Loss] Paciencia: 8/10\n",
      "2026-01-02 03:42:23,159 - INFO - Val Loss: 0.3520 Acc: 0.9244\n",
      "2026-01-02 03:42:23,160 - INFO - --- Época 93/150 ---\n",
      "2026-01-02 03:43:06,492 - INFO - Train Loss: 0.2847 Acc: 0.9234   \n",
      "2026-01-02 03:43:09,331 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:43:09,332 - INFO -   [Sin mejora Loss] Paciencia: 9/10\n",
      "2026-01-02 03:43:09,333 - INFO - Val Loss: 0.3634 Acc: 0.9104\n",
      "2026-01-02 03:43:09,335 - INFO - --- Época 94/150 ---\n",
      "2026-01-02 03:43:52,130 - INFO - Train Loss: 0.2679 Acc: 0.9245   \n",
      "2026-01-02 03:43:54,981 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:43:54,982 - INFO -   [Mejora Loss] 0.3472 -> 0.3351. Reseteando paciencia.\n",
      "2026-01-02 03:43:54,983 - INFO - Val Loss: 0.3351 Acc: 0.9104\n",
      "2026-01-02 03:43:54,984 - INFO - --- Época 95/150 ---\n",
      "2026-01-02 03:44:38,058 - INFO - Train Loss: 0.2748 Acc: 0.9263   \n",
      "2026-01-02 03:44:40,824 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:44:40,825 - INFO -   [Mejora Loss] 0.3351 -> 0.3326. Reseteando paciencia.\n",
      "2026-01-02 03:44:40,827 - INFO - Val Loss: 0.3326 Acc: 0.9356\n",
      "2026-01-02 03:44:41,265 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:44:41,267 - INFO - --- Época 96/150 ---\n",
      "2026-01-02 03:45:24,335 - INFO - Train Loss: 0.2774 Acc: 0.9231   \n",
      "2026-01-02 03:45:27,260 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:45:27,261 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:45:27,262 - INFO - Val Loss: 0.3427 Acc: 0.9188\n",
      "2026-01-02 03:45:27,264 - INFO - --- Época 97/150 ---\n",
      "2026-01-02 03:46:10,812 - INFO - Train Loss: 0.2704 Acc: 0.9281   \n",
      "2026-01-02 03:46:13,682 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:46:13,683 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:46:13,684 - INFO - Val Loss: 0.3412 Acc: 0.9020\n",
      "2026-01-02 03:46:13,685 - INFO - --- Época 98/150 ---\n",
      "2026-01-02 03:46:57,197 - INFO - Train Loss: 0.2735 Acc: 0.9217   \n",
      "2026-01-02 03:46:59,998 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:46:59,999 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:47:00,000 - INFO - Val Loss: 0.3491 Acc: 0.9160\n",
      "2026-01-02 03:47:00,001 - INFO - --- Época 99/150 ---\n",
      "2026-01-02 03:47:43,872 - INFO - Train Loss: 0.2879 Acc: 0.9220   \n",
      "2026-01-02 03:47:46,646 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:47:46,647 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:47:46,648 - INFO - Val Loss: 0.3407 Acc: 0.9216\n",
      "2026-01-02 03:47:46,650 - INFO - --- Época 100/150 ---\n",
      "2026-01-02 03:48:30,040 - INFO - Train Loss: 0.2770 Acc: 0.9241   \n",
      "2026-01-02 03:48:32,896 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:48:32,897 - INFO -   [Mejora Loss] 0.3326 -> 0.3236. Reseteando paciencia.\n",
      "2026-01-02 03:48:32,898 - INFO - Val Loss: 0.3236 Acc: 0.9216\n",
      "2026-01-02 03:48:32,899 - INFO - --- Época 101/150 ---\n",
      "2026-01-02 03:49:16,734 - INFO - Train Loss: 0.2764 Acc: 0.9249   \n",
      "2026-01-02 03:49:19,505 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:49:19,506 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:49:19,507 - INFO - Val Loss: 0.3600 Acc: 0.9076\n",
      "2026-01-02 03:49:19,509 - INFO - --- Época 102/150 ---\n",
      "2026-01-02 03:50:02,784 - INFO - Train Loss: 0.2750 Acc: 0.9231   \n",
      "2026-01-02 03:50:05,513 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:50:05,514 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:50:05,517 - INFO - Val Loss: 0.3312 Acc: 0.9328\n",
      "2026-01-02 03:50:05,518 - INFO - --- Época 103/150 ---\n",
      "2026-01-02 03:50:48,991 - INFO - Train Loss: 0.2750 Acc: 0.9302   \n",
      "2026-01-02 03:50:51,861 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:50:51,861 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:50:51,863 - INFO - Val Loss: 0.3438 Acc: 0.9132\n",
      "2026-01-02 03:50:51,864 - INFO - --- Época 104/150 ---\n",
      "2026-01-02 03:51:35,138 - INFO - Train Loss: 0.2716 Acc: 0.9281   \n",
      "2026-01-02 03:51:37,925 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:51:37,926 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:51:37,927 - INFO - Val Loss: 0.3386 Acc: 0.9328\n",
      "2026-01-02 03:51:37,928 - INFO - --- Época 105/150 ---\n",
      "2026-01-02 03:52:21,277 - INFO - Train Loss: 0.2654 Acc: 0.9281   \n",
      "2026-01-02 03:52:24,057 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:52:24,057 - INFO -   [Sin mejora Loss] Paciencia: 5/10\n",
      "2026-01-02 03:52:24,058 - INFO - Val Loss: 0.3474 Acc: 0.9300\n",
      "2026-01-02 03:52:24,059 - INFO - --- Época 106/150 ---\n",
      "2026-01-02 03:53:07,050 - INFO - Train Loss: 0.2564 Acc: 0.9298   \n",
      "2026-01-02 03:53:09,767 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:53:09,768 - INFO -   [Mejora Loss] 0.3236 -> 0.3229. Reseteando paciencia.\n",
      "2026-01-02 03:53:09,769 - INFO - Val Loss: 0.3229 Acc: 0.9216\n",
      "2026-01-02 03:53:09,770 - INFO - --- Época 107/150 ---\n",
      "2026-01-02 03:53:53,040 - INFO - Train Loss: 0.2692 Acc: 0.9245   \n",
      "2026-01-02 03:53:55,833 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:53:55,834 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:53:55,836 - INFO - Val Loss: 0.3338 Acc: 0.9300\n",
      "2026-01-02 03:53:55,836 - INFO - --- Época 108/150 ---\n",
      "2026-01-02 03:54:38,670 - INFO - Train Loss: 0.2648 Acc: 0.9288   \n",
      "2026-01-02 03:54:41,464 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:54:41,465 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:54:41,466 - INFO - Val Loss: 0.3257 Acc: 0.9216\n",
      "2026-01-02 03:54:41,468 - INFO - --- Época 109/150 ---\n",
      "2026-01-02 03:55:23,840 - INFO - Train Loss: 0.2621 Acc: 0.9284   \n",
      "2026-01-02 03:55:26,592 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:55:26,593 - INFO -   [Mejora Loss] 0.3229 -> 0.3113. Reseteando paciencia.\n",
      "2026-01-02 03:55:26,594 - INFO - Val Loss: 0.3113 Acc: 0.9216\n",
      "2026-01-02 03:55:26,595 - INFO - --- Época 110/150 ---\n",
      "2026-01-02 03:56:09,553 - INFO - Train Loss: 0.2836 Acc: 0.9227   \n",
      "2026-01-02 03:56:12,353 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:56:12,354 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 03:56:12,356 - INFO - Val Loss: 0.3180 Acc: 0.9272\n",
      "2026-01-02 03:56:12,358 - INFO - --- Época 111/150 ---\n",
      "2026-01-02 03:56:55,751 - INFO - Train Loss: 0.2720 Acc: 0.9270   \n",
      "2026-01-02 03:56:58,557 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:56:58,558 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 03:56:58,560 - INFO - Val Loss: 0.3206 Acc: 0.9188\n",
      "2026-01-02 03:56:58,561 - INFO - --- Época 112/150 ---\n",
      "2026-01-02 03:57:41,858 - INFO - Train Loss: 0.2611 Acc: 0.9291   \n",
      "2026-01-02 03:57:44,677 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:57:44,678 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 03:57:44,679 - INFO - Val Loss: 0.3209 Acc: 0.9188\n",
      "2026-01-02 03:57:44,680 - INFO - --- Época 113/150 ---\n",
      "2026-01-02 03:58:27,824 - INFO - Train Loss: 0.2717 Acc: 0.9284   \n",
      "2026-01-02 03:58:30,536 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:58:30,537 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 03:58:30,538 - INFO - Val Loss: 0.3233 Acc: 0.9300\n",
      "2026-01-02 03:58:30,539 - INFO - --- Época 114/150 ---\n",
      "2026-01-02 03:59:13,204 - INFO - Train Loss: 0.2688 Acc: 0.9252   \n",
      "2026-01-02 03:59:15,918 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 03:59:15,918 - INFO -   [Mejora Loss] 0.3113 -> 0.3111. Reseteando paciencia.\n",
      "2026-01-02 03:59:15,920 - INFO - Val Loss: 0.3111 Acc: 0.9384\n",
      "2026-01-02 03:59:16,338 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 03:59:16,339 - INFO - --- Época 115/150 ---\n",
      "2026-01-02 03:59:59,719 - INFO - Train Loss: 0.2539 Acc: 0.9320   \n",
      "2026-01-02 04:00:02,490 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 04:00:02,492 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:00:02,493 - INFO - Val Loss: 0.3348 Acc: 0.9104\n",
      "2026-01-02 04:00:02,493 - INFO - --- Época 116/150 ---\n",
      "2026-01-02 04:00:46,134 - INFO - Train Loss: 0.2756 Acc: 0.9213   \n",
      "2026-01-02 04:00:48,971 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 04:00:48,972 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 04:00:48,973 - INFO - Val Loss: 0.3201 Acc: 0.9244\n",
      "2026-01-02 04:00:48,974 - INFO - --- Época 117/150 ---\n",
      "2026-01-02 04:01:32,522 - INFO - Train Loss: 0.2598 Acc: 0.9263   \n",
      "2026-01-02 04:01:35,364 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 04:01:35,366 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 04:01:35,367 - INFO - Val Loss: 0.3215 Acc: 0.9272\n",
      "2026-01-02 04:01:35,368 - INFO - --- Época 118/150 ---\n",
      "2026-01-02 04:02:18,902 - INFO - Train Loss: 0.2546 Acc: 0.9302   \n",
      "2026-01-02 04:02:21,689 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 04:02:21,690 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 04:02:21,691 - INFO - Val Loss: 0.3306 Acc: 0.9188\n",
      "2026-01-02 04:02:21,692 - INFO - --- Época 119/150 ---\n",
      "2026-01-02 04:03:04,931 - INFO - Train Loss: 0.2632 Acc: 0.9284   \n",
      "2026-01-02 04:03:07,691 - INFO -   [LR] Tasa de aprendizaje actual: 0.000025\n",
      "2026-01-02 04:03:07,693 - INFO -   [Sin mejora Loss] Paciencia: 5/10\n",
      "2026-01-02 04:03:07,694 - INFO - Val Loss: 0.3311 Acc: 0.9188\n",
      "2026-01-02 04:03:07,695 - INFO - --- Época 120/150 ---\n",
      "2026-01-02 04:03:51,012 - INFO - Train Loss: 0.2674 Acc: 0.9270   \n",
      "2026-01-02 04:03:53,953 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:03:53,954 - INFO -   [Sin mejora Loss] Paciencia: 6/10\n",
      "2026-01-02 04:03:53,955 - INFO - Val Loss: 0.3159 Acc: 0.9272\n",
      "2026-01-02 04:03:53,956 - INFO - --- Época 121/150 ---\n",
      "2026-01-02 04:04:37,131 - INFO - Train Loss: 0.2499 Acc: 0.9338   \n",
      "2026-01-02 04:04:39,924 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:04:39,925 - INFO -   [Mejora Loss] 0.3111 -> 0.3088. Reseteando paciencia.\n",
      "2026-01-02 04:04:39,926 - INFO - Val Loss: 0.3088 Acc: 0.9300\n",
      "2026-01-02 04:04:39,927 - INFO - --- Época 122/150 ---\n",
      "2026-01-02 04:05:22,822 - INFO - Train Loss: 0.2441 Acc: 0.9387   \n",
      "2026-01-02 04:05:25,594 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:05:25,595 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:05:25,596 - INFO - Val Loss: 0.3128 Acc: 0.9356\n",
      "2026-01-02 04:05:25,596 - INFO - --- Época 123/150 ---\n",
      "2026-01-02 04:06:08,541 - INFO - Train Loss: 0.2404 Acc: 0.9313   \n",
      "2026-01-02 04:06:11,383 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:06:11,384 - INFO -   [Mejora Loss] 0.3088 -> 0.3045. Reseteando paciencia.\n",
      "2026-01-02 04:06:11,385 - INFO - Val Loss: 0.3045 Acc: 0.9272\n",
      "2026-01-02 04:06:11,387 - INFO - --- Época 124/150 ---\n",
      "2026-01-02 04:06:54,702 - INFO - Train Loss: 0.2436 Acc: 0.9405   \n",
      "2026-01-02 04:06:57,423 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:06:57,424 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:06:57,425 - INFO - Val Loss: 0.3051 Acc: 0.9328\n",
      "2026-01-02 04:06:57,427 - INFO - --- Época 125/150 ---\n",
      "2026-01-02 04:07:40,714 - INFO - Train Loss: 0.2606 Acc: 0.9284   \n",
      "2026-01-02 04:07:43,573 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:07:43,574 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 04:07:43,575 - INFO - Val Loss: 0.3122 Acc: 0.9272\n",
      "2026-01-02 04:07:43,576 - INFO - --- Época 126/150 ---\n",
      "2026-01-02 04:08:27,411 - INFO - Train Loss: 0.2520 Acc: 0.9341   \n",
      "2026-01-02 04:08:30,140 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:08:30,141 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 04:08:30,143 - INFO - Val Loss: 0.3102 Acc: 0.9300\n",
      "2026-01-02 04:08:30,144 - INFO - --- Época 127/150 ---\n",
      "2026-01-02 04:09:13,097 - INFO - Train Loss: 0.2499 Acc: 0.9341   \n",
      "2026-01-02 04:09:15,916 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:09:15,916 - INFO -   [Mejora Loss] 0.3045 -> 0.3017. Reseteando paciencia.\n",
      "2026-01-02 04:09:15,918 - INFO - Val Loss: 0.3017 Acc: 0.9356\n",
      "2026-01-02 04:09:15,919 - INFO - --- Época 128/150 ---\n",
      "2026-01-02 04:09:58,777 - INFO - Train Loss: 0.2408 Acc: 0.9320   \n",
      "2026-01-02 04:10:01,864 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:10:01,865 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:10:01,867 - INFO - Val Loss: 0.3208 Acc: 0.9300\n",
      "2026-01-02 04:10:01,868 - INFO - --- Época 129/150 ---\n",
      "2026-01-02 04:10:45,309 - INFO - Train Loss: 0.2461 Acc: 0.9395   \n",
      "2026-01-02 04:10:48,057 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:10:48,057 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 04:10:48,059 - INFO - Val Loss: 0.3127 Acc: 0.9216\n",
      "2026-01-02 04:10:48,061 - INFO - --- Época 130/150 ---\n",
      "2026-01-02 04:11:30,857 - INFO - Train Loss: 0.2500 Acc: 0.9298   \n",
      "2026-01-02 04:11:33,650 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:11:33,651 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 04:11:33,652 - INFO - Val Loss: 0.3212 Acc: 0.9300\n",
      "2026-01-02 04:11:33,653 - INFO - --- Época 131/150 ---\n",
      "2026-01-02 04:12:20,089 - INFO - Train Loss: 0.2468 Acc: 0.9363   \n",
      "2026-01-02 04:12:27,131 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:12:27,132 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 04:12:27,133 - INFO - Val Loss: 0.3133 Acc: 0.9188\n",
      "2026-01-02 04:12:27,134 - INFO - --- Época 132/150 ---\n",
      "2026-01-02 04:13:10,760 - INFO - Train Loss: 0.2517 Acc: 0.9391   \n",
      "2026-01-02 04:13:13,590 - INFO -   [LR] Tasa de aprendizaje actual: 0.000013\n",
      "2026-01-02 04:13:13,590 - INFO -   [Sin mejora Loss] Paciencia: 5/10\n",
      "2026-01-02 04:13:13,591 - INFO - Val Loss: 0.3021 Acc: 0.9356\n",
      "2026-01-02 04:13:13,592 - INFO - --- Época 133/150 ---\n",
      "2026-01-02 04:13:57,081 - INFO - Train Loss: 0.2537 Acc: 0.9291   \n",
      "2026-01-02 04:13:59,800 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:13:59,800 - INFO -   [Sin mejora Loss] Paciencia: 6/10\n",
      "2026-01-02 04:13:59,801 - INFO - Val Loss: 0.3020 Acc: 0.9272\n",
      "2026-01-02 04:13:59,802 - INFO - --- Época 134/150 ---\n",
      "2026-01-02 04:14:42,549 - INFO - Train Loss: 0.2355 Acc: 0.9441   \n",
      "2026-01-02 04:14:45,386 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:14:45,386 - INFO -   [Sin mejora Loss] Paciencia: 7/10\n",
      "2026-01-02 04:14:45,387 - INFO - Val Loss: 0.3019 Acc: 0.9272\n",
      "2026-01-02 04:14:45,389 - INFO - --- Época 135/150 ---\n",
      "2026-01-02 04:15:28,350 - INFO - Train Loss: 0.2379 Acc: 0.9409   \n",
      "2026-01-02 04:15:31,357 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:15:31,358 - INFO -   [Sin mejora Loss] Paciencia: 8/10\n",
      "2026-01-02 04:15:31,359 - INFO - Val Loss: 0.3066 Acc: 0.9356\n",
      "2026-01-02 04:15:31,360 - INFO - --- Época 136/150 ---\n",
      "2026-01-02 04:16:14,698 - INFO - Train Loss: 0.2369 Acc: 0.9359   \n",
      "2026-01-02 04:16:17,547 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:16:17,548 - INFO -   [Sin mejora Loss] Paciencia: 9/10\n",
      "2026-01-02 04:16:17,549 - INFO - Val Loss: 0.3038 Acc: 0.9328\n",
      "2026-01-02 04:16:17,550 - INFO - --- Época 137/150 ---\n",
      "2026-01-02 04:17:00,933 - INFO - Train Loss: 0.2509 Acc: 0.9320   \n",
      "2026-01-02 04:17:03,820 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:17:03,821 - INFO -   [Mejora Loss] 0.3017 -> 0.2975. Reseteando paciencia.\n",
      "2026-01-02 04:17:03,822 - INFO - Val Loss: 0.2975 Acc: 0.9328\n",
      "2026-01-02 04:17:03,823 - INFO - --- Época 138/150 ---\n",
      "2026-01-02 04:17:47,087 - INFO - Train Loss: 0.2419 Acc: 0.9387   \n",
      "2026-01-02 04:17:50,112 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:17:50,113 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:17:50,114 - INFO - Val Loss: 0.3031 Acc: 0.9328\n",
      "2026-01-02 04:17:50,116 - INFO - --- Época 139/150 ---\n",
      "2026-01-02 04:18:33,943 - INFO - Train Loss: 0.2306 Acc: 0.9420   \n",
      "2026-01-02 04:18:36,725 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:18:36,726 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 04:18:36,727 - INFO - Val Loss: 0.3054 Acc: 0.9356\n",
      "2026-01-02 04:18:36,728 - INFO - --- Época 140/150 ---\n",
      "2026-01-02 04:19:20,551 - INFO - Train Loss: 0.2285 Acc: 0.9476   \n",
      "2026-01-02 04:19:23,362 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:19:23,363 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 04:19:23,364 - INFO - Val Loss: 0.2980 Acc: 0.9356\n",
      "2026-01-02 04:19:23,365 - INFO - --- Época 141/150 ---\n",
      "2026-01-02 04:20:07,192 - INFO - Train Loss: 0.2473 Acc: 0.9366   \n",
      "2026-01-02 04:20:10,030 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:20:10,030 - INFO -   [Mejora Loss] 0.2975 -> 0.2957. Reseteando paciencia.\n",
      "2026-01-02 04:20:10,032 - INFO - Val Loss: 0.2957 Acc: 0.9356\n",
      "2026-01-02 04:20:10,033 - INFO - --- Época 142/150 ---\n",
      "2026-01-02 04:20:53,479 - INFO - Train Loss: 0.2370 Acc: 0.9380   \n",
      "2026-01-02 04:20:56,398 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:20:56,399 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:20:56,400 - INFO - Val Loss: 0.3016 Acc: 0.9412\n",
      "2026-01-02 04:20:56,838 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 04:20:56,839 - INFO - --- Época 143/150 ---\n",
      "2026-01-02 04:21:40,933 - INFO - Train Loss: 0.2344 Acc: 0.9377   \n",
      "2026-01-02 04:21:43,707 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:21:43,707 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 04:21:43,708 - INFO - Val Loss: 0.3048 Acc: 0.9216\n",
      "2026-01-02 04:21:43,709 - INFO - --- Época 144/150 ---\n",
      "2026-01-02 04:22:27,452 - INFO - Train Loss: 0.2464 Acc: 0.9387   \n",
      "2026-01-02 04:22:30,329 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:22:30,330 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 04:22:30,332 - INFO - Val Loss: 0.3054 Acc: 0.9160\n",
      "2026-01-02 04:22:30,333 - INFO - --- Época 145/150 ---\n",
      "2026-01-02 04:23:14,502 - INFO - Train Loss: 0.2388 Acc: 0.9366   \n",
      "2026-01-02 04:23:17,434 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:23:17,435 - INFO -   [Mejora Loss] 0.2957 -> 0.2945. Reseteando paciencia.\n",
      "2026-01-02 04:23:17,436 - INFO - Val Loss: 0.2945 Acc: 0.9328\n",
      "2026-01-02 04:23:17,438 - INFO - --- Época 146/150 ---\n",
      "2026-01-02 04:24:01,657 - INFO - Train Loss: 0.2350 Acc: 0.9387   \n",
      "2026-01-02 04:24:04,847 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:24:04,848 - INFO -   [Sin mejora Loss] Paciencia: 1/10\n",
      "2026-01-02 04:24:04,850 - INFO - Val Loss: 0.3053 Acc: 0.9272\n",
      "2026-01-02 04:24:04,851 - INFO - --- Época 147/150 ---\n",
      "2026-01-02 04:24:49,206 - INFO - Train Loss: 0.2423 Acc: 0.9370   \n",
      "2026-01-02 04:24:52,090 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:24:52,091 - INFO -   [Sin mejora Loss] Paciencia: 2/10\n",
      "2026-01-02 04:24:52,092 - INFO - Val Loss: 0.3003 Acc: 0.9356\n",
      "2026-01-02 04:24:52,093 - INFO - --- Época 148/150 ---\n",
      "2026-01-02 04:25:35,718 - INFO - Train Loss: 0.2451 Acc: 0.9370   \n",
      "2026-01-02 04:25:38,604 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:25:38,605 - INFO -   [Sin mejora Loss] Paciencia: 3/10\n",
      "2026-01-02 04:25:38,606 - INFO - Val Loss: 0.2956 Acc: 0.9328\n",
      "2026-01-02 04:25:38,607 - INFO - --- Época 149/150 ---\n",
      "2026-01-02 04:26:22,278 - INFO - Train Loss: 0.2330 Acc: 0.9409   \n",
      "2026-01-02 04:26:25,138 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:26:25,139 - INFO -   [Sin mejora Loss] Paciencia: 4/10\n",
      "2026-01-02 04:26:25,140 - INFO - Val Loss: 0.3034 Acc: 0.9440\n",
      "2026-01-02 04:26:25,545 - INFO -   [Nuevo Récord Acc] Guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\best_model.pth\n",
      "2026-01-02 04:26:25,547 - INFO - --- Época 150/150 ---\n",
      "2026-01-02 04:27:08,814 - INFO - Train Loss: 0.2293 Acc: 0.9459   \n",
      "2026-01-02 04:27:11,640 - INFO -   [LR] Tasa de aprendizaje actual: 0.000006\n",
      "2026-01-02 04:27:11,640 - INFO -   [Mejora Loss] 0.2945 -> 0.2903. Reseteando paciencia.\n",
      "2026-01-02 04:27:11,641 - INFO - Val Loss: 0.2903 Acc: 0.9356\n",
      "2026-01-02 04:27:11,642 - INFO - Entrenamiento finalizado en 153m 21s\n",
      "2026-01-02 04:27:11,643 - INFO - Mejor Val Acc lograda: 0.9440\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Barra de progreso\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, output_dir, logger, scheduler=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # --- CONFIGURACIÓN DE EARLY STOPPING ---\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    min_val_loss = np.inf  # Empezamos con pérdida infinita\n",
    "    early_stop = False\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    logger.info(f\"Iniciando entrenamiento por {num_epochs} épocas...\")\n",
    "    logger.info(f\"Paciencia configurada: {patience} épocas.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            break  # Salir del bucle de épocas\n",
    "            \n",
    "        logger.info(f'--- Época {epoch+1}/{num_epochs} ---')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            loop = tqdm(dataloader, desc=f\"{phase.capitalize()}\", leave=False)\n",
    "\n",
    "            for inputs, labels in loop:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "\n",
    "                # --- LÓGICA DEL SCHEDULER ---\n",
    "                if scheduler is not None:\n",
    "                    # El scheduler ReduceLROnPlateau necesita la pérdida de validación\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    # Log del Learning Rate actual para ver cuándo baja\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    logger.info(f\"  [LR] Tasa de aprendizaje actual: {current_lr:.6f}\")\n",
    "\n",
    "                # --- LÓGICA DE EARLY STOPPING (Basada en Pérdida de Validación) ---\n",
    "                if epoch_loss < min_val_loss:\n",
    "                    logger.info(f\"  [Mejora Loss] {min_val_loss:.4f} -> {epoch_loss:.4f}. Reseteando paciencia.\")\n",
    "                    min_val_loss = epoch_loss\n",
    "                    patience_counter = 0  # Hubo mejora, reseteamos el contador\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    logger.info(f\"  [Sin mejora Loss] Paciencia: {patience_counter}/{patience}\")\n",
    "                    if patience_counter >= patience:\n",
    "                        logger.info(\"¡EARLY STOPPING ACTIVADO! El modelo ya no mejora su pérdida.\")\n",
    "                        early_stop = True\n",
    "                # -----------------------------------------------------------------\n",
    "\n",
    "            logger.info(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Guardar el mejor modelo basado en ACCURACY (independiente del Early Stopping)\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                save_path = os.path.join(output_dir, 'best_model.pth')\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                logger.info(f\"  [Nuevo Récord Acc] Guardado en: {save_path}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    logger.info(f'Entrenamiento finalizado en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    logger.info(f'Mejor Val Acc lograda: {best_acc:.4f}')\n",
    "\n",
    "    # Cargar los mejores pesos encontrados\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    last_path = os.path.join(output_dir, 'last_model.pth')\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=1e-4, weight_decay=5e-2)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5,     # Lo reduce a la mitad\n",
    "    patience=5,     # Si en 5 épocas el val_loss no baja, reduce el LR\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "model_ft, history = train_model(\n",
    "    model=model_ft,\n",
    "    train_loader=dataloaders['train'], # Asume que ya definiste tus dataloaders\n",
    "    val_loader=dataloaders['val'],\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    output_dir=RUN_SAVE_DIR, # <--- Aquí se guardarán los .pth\n",
    "    logger=logger,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0992da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
      "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
      "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
      "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
      "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
      "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
      "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
      "├─KANLinear: 1-3                         [-1, 256]                 --\n",
      "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
      "├─Dropout: 1-4                           [-1, 256]                 --\n",
      "├─KANLinear: 1-5                         [-1, 128]                 --\n",
      "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
      "├─Dropout: 1-6                           [-1, 128]                 --\n",
      "├─KANLinear: 1-7                         [-1, 6]                   --\n",
      "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
      "==========================================================================================\n",
      "Total params: 241,536\n",
      "Trainable params: 241,536\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 679.73\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 44.41\n",
      "Params size (MB): 0.92\n",
      "Estimated Total Size (MB): 45.90\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 128, 14, 14]         --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 224, 224]        896\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 32, 224, 224]        64\n",
       "|    └─ReLU: 2-3                         [-1, 32, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 32, 112, 112]        --\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 112, 112]        18,496\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 64, 112, 112]        128\n",
       "|    └─ReLU: 2-7                         [-1, 64, 112, 112]        --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 64, 56, 56]          --\n",
       "|    └─Conv2d: 2-9                       [-1, 128, 56, 56]         73,856\n",
       "|    └─BatchNorm2d: 2-10                 [-1, 128, 56, 56]         256\n",
       "|    └─ReLU: 2-11                        [-1, 128, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-12                   [-1, 128, 28, 28]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 128, 28, 28]         147,584\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 128, 28, 28]         256\n",
       "|    └─ReLU: 2-15                        [-1, 128, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-16                   [-1, 128, 14, 14]         --\n",
       "├─TaylorSeriesApproximation: 1-2         [-1, 25088]               --\n",
       "├─KANLinear: 1-3                         [-1, 256]                 --\n",
       "|    └─SiLU: 2-17                        [-1, 25088]               --\n",
       "├─Dropout: 1-4                           [-1, 256]                 --\n",
       "├─KANLinear: 1-5                         [-1, 128]                 --\n",
       "|    └─SiLU: 2-18                        [-1, 256]                 --\n",
       "├─Dropout: 1-6                           [-1, 128]                 --\n",
       "├─KANLinear: 1-7                         [-1, 6]                   --\n",
       "|    └─SiLU: 2-19                        [-1, 128]                 --\n",
       "==========================================================================================\n",
       "Total params: 241,536\n",
       "Trainable params: 241,536\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 679.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 44.41\n",
       "Params size (MB): 0.92\n",
       "Estimated Total Size (MB): 45.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_ft, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80c1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfica guardada en: models/sbtaylor_kan_cotton\\run_20260102_015349\\training_history.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "    loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Gráfica de Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.grid(True)\n",
    "    # --- CORRECCIÓN AQUÍ ---\n",
    "    # 1. Guardar PRIMERO\n",
    "    save_path = os.path.join(RUN_SAVE_DIR, \"training_history.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight') # dpi=300 para alta calidad, bbox_inches corta bordes blancos extra\n",
    "    print(f\"Gráfica guardada en: {save_path}\")\n",
    "    \n",
    "    # 2. Mostrar DESPUÉS\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf7a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging # Necesario para el type hinting o manejo interno\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names, output_dir, logger):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo entrenado y genera reporte.\n",
    "    Ahora recibe 'logger' como argumento para asegurar que escriba en tu archivo .log.\n",
    "    \"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*40)\n",
    "    logger.info(\"--- INICIANDO EVALUACIÓN EN TEST SET ---\")\n",
    "    logger.info(\"=\"*40)\n",
    "\n",
    "    # 1. Poner el modelo en modo de evaluación (Apaga Dropout/BatchNorm)\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    total_inference_time = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # 2. Iterar sobre el conjunto de prueba\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # --- BLOQUE DE MEDICIÓN DE TIEMPO PRECISA ---\n",
    "            # Si usas GPU, es obligatorio sincronizar antes y después del forward\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            \n",
    "            end_time = time.time()\n",
    "            # ---------------------------------------------\n",
    "            \n",
    "            # Acumular tiempo real de procesamiento\n",
    "            total_inference_time += (end_time - start_time)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Convertir a numpy\n",
    "    true_labels = np.array(all_labels)\n",
    "    predicted_labels = np.array(all_preds)\n",
    "\n",
    "    # 3. Calcular Métricas\n",
    "    logger.info(\"Calculando métricas estadísticas...\")\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # zero_division=0 evita errores si una clase no tiene predicciones\n",
    "    precision_per_class = precision_score(true_labels, predicted_labels, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(true_labels, predicted_labels, average=None, zero_division=0)\n",
    "    f1_per_class = f1_score(true_labels, predicted_labels, average=None, zero_division=0)\n",
    "    \n",
    "    # Promedios Macro (trata todas las clases igual, útil si hay desbalance)\n",
    "    avg_precision = np.mean(precision_per_class)\n",
    "    avg_recall = np.mean(recall_per_class)\n",
    "    avg_f1 = np.mean(f1_per_class)\n",
    "\n",
    "    # Tiempo promedio por imagen (Métrica Clave para KAN vs VGG)\n",
    "    avg_inference_time_ms = (total_inference_time / total_samples) * 1000 \n",
    "\n",
    "    # 4. Matriz de Confusión Visual\n",
    "    logger.info(\"Generando matriz de confusión...\")\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\", # 'd' es para enteros (decimal), mejor que 'g' para conteos\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicción del Modelo\", fontsize=12)\n",
    "    plt.ylabel(\"Realidad (Ground Truth)\", fontsize=12)\n",
    "    plt.title(f\"Matriz de Confusión - Accuracy: {accuracy:.2%}\", fontsize=14)\n",
    "    \n",
    "    cm_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close() # Cierra la figura para liberar memoria\n",
    "    logger.info(f\"Gráfico guardado en: {cm_path}\")\n",
    "\n",
    "    # 5. Reporte de Texto\n",
    "    logger.info(\"Escribiendo reporte final...\")\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Clase\": class_names,\n",
    "        \"Precision\": np.round(precision_per_class, 4),\n",
    "        \"Recall\": np.round(recall_per_class, 4),\n",
    "        \"F1-Score\": np.round(f1_per_class, 4),\n",
    "    })\n",
    "\n",
    "    report_path = os.path.join(output_dir, \"test_metrics_report.txt\")\n",
    "    \n",
    "    with open(report_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\" REPORTE DE EVALUACIÓN: {time.strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Métricas Globales:\\n\")\n",
    "        f.write(f\"- Accuracy:          {accuracy:.4f} ({accuracy:.2%})\\n\")\n",
    "        f.write(f\"- Macro Precision:   {avg_precision:.4f}\\n\")\n",
    "        f.write(f\"- Macro Recall:      {avg_recall:.4f}\\n\")\n",
    "        f.write(f\"- Macro F1-Score:    {avg_f1:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"EFICIENCIA (Velocidad)\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"- Muestras totales:  {total_samples}\\n\")\n",
    "        f.write(f\"- Tiempo total:      {total_inference_time:.4f} seg\\n\")\n",
    "        f.write(f\"- Tiempo por imagen: {avg_inference_time_ms:.4f} ms\\n\\n\")\n",
    "        \n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(\"DETALLE POR CLASE\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        # Usamos to_markdown si pandas es reciente, sino to_string\n",
    "        try:\n",
    "            f.write(metrics_df.to_markdown(index=False))\n",
    "        except:\n",
    "            f.write(metrics_df.to_string(index=False))\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"Matriz de Confusión (Texto):\\n\")\n",
    "        f.write(np.array2string(cm, separator=', '))\n",
    "        \n",
    "    logger.info(f\"Reporte de texto guardado en: {report_path}\")\n",
    "    logger.info(\"--- EVALUACIÓN FINALIZADA ---\")\n",
    "    \n",
    "    return accuracy, avg_f1 # Retorna valores por si los necesitas en el script principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0555440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"processed_dataset/test\" # <--- Ruta a la carpeta de prueba\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c1eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 04:27:15,362 - INFO - Cargando el mejor modelo para la evaluación...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones calculadas automáticamente para FC1: 25088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Aphids',\n",
       " 'Army worm',\n",
       " 'Bacterial Blight',\n",
       " 'Healthy',\n",
       " 'Powdery Mildew',\n",
       " 'Target spot']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(RUN_SAVE_DIR, 'best_model.pth')\n",
    "# 2. Crear una nueva instancia del modelo y cargar los mejores pesos\n",
    "logger.info(\"Cargando el mejor modelo para la evaluación...\")\n",
    "eval_model = KAN_Model(num_classes=num_classes_cotton).to(device)\n",
    "eval_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "class_names = test_dataset.classes  # Obtener los nombres de las clases desde el dataset de prueba\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c9eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 04:27:16,310 - INFO - \n",
      "========================================\n",
      "2026-01-02 04:27:16,313 - INFO - --- INICIANDO EVALUACIÓN EN TEST SET ---\n",
      "2026-01-02 04:27:16,314 - INFO - ========================================\n",
      "2026-01-02 04:27:19,330 - INFO - Calculando métricas estadísticas...\n",
      "2026-01-02 04:27:19,341 - INFO - Generando matriz de confusión...\n",
      "2026-01-02 04:27:19,624 - INFO - Gráfico guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\confusion_matrix.png\n",
      "2026-01-02 04:27:19,625 - INFO - Escribiendo reporte final...\n",
      "2026-01-02 04:27:19,638 - INFO - Reporte de texto guardado en: models/sbtaylor_kan_cotton\\run_20260102_015349\\test_metrics_report.txt\n",
      "2026-01-02 04:27:19,640 - INFO - --- EVALUACIÓN FINALIZADA ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9329608938547486, np.float64(0.9328091845677683))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Llamar a la función de evaluación\n",
    "# Suponiendo que tienes un 'test_loader' y un 'RUN_DIR' definidos\n",
    "evaluate_model(\n",
    "    model=eval_model,\n",
    "    \n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    output_dir=RUN_SAVE_DIR, # El directorio de la ejecución actual para guardar los resultados\n",
    "    logger=logger\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
